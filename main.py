import os
import sys
import json
import logging
import asyncio
import time as time_module
import hashlib
import random
import uuid
import mimetypes
import textwrap
import re
import shutil
from typing import Optional
from collections import deque
from pathlib import Path
from datetime import datetime, time, timedelta
import numpy as np
from dotenv import load_dotenv

import requests
from PIL import Image, ImageDraw, ImageFont
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS
import moviepy.editor as mpe
import moviepy.video.fx.all as vfx
from moviepy.editor import VideoFileClip, AudioFileClip, ColorClip, TextClip, CompositeVideoClip, ImageClip, concatenate_videoclips, concatenate_audioclips, CompositeAudioClip
from openai import OpenAI
from telegram import Update
from telegram.constants import MessageEntityType
from telegram.ext import Application, MessageHandler, CommandHandler, ContextTypes, filters
from telegram.error import BadRequest
from supabase import create_client, Client

load_dotenv()

logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(message)s",
    level=logging.INFO
)
log = logging.getLogger(__name__)


def get_env_str(name: str) -> str:
    v = os.getenv(name, "").strip()
    if not v:
        raise RuntimeError(f"Missing env var: {name}")
    return v


def get_env_int(name: str) -> int:
    v = os.getenv(name, "").strip()
    if not v:
        raise RuntimeError(f"Missing env var: {name}")
    return int(v)


TELEGRAM_BOT_TOKEN = get_env_str("TELEGRAM_BOT_TOKEN")
BUFFER_CHANNEL_ID = get_env_int("BUFFER_CHANNEL_ID")
MAIN_CHANNEL_ID = get_env_int("MAIN_CHANNEL_ID")
ADMIN_TELEGRAM_ID = int(os.getenv("ADMIN_ID", "5675979056") or 5675979056)
REPORT_CHAT_ID = int(os.getenv("REPORT_CHAT_ID", "5675979056") or 0)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()

# ElevenLabs settings
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY", "").strip()
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "s756tFIFJ9r8dOGB5rlK").strip()

# Supabase settings
SUPABASE_URL = os.getenv("SUPABASE_URL", "").strip()
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY", "").strip()
SUPABASE_BUCKET = os.getenv("SUPABASE_BUCKET", "").strip()
SUPABASE_TIMEOUT_SECONDS = int(os.getenv("SUPABASE_TIMEOUT_SECONDS", "120"))

# Instagram settings
ENABLE_INSTAGRAM = os.getenv("ENABLE_INSTAGRAM", "1").strip()
IG_USER_ID = os.getenv("IG_USER_ID", "").strip()
IG_ACCESS_TOKEN = os.getenv("IG_ACCESS_TOKEN", "").strip()
IG_GRAPH_VERSION = os.getenv("IG_GRAPH_VERSION", "v21.0").strip()
IG_TIMEOUT_SECONDS = int(os.getenv("IG_TIMEOUT_SECONDS", "300"))
IG_POLL_SECONDS = int(os.getenv("IG_POLL_SECONDS", "30"))
IG_POLL_MAX_TRIES = int(os.getenv("IG_POLL_MAX_TRIES", "10"))

# Facebook settings
ENABLE_FB = os.getenv("ENABLE_FB", "1").strip() or "1"
FB_PAGE_ID = os.getenv("FB_PAGE_ID", "").strip()
FB_PAGE_TOKEN = os.getenv("FB_PAGE_TOKEN", "").strip()
FB_GRAPH_VERSION = os.getenv("FB_GRAPH_VERSION", "v21.0").strip()
FB_TIMEOUT_SECONDS = int(os.getenv("FB_TIMEOUT_SECONDS", "300"))

POST_DELAY_SECONDS_RAW = int(os.getenv("POST_DELAY_SECONDS", "1800"))  # 30 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: 1 —á–∞—Å (3600 —Å–µ–∫) –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
POST_DELAY_SECONDS = max(POST_DELAY_SECONDS_RAW, 3600)

# –§–ª–∞–≥ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –±—É—Ñ–µ—Ä–∞ –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
DELETE_FROM_BUFFER = int(os.getenv("DELETE_FROM_BUFFER", "1"))  # –í–∫–ª—é—á–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –§–ª–∞–≥ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —É—Å–ø–µ—à–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
REPORT_AFTER_POST = int(os.getenv("REPORT_AFTER_POST", "1"))

CHANNEL_LINK = "https://t.me/+19xSNtVpJx1hZGQy"
FOOTER_HTML = f"\n\n| <a href=\"{CHANNEL_LINK}\">Haqiqat üß†</a> | <a href=\"{CHANNEL_LINK}\">Kanalga obuna bo'ling</a>"
BRANDED_LINK = f"üëâ Batafsil: {CHANNEL_LINK}"
HASHTAGS_BLOCK = "#haqiqat #uzbekistan #qiziqarli"
PUBLISH_INTERVAL_SECONDS = 3600  # 60 –º–∏–Ω—É—Ç
LINK_BLOCK_HTML = '| <a href="https://t.me/+19xSNtVpjx1hZGQy">Haqiqat üß† | Kanalga obuna bo\'ling</a> |'
CAPTION_MAX_LENGTH = 900  # –õ–∏–º–∏—Ç –¥–ª—è caption

# –ê–¥–º–∏–Ω-—á–∞—Ç –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
ADMIN_CHAT_ID = os.getenv("ADMIN_CHAT_ID", "").strip()
if ADMIN_CHAT_ID:
    try:
        ADMIN_CHAT_ID = int(ADMIN_CHAT_ID)
    except ValueError:
        ADMIN_CHAT_ID = None
else:
    ADMIN_CHAT_ID = None

openai_client = None
if os.getenv("OPENAI_API_KEY"):
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

supabase_client: Optional[Client] = None

# message_id -> {emoji: count}
REACTIONS = {}
# message_id -> {user_id: emoji}
USER_REACTIONS = {}


POST_QUEUE = deque()
IS_POSTING = False
# –ü–µ—Ä–≤–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ä–µ—Å—Ç–∞—Ä—Ç–∞ ‚Äî –ø—É–±–ª–∏–∫—É–µ–º —Å—Ä–∞–∑—É –ø–µ—Ä–≤—ã–π –ø–æ—Å—Ç –±–µ–∑ –æ–∂–∏–¥–∞–Ω–∏–π
FIRST_RUN_IMMEDIATE = True

# üéõÔ∏è MIXED QUEUE 4+4: –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
VOICEOVER_POSTS_COUNT = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ—Å—Ç–æ–≤ —Å –æ–∑–≤—É—á–∫–æ–π
NO_VOICEOVER_POSTS_COUNT = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ—Å—Ç–æ–≤ –±–µ–∑ –æ–∑–≤—É—á–∫–∏
CURRENT_BLOCK_TYPE = "voiceover"  # –¢–µ–∫—É—â–∏–π —Ç–∏–ø –±–ª–æ–∫–∞: "voiceover" –∏–ª–∏ "no_voiceover"
# SMART CONTROL: –°–∏—Å—Ç–µ–º–∞ –ø–∞—É–∑—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π
IS_PAUSED = False

# –°–ò–°–¢–ï–ú–ê –ö–û–ù–í–ï–ô–ï–†: –ü–∞–ø–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
READY_TO_PUBLISH_DIR = Path("ready_to_publish")
READY_TO_PUBLISH_DIR.mkdir(exist_ok=True)
TARGET_READY_POSTS = 10  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º 10 –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ (5 –¥–Ω–µ–π –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã)
IS_PREPARING = False  # –§–ª–∞–≥ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏

QUEUE_FILE = Path("post_queue.json")
SEEN_FILE = Path("seen_posts.json")
SEEN_HASHES = set()
SEEN_FILE_IDS = set()

# IG —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–π (–≤ –ø–∞–º—è—Ç–∏, –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ)
IG_SCHEDULE = {
    "date": None,
    "morning_videos": 0,      # –¥–æ 14:00, –º–∞–∫—Å–∏–º—É–º 3
    "afternoon_videos": 0,    # –ø–æ—Å–ª–µ 16:00, –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ 1 –≤ —á–∞—Å
    "afternoon_carousels": 0  # –ø–æ—Å–ª–µ 15:00, –º–∞–∫—Å–∏–º—É–º 2
}

# –†–∞–∑–æ–≤—ã–π —Ñ–æ—Ä—Å-—Ç–µ—Å—Ç –∫–∞—Ä—É—Å–µ–ª–∏ (–∏–≥–Ω–æ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è/–∑–∞–¥–µ—Ä–∂–µ–∫ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ carousel_pending)
FORCE_CAROUSEL_TEST = True

# –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π
LAST_PHOTO_TIME = None
LAST_VIDEO_TIME = None
LAST_POST_TIME = None
LAST_POST_TIME_FILE = Path("last_post_time.json")
VIDEO_MIRROR_TOGGLE = False

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
PUBLISHED_TEXTS_FILE = Path("published_texts.json")
PUBLISHED_TEXTS = []  # –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
MAX_PUBLISHED_TEXTS = 50  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –ø–æ—Å—Ç–æ–≤

# –ò—Å—Ç–æ—Ä–∏—è –∏ –æ—Ç—á—ë—Ç—ã
HISTORY_LOG = Path("history.log")
REPORTS_DIR = Path("reports")
DAILY_COST_USD = 0.0
TRANSLATION_LAST_COST = 0.0

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
PUBLISHED_TEXTS_FILE = Path("published_texts.json")
PUBLISHED_TEXTS = []  # –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
MAX_PUBLISHED_TEXTS = 50  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –ø–æ—Å—Ç–æ–≤


def get_supabase_client() -> Optional[Client]:
    """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase –∫–ª–∏–µ–Ω—Ç–∞."""
    global supabase_client
    if supabase_client:
        return supabase_client
    
    if not (SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY):
        log.warning("Supabase credentials are not set")
        return None
    
    try:
        supabase_client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
    except Exception as e:
        log.error(f"Failed to create Supabase client: {e}")
        supabase_client = None
    
    return supabase_client


def upload_to_supabase(local_file_path: str, content_type: str) -> Optional[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –≤ Supabase Storage –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É–±–ª–∏—á–Ω—ã–π URL.
    –ù–µ –º–µ–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –±–æ—Ç–∞.
    """
    client = get_supabase_client()
    if not client:
        return None
    
    if not SUPABASE_BUCKET:
        log.warning("Supabase bucket name is not set")
        return None
    
    path_obj = Path(local_file_path)
    if not path_obj.exists():
        log.warning(f"Supabase upload skipped, file not found: {local_file_path}")
        return None
    
    size_mb = path_obj.stat().st_size / (1024 * 1024)
    log.info(f"[DEBUG] File size: {size_mb:.2f} MB")

    unique_name = f"{int(datetime.now().timestamp() * 1000)}_{uuid.uuid4().hex}{path_obj.suffix}"
    upload_url = f"{SUPABASE_URL.rstrip('/')}/storage/v1/object/{SUPABASE_BUCKET}/{unique_name}"
    headers = {
        "Authorization": f"Bearer {SUPABASE_SERVICE_ROLE_KEY}",
        "apikey": SUPABASE_SERVICE_ROLE_KEY,
        "Content-Type": content_type or "application/octet-stream",
        "x-upsert": "false",
    }
    
    try:
        with path_obj.open("rb") as f:
            resp = requests.post(
                upload_url,
                data=f,
                headers=headers,
                timeout=SUPABASE_TIMEOUT_SECONDS,
            )
        resp.raise_for_status()
        public_url = client.storage.from_(SUPABASE_BUCKET).get_public_url(unique_name)
        log.info(f"[Supabase] File uploaded: {public_url}")
        return public_url
    except Exception as e:
        log.error(f"Supabase upload failed: {e}")
        return None


def delete_supabase_file(public_url: str):
    """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ Supabase –ø–æ –ø—É–±–ª–∏—á–Ω–æ–º—É URL."""
    client = get_supabase_client()
    if not client:
        return
    if not (public_url and SUPABASE_BUCKET):
        return

    marker = "/storage/v1/object/public/"
    try:
        if marker not in public_url:
            raise ValueError("public url format unexpected")
        path_part = public_url.split(marker, 1)[1]
        bucket_from_url, key = path_part.split("/", 1)
        if bucket_from_url != SUPABASE_BUCKET:
            log.warning(f"[Supabase] Bucket mismatch when deleting: url_bucket={bucket_from_url}, env_bucket={SUPABASE_BUCKET}")
        if not key:
            raise ValueError("empty storage key")
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏–∑ –±–∞–∫–µ—Ç–∞ (–∫–ª—é—á –±–µ–∑ –∏–º–µ–Ω–∏ –±–∞–∫–µ—Ç–∞)
        client.storage.from_(SUPABASE_BUCKET).remove([key])
        log.info(f"INFO | [CLEANUP] Supabase storage cleared for file: {key}")
    except Exception as e:
        log.warning(f"[Supabase] File delete failed: {e}")


def delete_supabase_files(urls: list[str]):
    """–£–¥–∞–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –∏–∑ Supabase."""
    for url in urls or []:
        delete_supabase_file(url)


def supabase_key_from_url(public_url: str) -> Optional[str]:
    marker = "/storage/v1/object/public/"
    if not public_url or marker not in public_url:
        return None
    try:
        path_part = public_url.split(marker, 1)[1]
        bucket_from_url, key = path_part.split("/", 1)
        if bucket_from_url != SUPABASE_BUCKET:
            return None
        return key
    except Exception:
        return None


def maybe_delete_supabase_media(item: dict, reason: str):
    """
    –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ Supabase, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —É–¥–∞–ª—ë–Ω.
    –ß—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å FB –ø—É–±–ª–∏–∫–∞—Ü–∏—é, –ø–æ—Å–ª–µ IG —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ FB –æ—Ç–∫–ª—é—á—ë–Ω.
    """
    if not item or item.get("supabase_deleted"):
        return
    public_url = item.get("supabase_url")
    if not public_url:
        return

    if reason == "instagram" and ENABLE_FB == "1" and not item.get("fb_published"):
        log.info("[DEBUG] Skip delete after IG publish because FB is enabled; will delete after FB.")
        return

    delete_supabase_file(public_url)
    item["supabase_deleted"] = True


async def cleanup_supabase_orphans(dry_run: bool = True) -> list[str]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–∞–∫–µ—Ç–∞ media —Å —Ç–µ–∫—É—â–µ–π POST_QUEUE –∏ —É–¥–∞–ª—è–µ—Ç (–∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç) –ª–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã.
    dry_run=True ‚Äî —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–∏—Ä–æ—Ç.
    """
    client = get_supabase_client()
    if not client:
        log.warning("[Supabase] cleanup aborted: client not available")
        return []
    if not SUPABASE_BUCKET:
        log.warning("[Supabase] cleanup aborted: bucket not configured")
        return []

    keep_keys = set()
    for it in POST_QUEUE:
        k = supabase_key_from_url(it.get("supabase_url"))
        if k:
            keep_keys.add(k)

    orphans: list[str] = []
    offset = 0
    page_size = 1000
    while True:
        try:
            files = client.storage.from_(SUPABASE_BUCKET).list(
                path="",
                options={"limit": page_size, "offset": offset, "sortBy": {"column": "name", "order": "asc"}},
            )
        except Exception as e:
            log.error(f"[Supabase] cleanup list failed: {e}")
            break
        if not files:
            break
        for f in files:
            name = f.get("name")
            if name and name not in keep_keys:
                orphans.append(name)
        if len(files) < page_size:
            break
        offset += page_size

    if dry_run:
        log.info(f"[Supabase] cleanup dry-run: orphans={orphans}")
        return orphans

    for name in orphans:
        try:
            client.storage.from_(SUPABASE_BUCKET).remove([name])
            log.info(f"INFO | [CLEANUP] Supabase storage cleared for file: {name}")
        except Exception as e:
            log.warning(f"[Supabase] cleanup remove failed for {name}: {e}")
    return orphans


def ig_post(path: str, data: dict) -> dict:
    """POST –∫ Instagram Graph API —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://graph.facebook.com/{IG_GRAPH_VERSION}/{path.lstrip('/')}"
    try:
        resp = requests.post(url, data=data, timeout=IG_TIMEOUT_SECONDS)
        text = (resp.text or "")[:500]
        log.info(f"IG_POST url={url} status={resp.status_code} resp={text}")
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        log.error(f"IG_POST_FAIL url={url} error={e}")
        return {}


def ig_get(path: str, params: dict) -> dict:
    """GET –∫ Instagram Graph API —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://graph.facebook.com/{IG_GRAPH_VERSION}/{path.lstrip('/')}"
    try:
        resp = requests.get(url, params=params, timeout=IG_TIMEOUT_SECONDS)
        text = (resp.text or "")[:500]
        log.info(f"IG_GET url={resp.url} status={resp.status_code} resp={text}")
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        log.error(f"IG_GET_FAIL url={url} error={e}")
        return {}


async def publish_to_instagram(item: dict):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ–¥–∏–∞ –≤ Instagram –ø–æ –ø—É–±–ª–∏—á–Ω–æ–º—É URL –∏–∑ Supabase. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
    if ENABLE_INSTAGRAM != "1":
        return True
    if not IG_USER_ID or not IG_ACCESS_TOKEN:
        log.warning("Instagram disabled: missing IG_USER_ID or IG_ACCESS_TOKEN")
        return True

    media_type = item.get("type")
    if media_type == "text":
        log.info("Instagram skip: text post")
        return True
    
    if media_type not in ("video",):
        log.info(f"Instagram skip: unsupported type {media_type}")
        return True
    
    supabase_url = item.get("supabase_url")
    if not supabase_url:
        log.warning("Instagram skip: no supabase_url")
        return True
    
    caption = item.get("caption") or item.get("text") or ""
    safe_caption = clean_social_text(caption)
    log.info(f"IG_CAPTION len={len(safe_caption)} text={safe_caption[:300]}")

    # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
    if media_type == "photo":
        payload = {
            "image_url": supabase_url,
            "caption": safe_caption,
            "access_token": IG_ACCESS_TOKEN,
        }
    else:
        payload = {
            "media_type": "REELS",
            "video_url": supabase_url,
            "caption": safe_caption,
            "audio_type": "ORIGINAL",
            "access_token": IG_ACCESS_TOKEN,
        }
    
    res = ig_post(f"{IG_USER_ID}/media", payload)
    log.info(f"IG_CREATE_RESP: {res}")
    creation_id = res.get("id")
    if not creation_id:
        log.error(f"IG_CREATE_CONTAINER_FAIL resp={res}")
        return False
    log.info(f"IG_CREATE_CONTAINER_OK creation_id={creation_id}")

    # –î–ª—è –≤–∏–¥–µ–æ –∂–¥—ë–º, –ø–æ–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç—Å—è
    if media_type == "video":
        tries = IG_POLL_MAX_TRIES
        while tries > 0:
            status_res = ig_get(creation_id, {"fields": "status_code", "access_token": IG_ACCESS_TOKEN})
            status_code = status_res.get("status_code")
            log.info(f"IG_STATUS creation_id={creation_id} status_code={status_code} resp={status_res}")
            if status_code == "FINISHED":
                break
            if status_code in ("ERROR", "FAILED", "EXPIRED"):
                # –û–¥–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –ø–æ—Å–ª–µ 30 —Å–µ–∫—É–Ω–¥
                await asyncio.sleep(30)
                status_res_retry = ig_get(creation_id, {"fields": "status_code", "access_token": IG_ACCESS_TOKEN})
                status_code_retry = status_res_retry.get("status_code")
                log.info(f"IG_STATUS_RETRY creation_id={creation_id} status_code={status_code_retry} resp={status_res_retry}")
                if status_code_retry == "FINISHED":
                    break
                log.error(f"IG_STATUS_FAIL creation_id={creation_id} status_code={status_code_retry} - Smart Skip activated")
                return False
            tries -= 1
            await asyncio.sleep(IG_POLL_SECONDS)
        if tries == 0:
            log.warning(f"IG_STATUS_TIMEOUT creation_id={creation_id} after 5 minutes - trying media_publish anyway (Smart Skip improved)")
    
    # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–µ–π, —á—Ç–æ–±—ã Meta —É—Å–ø–µ–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
    time_module.sleep(10)

    # –ü—É–±–ª–∏–∫—É–µ–º
    publish_res = ig_post(f"{IG_USER_ID}/media_publish", {"creation_id": creation_id, "access_token": IG_ACCESS_TOKEN})
    log.info(f"IG_PUBLISH_RESP: {publish_res}")
    media_id = publish_res.get("id")
    if media_id:
        log.info(f"IG_PUBLISH_OK media_id={media_id}")
        item["ig_published"] = True
        ig_mark_published("video")
        return True
    else:
        log.error("IG_PUBLISH_FAIL - Smart Skip activated")
        return False


async def publish_to_instagram_carousel(item: dict, image_urls: list[str]):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–∞—Ä—É—Å–µ–ª–∏ (–∞–ª—å–±–æ–º) –≤ Instagram."""
    if ENABLE_INSTAGRAM != "1":
        return
    if not IG_USER_ID or not IG_ACCESS_TOKEN:
        log.warning("Instagram disabled: missing IG_USER_ID or IG_ACCESS_TOKEN")
        return
    if not image_urls:
        log.warning("Instagram carousel: no images to publish")
        return

    caption = item.get("caption") or item.get("text") or ""
    safe_caption = clean_social_text(caption)

    child_ids = []
    for url in image_urls:
        res = ig_post(
            f"{IG_USER_ID}/media",
            {
                "image_url": url,
                "is_carousel_item": "true",
                "access_token": IG_ACCESS_TOKEN,
            },
        )
        media_id = res.get("id")
        if media_id:
            child_ids.append(media_id)
        else:
            log.error("IG_CAROUSEL_CHILD_FAIL")

    if not child_ids:
        log.error("IG_CAROUSEL_CHILDREN_EMPTY")
        return

    parent_res = ig_post(
        f"{IG_USER_ID}/media",
        {
            "media_type": "CAROUSEL",
            "children": child_ids,
            "caption": safe_caption,
            "access_token": IG_ACCESS_TOKEN,
        },
    )
    creation_id = parent_res.get("id")
    if not creation_id:
        log.error("IG_CAROUSEL_PARENT_FAIL")
        return

    publish_res = ig_post(
        f"{IG_USER_ID}/media_publish",
        {"creation_id": creation_id, "access_token": IG_ACCESS_TOKEN},
    )
    media_id = publish_res.get("id")
    if media_id:
        log.info(f"IG_PUBLISH_CAROUSEL_OK media_id={media_id}")
        item["ig_published"] = True
        ig_mark_published("carousel")
        if ENABLE_FB != "1":
            delete_supabase_files(image_urls)
    else:
        log.error("IG_PUBLISH_CAROUSEL_FAIL")


def fb_post(path: str, data: dict) -> dict:
    """POST –∫ Facebook Graph API (Page) —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://graph.facebook.com/{FB_GRAPH_VERSION}/{path.lstrip('/')}"
    try:
        resp = requests.post(url, data=data, timeout=FB_TIMEOUT_SECONDS)
        text = (resp.text or "")[:500]
        log.info(f"FB_POST url={url} status={resp.status_code} resp={text}")
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        log.error(f"FB_POST_FAIL url={url} error={e}")
        return {}


async def publish_to_facebook(item: dict):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ–¥–∏–∞ –≤ Facebook Page –ø–æ –ø—É–±–ª–∏—á–Ω–æ–º—É URL –∏–∑ Supabase."""
    if ENABLE_FB != "1":
        return
    if not FB_PAGE_ID or not FB_PAGE_TOKEN:
        log.warning("Facebook disabled: missing FB_PAGE_ID or FB_PAGE_TOKEN")
        return

    media_type = item.get("type")
    if media_type == "text":
        log.info("Facebook skip: text post")
        return
    
    if media_type not in ("photo", "video"):
        log.info(f"Facebook skip: unsupported type {media_type}")
        return
    
    supabase_url = item.get("supabase_url")
    if not supabase_url:
        log.warning("Facebook skip: no supabase_url")
        return
    
    caption = item.get("caption") or item.get("text") or ""
    safe_caption = clean_social_text(caption)

    try:
        if media_type == "photo":
            res = fb_post(f"{FB_PAGE_ID}/photos", {
                "url": supabase_url,
                "caption": safe_caption,
                "access_token": FB_PAGE_TOKEN,
            })
            media_id = res.get("id")
            if media_id:
                log.info(f"FB_PUBLISH_PHOTO_OK id={media_id}")
            else:
                log.error("FB_PUBLISH_PHOTO_FAIL")
        else:
            res = fb_post(f"{FB_PAGE_ID}/videos", {
                "file_url": supabase_url,
                "description": safe_caption,
                "access_token": FB_PAGE_TOKEN,
            })
            media_id = res.get("id")
            if media_id:
                log.info(f"FB_PUBLISH_VIDEO_OK id={media_id}")
                item["fb_published"] = True
            else:
                log.error("FB_PUBLISH_VIDEO_FAIL")
    except Exception as e:
        log.error(f"Facebook publish error: {e}")


async def publish_to_facebook_carousel(item: dict, image_urls: list[str]):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞ —Ñ–æ—Ç–æ –∫–∞–∫ –∞–ª—å–±–æ–º/—Å–µ—Ä–∏—è –≤ Facebook Page."""
    if ENABLE_FB != "1":
        return
    if not FB_PAGE_ID or not FB_PAGE_TOKEN:
        log.warning("Facebook disabled: missing FB_PAGE_ID or FB_PAGE_TOKEN")
        return
    if not image_urls:
        log.warning("Facebook carousel: no images to publish")
        return

    caption = item.get("caption") or item.get("text") or ""
    safe_caption = clean_social_text(caption)

    success = False
    for idx, url in enumerate(image_urls):
        res = fb_post(
            f"{FB_PAGE_ID}/photos",
            {
                "url": url,
                "caption": safe_caption if idx == 0 else "",
                "access_token": FB_PAGE_TOKEN,
            },
        )
        media_id = res.get("id")
        if media_id:
            success = True
            log.info(f"FB_PUBLISH_CAROUSEL_PHOTO_OK id={media_id} idx={idx}")
        else:
            log.error(f"FB_PUBLISH_CAROUSEL_PHOTO_FAIL idx={idx}")

    if success:
        item["fb_published"] = True
        delete_supabase_files(image_urls)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
STATS_FILE = Path("daily_stats.json")
DAILY_STATS = {
    "date": None,  # –¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞
    "morning": 0,  # –î–æ –æ–±–µ–¥–∞ (–¥–æ 14:00)
    "afternoon": 0,  # –ü–æ—Å–ª–µ –æ–±–µ–¥–∞ (—Å 14:00)
    "video": 0,
    "photo": 0,
    "text": 0,
    "total": 0,
    "tokens": {
        "prompt_tokens": 0,
        "completion_tokens": 0,
        "total_tokens": 0
    },
    "cost_usd": 0.0
}


def save_queue():
    try:
        with QUEUE_FILE.open("w", encoding="utf-8") as f:
            json.dump(list(POST_QUEUE), f, ensure_ascii=False)
    except Exception as e:
        print("Failed to save queue", e)


def load_queue():
    if not QUEUE_FILE.exists():
        return
    try:
        with QUEUE_FILE.open("r", encoding="utf-8") as f:
            items = json.load(f)
            for it in items:
                POST_QUEUE.append(it)
    except Exception as e:
        print("Failed to load queue", e)


def load_seen():
    if SEEN_FILE.exists():
        try:
            data = json.loads(SEEN_FILE.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                # –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {"hashes": [...], "buffer_message_ids": [...], "file_ids": [...]}
                SEEN_HASHES.update(data.get("hashes", []))
                SEEN_FILE_IDS.update(data.get("file_ids", []))
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ message_id (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if "buffer_message_ids" in data:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ
                    pass
            else:
                # –°—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ —Ö–µ—à–µ–π
                SEEN_HASHES.update(data)
        except Exception:
            pass


def save_seen():
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    data = {
        "hashes": list(SEEN_HASHES),
        "file_ids": list(SEEN_FILE_IDS),
        "buffer_message_ids": []  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    }
    SEEN_FILE.write_text(json.dumps(data), encoding="utf-8")


def load_last_post_time():
    global LAST_POST_TIME
    if LAST_POST_TIME_FILE.exists():
        try:
            data = json.loads(LAST_POST_TIME_FILE.read_text(encoding="utf-8"))
            if isinstance(data, dict) and data.get("last_post_time"):
                LAST_POST_TIME = datetime.fromisoformat(data["last_post_time"])
        except Exception:
            pass


def save_last_post_time():
    if LAST_POST_TIME:
        try:
            LAST_POST_TIME_FILE.write_text(
                json.dumps({"last_post_time": LAST_POST_TIME.isoformat()}),
                encoding="utf-8"
            )
        except Exception as e:
            log.warning(f"Failed to save last_post_time: {e}")


def mark_file_id_seen(file_id: str):
    if not file_id:
        return
    if file_id in SEEN_FILE_IDS:
        return
    SEEN_FILE_IDS.add(file_id)
    save_seen()


def reset_ig_schedule_if_needed():
    today = datetime.now().strftime("%Y-%m-%d")
    if IG_SCHEDULE["date"] != today:
        IG_SCHEDULE["date"] = today
        IG_SCHEDULE["morning_videos"] = 0
        IG_SCHEDULE["afternoon_videos"] = 0
        IG_SCHEDULE["afternoon_carousels"] = 0


def can_ig_publish(media_kind: str) -> bool:
    """
    IG —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ (–û–ë–ù–û–í–õ–ï–ù–û):
    - –¢–æ–ª—å–∫–æ video (Reels)
    - –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∞ –í–°–ï–ì–î–ê (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å TG –∏ FB)
    - –ë–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    """
    if media_kind != "video":
        return False

    reset_ig_schedule_if_needed()
    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∞ –≤—Å–µ–≥–¥–∞ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å TG –∏ FB
    return True


def ig_mark_published(media_kind: str):
    reset_ig_schedule_if_needed()
    if media_kind == "video":
        # –°—á–∏—Ç–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        IG_SCHEDULE["afternoon_videos"] += 1


def load_published_texts():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    global PUBLISHED_TEXTS
    if PUBLISHED_TEXTS_FILE.exists():
        try:
            with PUBLISHED_TEXTS_FILE.open("r", encoding="utf-8") as f:
                PUBLISHED_TEXTS = json.load(f)
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ MAX_PUBLISHED_TEXTS
                if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                    PUBLISHED_TEXTS = PUBLISHED_TEXTS[-MAX_PUBLISHED_TEXTS:]
        except Exception as e:
            log.warning(f"Failed to load published texts: {e}")
            PUBLISHED_TEXTS = []


def save_published_texts():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    try:
        with PUBLISHED_TEXTS_FILE.open("w", encoding="utf-8") as f:
            json.dump(PUBLISHED_TEXTS, f, ensure_ascii=False)
    except Exception as e:
        log.warning(f"Failed to save published texts: {e}")


async def check_similar_content(text: str) -> tuple[bool, float]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç semantic similarity —Å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ—Å—Ç–∞–º–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_similar, similarity_score)"""
    if not openai_client or not text or not PUBLISHED_TEXTS:
        return (False, 0.0)
    
    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –ø–æ—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (—É–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
    recent_texts = PUBLISHED_TEXTS[-20:] if len(PUBLISHED_TEXTS) > 20 else PUBLISHED_TEXTS
    
    if not recent_texts:
        return (False, 0.0)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ OpenAI semantic similarity
        resp = openai_client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—é –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ Telegram-–∫–∞–Ω–∞–ª–µ.\n\n"
                        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –î–£–ë–õ–ò–ö–ê–¢–û–ú —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞.\n\n"
                        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
                        '{"is_similar": true/false, "similarity_score": 0.0-1.0, "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"}\n\n'
                        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: is_similar = true, –µ—Å–ª–∏:\n"
                        "1. –û–î–ò–ù–ê–ö–û–í–ê–Ø –¢–ï–ú–ê/–ò–î–ï–Ø (–¥–∞–∂–µ –µ—Å–ª–∏ —Å–ª–æ–≤–∞ —Ä–∞–∑–Ω—ã–µ):\n"
                        "   - '–∏–∑–±–µ–≥–∞–π —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π' = '–¥–µ—Ä–∂–∏—Å—å –ø–æ–¥–∞–ª—å—à–µ –æ—Ç —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π' = '–Ω–µ –æ–±—â–∞–π—Å—è —Å —Ç–∞–∫–∏–º–∏'\n"
                        "   - '—Å–æ–≤–µ—Ç—ã –ø–æ —É—Å–ø–µ—Ö—É' = '–∫–∞–∫ –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞' = '–ø—Ä–∞–≤–∏–ª–∞ —É—Å–ø–µ—Ö–∞'\n"
                        "   - '–ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –ª—é–¥–µ–π' = '–∫–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø–ª–æ—Ö–∏—Ö –ª—é–¥–µ–π' = '–∏–∑–±–µ–≥–∞–π —ç—Ç–∏—Ö –ª—é–¥–µ–π'\n\n"
                        "2. –û–î–ò–ù–ê–ö–û–í–´–ï –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–´/–ü–†–ò–ú–ï–†–´:\n"
                        "   - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ø–∏—Å–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤/—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n"
                        "   - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã/—Å–∏—Ç—É–∞—Ü–∏–∏\n"
                        "   - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã/—Å–æ–≤–µ—Ç—ã\n\n"
                        "3. –ü–û–•–û–ñ–ò–ô –ü–ï–†–ï–í–û–î –û–î–ù–û–ì–û –ò –¢–û–ì–û –ñ–ï –ò–°–¢–û–ß–ù–ò–ö–ê:\n"
                        "   - –µ—Å–ª–∏ –æ–±–∞ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ —Ä—É—Å—Å–∫–æ–≥–æ –ø–æ—Å—Ç–∞\n"
                        "   - –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è\n\n"
                        "4. similarity_score >= 0.65 (—Å–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)\n\n"
                        "is_similar = false –¢–û–õ–¨–ö–û –µ—Å–ª–∏:\n"
                        "- –†–ê–ó–ù–´–ï —Ç–µ–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ø—Ä–æ —É—Å–ø–µ—Ö' vs '–ø—Ä–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è')\n"
                        "- –†–ê–ó–ù–´–ï —Ñ–∞–∫—Ç—ã/–ø—Ä–∏–º–µ—Ä—ã\n"
                        "- –†–ê–ó–ù–ê–Ø –æ—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è\n"
                        "- similarity_score < 0.65\n\n"
                        "–ü–†–ò–ú–ï–†–´ –î–£–ë–õ–ò–ö–ê–¢–û–í (is_similar = true):\n"
                        "- '–ò–∑–±–µ–≥–∞–π —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π: –æ–Ω–∏ –Ω–µ –¥–µ—Ä–∂–∞—Ç —Å–µ–∫—Ä–µ—Ç—ã' vs '–î–µ—Ä–∂–∏—Å—å –ø–æ–¥–∞–ª—å—à–µ –æ—Ç –ª—é–¥–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–º–µ—é—Ç —Ö—Ä–∞–Ω–∏—Ç—å —Ç–∞–π–Ω—ã'\n"
                        "- '5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –ª—é–¥–µ–π' vs '–ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞: 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤'\n"
                        "- '–°–æ–≤–µ—Ç—ã –ø–æ —É—Å–ø–µ—Ö—É: —Ä–∞–±–æ—Ç–∞–π —É—Å–µ—Ä–¥–Ω–æ' vs '–ö–∞–∫ –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞: —É—Å–µ—Ä–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞'\n\n"
                        "–ü–†–ò–ú–ï–†–´ –ù–ï –î–£–ë–õ–ò–ö–ê–¢–û–í (is_similar = false):\n"
                        "- '–ö–∞–∫ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ–Ω—å–≥–∏' vs '–ö–∞–∫ –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—Ç—É'\n"
                        "- '–ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –ª—é–¥–µ–π' vs '–ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è'\n"
                        "- '–°–æ–≤–µ—Ç—ã –ø–æ –∫–∞—Ä—å–µ—Ä–µ' vs '–°–æ–≤–µ—Ç—ã –ø–æ –∑–¥–æ—Ä–æ–≤—å—é'\n\n"
                        "–ë–£–î–¨ –°–¢–†–û–ì–ò–ú: –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –º–∞–ª–µ–π—à–µ–µ —Å–æ–º–Ω–µ–Ω–∏–µ, —á—Ç–æ —ç—Ç–æ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø–æ—Å—Ç/—Ç–µ–º–∞ ‚Äî –≤–µ—Ä–Ω–∏ is_similar = true."
                    ),
                },
                {
                    "role": "user",
                    "content": f"–ù–æ–≤—ã–π —Ç–µ–∫—Å—Ç:\n{text}\n\n–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10):\n" + "\n---\n".join(recent_texts[:10])
                },
            ],
            response_format={"type": "json_object"},
        )
        
        result = json.loads(resp.choices[0].message.content or "{}")
        similarity_score = float(result.get("similarity_score", 0.0))
        is_similar = result.get("is_similar", False) or similarity_score >= 0.65  # –°–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ —Å 0.75 –¥–æ 0.65
        
        if is_similar:
            log.warning(f"SKIP: semantic duplicate (similarity={similarity_score:.2f}): {result.get('reason', '')}")
        
        return (is_similar, similarity_score)
        
    except Exception as e:
        log.warning(f"Failed to check similar content: {e}")
        return (False, 0.0)


def remove_comment_phrases(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Ñ—Ä–∞–∑—ã –ø—Ä–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return text
    
    import re
    phrases_to_remove = [
        r"–æ—Å—Ç–∞–≤—å—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π[^\n]*",
        r"–Ω–∞–ø–∏—à–∏—Ç–µ –Ω–∏–∂–µ[^\n]*",
        r"—á—Ç–æ –¥—É–º–∞–µ—Ç–µ[^\n]*",
        r"–≤–∞—à–µ –º–Ω–µ–Ω–∏–µ[^\n]*",
        r"–æ–±—Å—É–¥–∏–º[^\n]*",
        r"–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ[^\n]*",
        r"–ø–∏—à–∏—Ç–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö[^\n]*",
        r"fikringiz[^\n]*",
        r"yozing[^\n]*",
        r"muloqot[^\n]*",
    ]
    
    cleaned = text
    for phrase in phrases_to_remove:
        cleaned = re.sub(phrase, "", cleaned, flags=re.IGNORECASE)
    
    return cleaned.strip()


def clean_social_text(text: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏ –∏ –æ–±—Ä–µ–∑–∞–µ—Ç –≤—Å—ë –ø–æ—Å–ª–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π —á–µ—Ä—Ç—ã –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π.
    –¢–µ–ª–µ–≥—Ä–∞–º –æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ‚Äî —ç—Ç–æ—Ç —Ñ–∏–ª—å—Ç—Ä –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ IG/FB.
    """
    if not text:
        return ""
    # –∂—ë—Å—Ç–∫–æ —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ —Å—Ä–∞–∑—É, –¥–æ –¥—Ä—É–≥–∏—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
    cleaned = re.sub(r"qiziqarlidunyo", "", text, flags=re.IGNORECASE)
    cleaned = re.sub(r"\bmain\.py\b", "", cleaned, flags=re.IGNORECASE)
    # —É–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏
    cleaned = re.sub(r"<[^>]+>", "", cleaned)
    # –æ–±—Ä–µ–∑–∞–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é |
    if "|" in cleaned:
        cleaned = cleaned.split("|", 1)[0]
    # —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –æ–±—Ä–µ–∑–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –ø–æ –∫—Ä–∞—è–º
    cleaned = re.sub(r"\s+", " ", cleaned).strip(" \t\r\n.,;:!-|")
    return cleaned.strip()


def ensure_utf8_text(text: str) -> str:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫—É –∫ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π UTF-8, —É–±–∏—Ä–∞—è –±–∏—Ç—ã–µ —Å–∏–º–≤–æ–ª—ã."""
    if text is None:
        return ""
    if isinstance(text, bytes):
        return text.decode("utf-8", errors="ignore")
    try:
        return text.encode("utf-8", errors="ignore").decode("utf-8", errors="ignore")
    except Exception:
        return str(text)


def split_text_for_carousel(text: str, max_chars: int = 700) -> list[str]:
    """–î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è —Å–ª–∞–π–¥–æ–≤, —á—Ç–æ–±—ã –∫–∞–∂–¥–∞—è –±—ã–ª–∞ —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞."""
    chunks = []
    current = []
    total = 0
    # —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    for sent in sentences:
        if not sent:
            continue
        if total + len(sent) > max_chars and current:
            chunks.append(" ".join(current).strip())
            current = [sent]
            total = len(sent)
        else:
            current.append(sent)
            total += len(sent)
    if current:
        chunks.append(" ".join(current).strip())
    return chunks or [text.strip()]


def wrap_lines_to_width(draw: ImageDraw.ImageDraw, text: str, font: ImageFont.FreeTypeFont, max_width: int) -> list[str]:
    """–ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ —Å —É—á—ë—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω—ã."""
    words = text.split()
    lines = []
    line = ""
    for word in words:
        candidate = (line + " " + word).strip()
        if not candidate:
            continue
        bbox = draw.textbbox((0, 0), candidate, font=font)
        width = bbox[2] - bbox[0]
        if width <= max_width:
            line = candidate
        else:
            if line:
                lines.append(line)
            line = word
    if line:
        lines.append(line)
    return lines


def parse_accent_tokens(text: str) -> list[tuple[str, bool]]:
    """–ü–∞—Ä—Å–∏—Ç *–≤—ã–¥–µ–ª–µ–Ω–Ω—ã–µ* —Å–ª–æ–≤–∞: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (token, is_accent)."""
    tokens = []
    parts = text.split("*")
    # –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π —á—ë—Ç–Ω–æ–µ, –∑–Ω–∞—á–∏—Ç –Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –ø–∞—Ä ‚Äî —Ç—Ä–∞–∫—Ç—É–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    if len(parts) < 3:
        return [(text, False)]
    accent = False
    for part in parts:
        if part == "":
            accent = not accent
            continue
        tokens.append((part, accent))
        accent = not accent
    return tokens


def wrap_tokens_to_width(draw: ImageDraw.ImageDraw, tokens: list[tuple[str, bool]], font: ImageFont.FreeTypeFont, max_width: int) -> list[list[tuple[str, bool]]]:
    """–ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ —Å —É—á—ë—Ç–æ–º —à–∏—Ä–∏–Ω—ã –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π."""
    lines: list[list[tuple[str, bool]]] = []
    line: list[tuple[str, bool]] = []

    def measure(line_tokens: list[tuple[str, bool]]) -> float:
        if not line_tokens:
            return 0
        joined = " ".join(t[0] for t in line_tokens)
        bbox = draw.textbbox((0, 0), joined, font=font)
        return bbox[2] - bbox[0]

    for tok in tokens:
        if not line:
            line.append(tok)
            if measure(line) > max_width and len(tok[0]) > 0:
                lines.append(line)
                line = []
            continue
        candidate = line + [tok]
        if measure(candidate) <= max_width:
            line.append(tok)
        else:
            lines.append(line)
            line = [tok]
    if line:
        lines.append(line)
    return lines


def create_carousel_images(text: str) -> list[str]:
    """
    –°–æ–∑–¥–∞—ë—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –∫–∞—Ä—É—Å–µ–ª–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –≤—Ä–µ–º–µ–Ω–Ω—ã–º PNG-—Ñ–∞–π–ª–∞–º.
    """
    base_dir = Path("D:/Project/Auto Telegramm")
    backgrounds_dir = base_dir / "backgrounds"
    fonts_dir = base_dir / "fonts"
    tmp_dir = Path("tmp_media") / "carousel"
    tmp_dir.mkdir(parents=True, exist_ok=True)

    bg_files = [p for p in backgrounds_dir.glob("*") if p.suffix.lower() in {".jpg", ".jpeg", ".png"}]
    font_files = [p for p in fonts_dir.glob("*.ttf")]
    if not bg_files or not font_files:
        log.error("Carousel assets missing: backgrounds or fonts not found")
        return []

    slides = []
    chunks = split_text_for_carousel(text)

    for idx, chunk in enumerate(chunks, start=1):
        bg_path = random.choice(bg_files)
        font_path = random.choice(font_files)
        img = Image.open(bg_path).convert("RGBA")
        draw = ImageDraw.Draw(img)

        max_text_width = int(img.width * 0.55)  # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞
        max_text_height = int(img.height * 0.8)

        # –ø–æ–¥–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞ (–∫—Ä—É–ø–Ω—ã–π, –Ω–µ –Ω–∏–∂–µ 50)
        font_size = 72
        min_font = 50
        chosen_lines = []
        chosen_font = ImageFont.truetype(str(font_path), font_size)

        while font_size >= min_font:
            font = ImageFont.truetype(str(font_path), font_size)
            lines = wrap_lines_to_width(draw, chunk, font, max_text_width)
            text_block = "\n".join(lines)
            bbox = draw.multiline_textbbox((0, 0), text_block, font=font, align="center")
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]

            if text_w <= max_text_width and text_h <= max_text_height and len(lines) <= 18:
                chosen_lines = lines
                chosen_font = font
                break
            font_size -= 2

        # –µ—Å–ª–∏ –Ω–µ —É–ª–æ–∂–∏–ª–∏—Å—å, –∂—ë—Å—Ç–∫–æ —Ä–µ–∂–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ 18
        if not chosen_lines:
            lines = wrap_lines_to_width(draw, chunk, chosen_font, max_text_width)
            chosen_lines = lines[:18]

        final_text = "\n".join(chosen_lines)
        bbox = draw.multiline_textbbox((0, 0), final_text, font=chosen_font, align="center")
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]
        x = (img.width - text_w) / 2
        y = (img.height - text_h) / 2

        # —Ç–µ–Ω—å
        shadow_offset = 2
        draw.multiline_text(
            (x + shadow_offset, y + shadow_offset),
            final_text,
            font=chosen_font,
            fill="black",
            align="center",
        )
        # –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        draw.multiline_text(
            (x, y),
            final_text,
            font=chosen_font,
            fill="white",
            align="center",
        )

        out_path = tmp_dir / f"carousel_{uuid.uuid4().hex}.png"
        img.save(out_path, format="PNG")
        log.info(f"[PILLOW] –°–ª–∞–π–¥ ‚Ññ{idx} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        slides.append(str(out_path))

    return slides


def summarize_for_image(text: str) -> str:
    """–ö—Ä–∞—Ç–∫–æ–µ –∏ —ë–º–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–ª–∞–π–¥–∞ (—É–∑–±–µ–∫—Å–∫–∏–π, –∫–æ—Ä–æ—Ç–∫–æ)."""
    txt = (text or "").strip()
    if not txt:
        return ""
    if len(txt) <= 260:
        return txt
    if not openai_client:
        return txt[:260]


def append_history(social: str, media_type: str, url: str, cost: float):
    """–ü–∏—à–µ—Ç —Å—Ç—Ä–æ–∫—É –∏—Å—Ç–æ—Ä–∏–∏ –≤ history.log"""
    try:
        ts = datetime.now().strftime("%d.%m.%Y %H:%M")
        line = f"[{ts}] | –°–æ—Ü—Å–µ—Ç—å: {social} | –¢–∏–ø: {media_type} | –°—Å—ã–ª–∫–∞: {url or '-'} | –¶–µ–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: ${cost:.4f}\n"
        with HISTORY_LOG.open("a", encoding="utf-8") as f:
            f.write(line)
    except Exception as e:
        log.warning(f"Failed to append history: {e}")


def send_admin_error(error_message: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É –∞–¥–º–∏–Ω—É –≤ Telegram (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —á–µ—Ä–µ–∑ Telegram Bot API)."""
    if not ADMIN_TELEGRAM_ID:
        return
    try:
        ts = datetime.now().strftime("%d.%m.%Y %H:%M")
        payload = {
            "chat_id": ADMIN_TELEGRAM_ID,
            "text": f"[ERROR {ts}]\n{error_message}",
        }
        requests.post(f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage", data=payload, timeout=10)
    except Exception as e:
        log.warning(f"Failed to notify admin: {e}")


def send_report_message(text: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–Ω–µ–≤–Ω–æ–π –æ—Ç—á—ë—Ç –≤ REPORT_CHAT_ID."""
    chat_id = REPORT_CHAT_ID or ADMIN_TELEGRAM_ID
    if not chat_id:
        return
    try:
        requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
            data={"chat_id": chat_id, "text": text},
            timeout=15,
        )
    except Exception as e:
        log.warning(f"Failed to send report message: {e}")


def rotate_history_log():
    """–ö–æ–ø–∏—Ä—É–µ—Ç history.log –≤ reports/report_YYYY_MM_DD.log –∏ –æ—á–∏—â–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥."""
    try:
        if not HISTORY_LOG.exists():
            return
        REPORTS_DIR.mkdir(exist_ok=True)
        today = datetime.now().strftime("%Y_%m_%d")
        target = REPORTS_DIR / f"report_{today}.log"
        target.write_text(HISTORY_LOG.read_text(encoding="utf-8"), encoding="utf-8")
        HISTORY_LOG.write_text("", encoding="utf-8")
        log.info(f"History rotated to {target}")
    except Exception as e:
        log.warning(f"Failed to rotate history log: {e}")


def create_single_art_image(text: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ PNG —Ñ–∞–π–ª—É.
    """
    base_dir = Path("D:/Project/Auto Telegramm")
    backgrounds_dir = base_dir / "backgrounds"
    fonts_dir = base_dir / "fonts"
    tmp_dir = Path("tmp_media") / "single_art"
    tmp_dir.mkdir(parents=True, exist_ok=True)

    bg_files = [p for p in backgrounds_dir.glob("*") if p.suffix.lower() in {".jpg", ".jpeg", ".png"}]
    font_files = [p for p in fonts_dir.glob("*.ttf")]
    if not bg_files or not font_files:
        log.error("Single art assets missing: backgrounds or fonts not found")
        return ""

    bg_path = random.choice(bg_files)
    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ Bold-—à—Ä–∏—Ñ—Ç
    bold_fonts = [p for p in font_files if "bold" in p.name.lower()]
    font_path = bold_fonts[0] if bold_fonts else font_files[0]

    img = Image.open(bg_path).convert("RGBA")
    draw = ImageDraw.Draw(img)

    # –û—á–∏—Å—Ç–∫–∞ HTML –∏ —É–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    plain = re.sub(r"<[^>]+>", "", text or "")
    summary = summarize_for_image(plain).upper()

    max_text_width = int(img.width * 0.45)  # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –±–ª–æ–∫ ~45%
    max_text_height = int(img.height * 0.8)

    font_size = 140
    min_font = 100
    chosen_lines = []
    chosen_font = ImageFont.truetype(str(font_path), font_size)
    tokens = parse_accent_tokens(summary)

    def measure_lines(lines_tokens: list[list[tuple[str, bool]]], font: ImageFont.FreeTypeFont) -> tuple[float, float, list[float], list[float]]:
        spacing_px_inner = int(font.size * 0.6)
        line_heights_inner = []
        line_widths_inner = []
        for line in lines_tokens:
            text_line = " ".join(t[0] for t in line)
            bbox = draw.textbbox((0, 0), text_line, font=font)
            line_widths_inner.append(bbox[2] - bbox[0])
            line_heights_inner.append(bbox[3] - bbox[1])
        total_h_inner = sum(line_heights_inner) + spacing_px_inner * (len(lines_tokens) - 1 if lines_tokens else 0)
        max_w_inner = max(line_widths_inner) if line_widths_inner else 0
        return max_w_inner, total_h_inner, line_widths_inner, line_heights_inner

    while font_size >= min_font:
        font = ImageFont.truetype(str(font_path), font_size)
        lines_tokens = wrap_tokens_to_width(draw, tokens, font, max_text_width)
        max_w, total_h, line_widths, line_heights = measure_lines(lines_tokens, font)

        if max_w <= max_text_width and total_h <= max_text_height and len(lines_tokens) <= 12:
            chosen_lines = lines_tokens
            chosen_font = font
            chosen_line_widths = line_widths
            chosen_line_heights = line_heights
            break
        font_size -= 2

    if not chosen_lines:
        lines_tokens = wrap_tokens_to_width(draw, tokens, chosen_font, max_text_width)
        chosen_lines = lines_tokens[:12]
        max_w, total_h, chosen_line_widths, chosen_line_heights = measure_lines(chosen_lines, chosen_font)
    else:
        max_w, total_h = max(chosen_line_widths), sum(chosen_line_heights) + int(chosen_font.size * 0.6) * (len(chosen_lines) - 1 if chosen_lines else 0)

    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ –≤–ª–µ–∑–∞–µ—Ç ‚Äî —É–º–µ–Ω—å—à–∞–µ–º —à—Ä–∏—Ñ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
    reduce_steps = 0
    while (max_w > max_text_width or total_h > max_text_height) and chosen_font.size > min_font:
        new_size = max(min_font, int(chosen_font.size * 0.9))
        chosen_font = ImageFont.truetype(str(font_path), new_size)
        chosen_lines = wrap_tokens_to_width(draw, tokens, chosen_font, max_text_width)[:12]
        max_w, total_h, chosen_line_widths, chosen_line_heights = measure_lines(chosen_lines, chosen_font)
        reduce_steps += 1
        if reduce_steps > 10:
            break

    spacing_px = int(chosen_font.size * 0.6)
    x_start = (img.width - max_w) / 2
    y_start = (img.height - total_h) / 2

    # –õ—ë–≥–∫–æ–µ –∑–∞—Ç–µ–º–Ω–µ–Ω–∏–µ –ø–æ–¥ —Ç–µ–∫—Å—Ç –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ (50%)
    overlay = Image.new("RGBA", img.size, (0, 0, 0, int(255 * 0.50)))
    img = Image.alpha_composite(img, overlay)
    draw = ImageDraw.Draw(img)

    accent_color = "#D4AF37"  # –∑–æ–ª–æ—Ç–∏—Å—Ç–æ-–±–µ–∂–µ–≤—ã–π

    y = y_start
    for line_idx, line in enumerate(chosen_lines):
        text_line = " ".join(t[0] for t in line)
        line_bbox = draw.textbbox((0, 0), text_line, font=chosen_font)
        line_width = line_bbox[2] - line_bbox[0]
        x = (img.width - line_width) / 2

        cursor_x = x
        for i, (tok, is_accent) in enumerate(line):
            fill_color = accent_color if is_accent else "white"
            tok_bbox = draw.textbbox((0, 0), tok, font=chosen_font)
            tok_width = tok_bbox[2] - tok_bbox[0]
            space_bbox = draw.textbbox((0, 0), " ", font=chosen_font)
            space_w = space_bbox[2] - space_bbox[0]
            draw.text(
                (cursor_x, y),
                tok,
                font=chosen_font,
                fill=fill_color,
                stroke_width=5,
                stroke_fill="black",
            )
            cursor_x += tok_width
            if i != len(line) - 1:
                cursor_x += space_w

        y += line_heights[line_idx]
        if line_idx != len(chosen_lines) - 1:
            y += spacing_px

    out_path = tmp_dir / f"single_art_{uuid.uuid4().hex}.png"
    img.save(out_path, format="PNG")
    log.info("[PILLOW] Single art post created successfully")
    return str(out_path)


def _rounded_mask(size: tuple[int, int], radius: int) -> np.ndarray:
    """–°–æ–∑–¥–∞–µ—Ç –º–∞—Å–∫—É —Å –∑–∞–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏ (0..1)."""
    w, h = size
    mask_img = Image.new("L", (w, h), 0)
    draw = ImageDraw.Draw(mask_img)
    draw.rounded_rectangle([(0, 0), (w, h)], radius=radius, fill=255)
    arr = np.array(mask_img).astype("float32") / 255.0
    return arr


def _render_caption_image(text: str, width: int = 1080, height: int = 200) -> Path | None:
    """–†–µ–Ω–¥–µ—Ä–∏—Ç —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ PNG –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å."""
    if not text:
        return None
    try:
        tmp_dir = Path("tmp_media") / "captions"
        tmp_dir.mkdir(parents=True, exist_ok=True)
        img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        font = ImageFont.load_default()
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
        first_line = text.splitlines()[0].strip()
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(first_line) > 80:
            first_line = first_line[:80] + "..."
        bbox = draw.textbbox((0, 0), first_line, font=font)
        tw = bbox[2] - bbox[0]
        th = bbox[3] - bbox[1]
        pos = ((width - tw) // 2, (height - th) // 2)
        draw.text(pos, first_line, font=font, fill=(255, 215, 0, 255))
        out_path = tmp_dir / f"caption_{uuid.uuid4().hex}.png"
        img.save(out_path, "PNG")
        return out_path
    except Exception as e:
        log.warning(f"Caption render failed: {e}")
        return None


def process_video(local_path: Path, caption: str | None = None, speed_multiplier: float = 1.01, bg_color_override: tuple | None = None, brightness_adjust: float = 0.0, random_crop: bool = False, voiceover_path: str | None = None, source: str | None = None) -> Path | None:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –≤–∏–¥–µ–æ –≤ —Å—Ç–∏–ª–µ Reels:
    - –ö–∞–Ω–≤–∞—Å 1080x1920 —Ç—ë–º–Ω—ã–π
    - –í–∏–¥–µ–æ ~80% —à–∏—Ä–∏–Ω—ã, –ø–æ —Ü–µ–Ω—Ç—Ä—É, —Å–∫—Ä—É–≥–ª—ë–Ω–Ω—ã–µ —É–≥–ª—ã
    - –õ–æ–≥–æ—Ç–∏–ø –ø–æ–≤–µ—Ä—Ö
    - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ caption
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è "–ü–ª–∞–Ω–∞ –ë":
    - speed_multiplier: –º–Ω–æ–∂–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ (1.01, 1.02, 1.03)
    - bg_color_override: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ü–≤–µ—Ç —Ñ–æ–Ω–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
    - brightness_adjust: –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏ (0.0 –¥–æ 0.03)
    - random_crop: —Å–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ 5-15px —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    # === IRONCLAD CONFIGURATION: DO NOT ALTER ===
    # BITRATE: 5000k (Strict limit for Supabase)
    # PRESET: slow (High quality encoding)
    # CRF: 19 (Optimal quality/size balance)
    # STITCHES: Checked for duration (No crashes)
    # AUDIO: Pro processing Pitch 0.2 / Tempo 0.5
    # ============================================
    try:
        header_path = (Path(__file__).parent / "header.gif").resolve()
        clip = VideoFileClip(str(local_path))
        duration = clip.duration
        
        # –ü–õ–ê–ù –ë: –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ (Random Crop) –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
        if random_crop:
            original_w, original_h = clip.w, clip.h
            crop_pixels = random.randint(5, 15)
            
            # –û–±—Ä–µ–∑–∞–µ–º —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω
            x1 = crop_pixels
            y1 = crop_pixels
            x2 = original_w - crop_pixels
            y2 = original_h - crop_pixels
            
            clip = clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)
            # –†–∞—Å—Ç—è–≥–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            clip = clip.resize((original_w, original_h))
            log.info(f"[PLAN B] Random crop applied: {crop_pixels}px from each side, resized back to {original_w}x{original_h}")

        canvas_size = (1080, 1920)
        dark_palette = [
            (0, 0, 0),
            (10, 10, 20),
            (20, 20, 30),
            (12, 8, 24),
            (6, 12, 18),
        ]
        bg_color = bg_color_override if bg_color_override is not None else random.choice(dark_palette)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if bg_color_override is not None or speed_multiplier > 1.01 or brightness_adjust != 0.0:
            log.info(f"[PLAN B] Video processing with unique parameters: speed={speed_multiplier:.3f}, bg={bg_color}, brightness={brightness_adjust:+.3f}")
        
        # –ü–õ–ê–ù –ë: –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ (Random Crop) –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
        if brightness_adjust != 0.0:
            crop_pixels = random.randint(5, 15)
            original_w, original_h = clip.w, clip.h
            
            # –û–±—Ä–µ–∑–∞–µ–º —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω
            x1 = crop_pixels
            y1 = crop_pixels
            x2 = original_w - crop_pixels
            y2 = original_h - crop_pixels
            
            clip = clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)
            log.info(f"[PLAN B] Random crop applied: {crop_pixels}px from each side ({original_w}x{original_h} -> {clip.w}x{clip.h})")
        
        # –ó–æ–ª–æ—Ç–æ–π —à–∞–±–ª–æ–Ω: –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø–æ–ª—è —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω (10% margin)
        margin = 0.10
        target_w = int(canvas_size[0] * (1 - margin))
        target_h = int(canvas_size[1] * (1 - margin))
        scale = min(target_w / clip.w, target_h / clip.h)
        new_w = int(clip.w * scale)
        new_h = int(clip.h * scale)
        log.info(f"[DEBUG] Golden Template: Resizing video to {new_w}x{new_h} on canvas {canvas_size} with equal margins")

        # –ü–æ—Å–ª–µ crop –≤–∏–¥–µ–æ —Ä–µ—Å–∞–π–∑–∏—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–æ –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è 1080x1920 –∫–∞–Ω–≤–∞—Å–∞
        clip = clip.resize(width=new_w, height=new_h)
        clip = clip.fx(vfx.speedx, speed_multiplier)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —è—Ä–∫–æ—Å—Ç–∏ (–ü–ª–∞–Ω –ë)
        if brightness_adjust != 0.0:
            clip = clip.fx(vfx.colorx, 1.0 + brightness_adjust)
            log.info(f"[PLAN B] Brightness adjusted: {brightness_adjust:+.3f}")
        
        # SMART SLICER & ZOOM: –ù–∞—Ä–µ–∑–∫–∞ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã —Å Crossfade –∏ –ª–µ–≥–∫–∏–º –∑—É–º–æ–º (–∑–∞–º–µ–Ω–∞ —à—É–º–∞)
        if brightness_adjust != 0.0 or speed_multiplier > 1.01 or random_crop:
            try:
                segment_duration = random.uniform(3.5, 4.0)  # –î–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
                fade_duration = 0.25  # –î–ª–∏–Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
                zoom_factor = 1.03  # –õ–µ–≥–∫–∏–π –∑—É–º –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–π –ø–æ–¥–ø–∏—Å–∏
                
                segments = []
                current_time = 0
                
                while current_time < duration:
                    # –ü–†–û–í–ï–†–ö–ê: end_time –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±–æ–ª—å—à–µ duration
                    end_time = min(current_time + segment_duration, duration)
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Å–µ–≥–º–µ–Ω—Ç –∏–º–µ–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
                    if end_time - current_time < 0.5:
                        break
                    
                    segment = clip.subclip(current_time, end_time)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–µ–≥–∫–∏–π –∑—É–º –∫ –∫–∞–∂–¥–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É
                    segment = segment.resize(zoom_factor)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º fade-in –∏ fade-out –¥–ª—è –ø–ª–∞–≤–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
                    segment_duration_actual = segment.duration
                    if len(segments) > 0 and segment_duration_actual > fade_duration * 2:
                        # Fade-in –¥–ª—è –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                        segment = segment.fadein(fade_duration)
                    
                    if segment_duration_actual > fade_duration * 2:
                        # Fade-out –¥–ª—è –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                        segment = segment.fadeout(fade_duration)
                    
                    segments.append(segment)
                    current_time = end_time
                
                if len(segments) > 1:
                    from moviepy import concatenate
                    clip = concatenate_videoclips(segments, method="compose")
                    log.info(f"[SMART SLICER] Video sliced into {len(segments)} segments with Fade transitions & Zoom 1.03x")
                elif len(segments) == 1:
                    clip = segments[0]
                    log.info(f"[SMART SLICER] Single segment with Zoom 1.03x applied")
            except Exception as e:
                log.warning(f"[SMART SLICER] Failed to apply: {e}, using original clip")

        # MICRO-STITCHES: –ù–µ–≤–∏–¥–∏–º—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 3 —Å–µ–≥–º–µ–Ω—Ç–∞ + —É–¥–∞–ª–µ–Ω–∏–µ 2 –∫–∞–¥—Ä–æ–≤)
        if duration > 3.0:  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∏–¥–µ–æ –¥–ª–∏–Ω–Ω–µ–µ 3 —Å–µ–∫—É–Ω–¥
            try:
                fps = clip.fps or 30
                frame_duration = 1.0 / fps
                
                # Duration Guard: –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ —Å–Ω–∏–∂–∞–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –≤—ã—Ä–µ–∑–æ–≤
                if duration < 10.0:
                    cut_frames = 1  # –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ: —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ 1 –∫–∞–¥—Ä
                    trim_duration = 0.3  # –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ: –æ–±—Ä–µ–∑–∞–µ–º —Ç–æ–ª—å–∫–æ 0.3 —Å–µ–∫
                else:
                    cut_frames = 2  # –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: —É–¥–∞–ª—è–µ–º 2 –∫–∞–¥—Ä–∞
                    trim_duration = 1.5  # –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: –æ–±—Ä–µ–∑–∞–µ–º 1.5 —Å–µ–∫
                
                cut_time = cut_frames * frame_duration
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º 3 —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç–æ—á–∫–∏ —Ä–∞–∑—Ä–µ–∑–∞
                segment_1_end = random.uniform(duration * 0.2, duration * 0.4)
                segment_2_end = random.uniform(duration * 0.6, duration * 0.8)
                
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –Ω–µ –≤—ã—Ö–æ–¥–∏–º –∑–∞ –ø—Ä–µ–¥–µ–ª—ã duration
                seg1_start = 0
                seg1_end = min(segment_1_end - cut_time, duration)
                seg2_start = min(segment_1_end + cut_time, duration)
                seg2_end = min(segment_2_end - cut_time, duration)
                seg3_start = min(segment_2_end + cut_time, duration - 0.1)
                seg3_end = duration
                
                # –°–æ–∑–¥–∞–µ–º 3 —Å–µ–≥–º–µ–Ω—Ç–∞ —Å –º–∏–∫—Ä–æ-–≤—ã—Ä–µ–∑–∞–º–∏ (–µ—Å–ª–∏ seg3 –≤–∞–ª–∏–¥–Ω—ã–π)
                segments = []
                if seg1_end > seg1_start:
                    segments.append(clip.subclip(seg1_start, seg1_end))
                if seg2_end > seg2_start:
                    segments.append(clip.subclip(seg2_start, seg2_end))
                if seg3_start < seg3_end and seg3_start < duration - 0.05:
                    segments.append(clip.subclip(seg3_start, seg3_end))
                
                # –°–∫–ª–µ–∏–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
                if len(segments) > 1:
                    clip = concatenate_videoclips(segments, method="compose")
                else:
                    log.warning("[MICRO-STITCH] Not enough valid segments, skipping stitch")
                
                # Random Trim
                if clip.duration > trim_duration + 1.0:
                    if random.choice([True, False]):
                        # –û—Ç—Ä–µ–∑–∞–µ–º —Å –Ω–∞—á–∞–ª–∞
                        clip = clip.subclip(trim_duration, clip.duration)
                        log.info(f"[MICRO-STITCH] Trimmed {trim_duration}s from start")
                    else:
                        # –û—Ç—Ä–µ–∑–∞–µ–º —Å –∫–æ–Ω—Ü–∞
                        clip = clip.subclip(0, clip.duration - trim_duration)
                        log.info(f"[MICRO-STITCH] Trimmed {trim_duration}s from end")
                
                duration = clip.duration
                log.info(f"[MICRO-STITCH] Applied 3 segments with frame cuts. New duration: {duration:.2f}s")
            except Exception as stitch_err:
                log.warning(f"[MICRO-STITCH] Failed to apply: {stitch_err}, using original clip")

        # –ú–∞—Å–∫–∞ —Å–∫—Ä—É–≥–ª–µ–Ω–Ω—ã—Ö —É–≥–ª–æ–≤
        radius = 45
        mask_arr = _rounded_mask((new_w, new_h), radius)
        mask_clip = ImageClip(mask_arr).set_duration(duration)
        mask_clip.ismask = True  # MoviePy 2.1: —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏
        clip = clip.set_mask(mask_clip)

        layers = []
        canvas_clip = ColorClip(canvas_size, color=bg_color).set_duration(duration)
        layers.append(canvas_clip)
        layers.append(clip.set_position("center"))

        # –õ–æ–≥–æ—Ç–∏–ø –æ—Ç–∫–ª—é—á—ë–Ω –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é

        out_path = Path("tmp_media") / f"proc_{local_path.stem}.mp4"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        final_video = CompositeVideoClip(layers)
        
        # --- –£–ú–ù–´–ô –§–ò–õ–¨–¢–† –ò–°–¢–û–ß–ù–ò–ö–ê ---
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º source –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ñ–∞–π–ª–∞ (fallback)
        if source:
            is_instagram = (source == "instagram")
        else:
            # Fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤—ã–∑–æ–≤–æ–≤
            is_instagram = local_path.name.startswith("instagram_")
        
        log.info(f"[PROCESS_VIDEO] Source: {source or 'detected from filename'}, is_instagram: {is_instagram}")
        
        # 5. –û–∑–≤—É—á–∫–∞ ElevenLabs (–°–ò–°–¢–ï–ú–ê –†–ï–¢–†–ê–ï–í)
        voiceover_audio = None
        original_audio = None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º original_audio –∏–∑ clip.audio, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if clip.audio is not None:
            original_audio = clip.audio
        
        if is_instagram:
            log.info("[SMART ROUTING] Instagram source ‚Üí Full processing (Voice + Music)")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –æ–∑–≤—É—á–∫–∏ –∏–ª–∏ –Ω—É–∂–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
            if voiceover_path and Path(voiceover_path).exists():
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –æ–∑–≤—É—á–∫–∏
                try:
                    voiceover_audio = AudioFileClip(str(voiceover_path))
                    log.info(f"[ELEVENLABS] Using existing voiceover: {Path(voiceover_path).name}")
                except Exception as e:
                    log.warning(f"[ELEVENLABS] Failed to load existing voiceover: {e}")
            elif caption and caption.strip() and ELEVENLABS_API_KEY:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–∑–≤—É—á–∫—É —Å —Ä–µ—Ç—Ä–∞—è–º–∏
                post_id = uuid.uuid4().hex[:8]
                voiceover_filename = f"voiceover_{post_id}.mp3"
                voiceover_path_full = Path("tmp_media") / voiceover_filename
                voiceover_path_full.parent.mkdir(parents=True, exist_ok=True)
                
                # –ë–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–≤–µ—Å—å caption, –Ω–æ —É–±–∏—Ä–∞–µ–º —Ö—ç—à—Ç–µ–≥–∏ –∏ footer)
                # –í–ê–ñ–ù–û: –û–±—ã—á–Ω–æ –æ–∑–≤—É—á–∫–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –î–û –≤—ã–∑–æ–≤–∞ process_video, —ç—Ç–æ fallback
                import re
                text_for_voice = caption or ""
                # –£–±–∏—Ä–∞–µ–º —Ö—ç—à—Ç–µ–≥–∏
                text_for_voice = re.sub(r'#\w+', '', text_for_voice)
                # –£–±–∏—Ä–∞–µ–º footer (—Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞–Ω–∞–ª)
                text_for_voice = re.sub(r'\|.*?\|', '', text_for_voice)
                text_for_voice = re.sub(r'<a.*?</a>', '', text_for_voice)
                text_for_voice = text_for_voice.strip()
                
                if text_for_voice:
                    log.info(f"[ELEVENLABS] Starting voiceover process for: {text_for_voice[:50]}...")
                    
                    try:
                        from elevenlabs.client import ElevenLabs
                        eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
                    except ImportError:
                        log.error("[ELEVENLABS] elevenlabs package not installed")
                        eleven_client = None
                    
                    if eleven_client:
                        for attempt in range(1, 4):  # 3 –ø–æ–ø—ã—Ç–∫–∏
                            try:
                                log.info(f"[ELEVENLABS] Attempt {attempt}/3...")
                                
                                # –ï—Å–ª–∏ —Ñ–∞–π–ª –æ—Å—Ç–∞–ª—Å—è –æ—Ç –ø—Ä–æ—à–ª–æ–π –Ω–µ—É–¥–∞—á–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ ‚Äî —É–¥–∞–ª—è–µ–º
                                if voiceover_path_full.exists():
                                    try: 
                                        voiceover_path_full.unlink()
                                    except: 
                                        pass
                                
                                # --- –ì–ï–ù–ï–†–ê–¶–ò–Ø: –ù–ê–°–¢–†–û–ô–ö–ò "–ñ–ò–í–û–ô –ß–ï–õ–û–í–ï–ö" ---
                                audio_generator = eleven_client.text_to_speech.convert(
                                    voice_id="RlVk06jBShtFu3ub6usx", # –¢–≤–æ–π –∫–ª–æ–Ω
                                    text=text_for_voice,
                                    model_id="eleven_multilingual_v2",
                                    voice_settings={
                                        "stability": 0.35,        # –°–Ω–∏–∂–∞–µ–º –¥–æ 0.35! –ì–æ–ª–æ—Å —Å—Ç–∞–Ω–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–µ–µ –∏ –∂–∏–≤–µ–µ.
                                        "similarity_boost": 0.60, # –°–Ω–∏–∂–∞–µ–º –¥–æ 0.60! –£–π–¥–µ—Ç "–º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏–π" –∑–≤–æ–Ω.
                                        "style": 0.55,            # –î–æ–±–∞–≤–ª—è–µ–º 55% —Å—Ç–∏–ª—è (—ç–∫—Å–ø—Ä–µ—Å—Å–∏—è).
                                        "use_speaker_boost": True
                                    }
                                )
                                # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –ø–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö –≤ –∞—É–¥–∏–æ—Ñ–∞–π–ª
                                audio_data = b"".join(list(audio_generator))
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
                                with open(voiceover_path_full, "wb") as f:
                                    f.write(audio_data)
                                
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –≤ MoviePy
                                temp_audio = AudioFileClip(str(voiceover_path_full))
                                
                                # --- –£–°–ö–û–†–ï–ù–ò–ï –ì–û–õ–û–°–ê –î–õ–Ø –†–ò–õ–°–ê ---
                                # 1.15 –æ–∑–Ω–∞—á–∞–µ—Ç —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ 15%. –ú–æ–∂–Ω–æ —Å—Ç–∞–≤–∏—Ç—å 1.1 –∏–ª–∏ 1.2
                                voiceover_audio = temp_audio.fx(vfx.speedx, 1.15)
                                
                                log.info(f"[ELEVENLABS] Success on attempt {attempt}! Voice speed increased by 15%.")
                                break  # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ ‚Äî –≤—Å—ë –∫—Ä—É—Ç–æ, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ–ø—ã—Ç–æ–∫
                                
                            except Exception as e:
                                log.error(f"[ELEVENLABS] Attempt {attempt} failed: {e}")
                                if attempt < 3:
                                    wait_time = 5 * attempt  # –° –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–æ–π –∂–¥–µ–º –¥–æ–ª—å—à–µ (5—Å, 10—Å)
                                    log.info(f"[ELEVENLABS] Retrying in {wait_time} seconds...")
                                    time_module.sleep(wait_time)
                                else:
                                    log.critical("[ELEVENLABS] All 3 attempts failed. Moving to original audio.")
        else:
            log.info("[SMART ROUTING] Telegram source ‚Üí Template only (No Voiceover)")
            voiceover_audio = None  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∫—É –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        
        # --- –°–ö–õ–ï–ô–ö–ê –ó–í–£–ö–ê (–ì–û–õ–û–° + –§–û–ù–û–í–ê–Ø –ú–£–ó–´–ö–ê) ---
        if voiceover_audio is not None:
            try:
                log.info("[AUDIO] Mixing voiceover with background music")
                
                # 1. –ì–æ–ª–æ—Å (—É–∂–µ —É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π)
                voice_track = voiceover_audio.volumex(1.2) # –ù–µ–º–Ω–æ–≥–æ –ø—Ä–∏–±–∞–≤–∏–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –≥–æ–ª–æ—Å–∞
                
                # --- –í–´–ë–û–† –°–õ–£–ß–ê–ô–ù–û–ì–û –•–ò–¢–ê –ò–ó –ü–ê–ü–ö–ò ASSETS ---
                assets_dir = Path("assets")
                # –ò—â–µ–º –≤—Å–µ mp3 —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
                music_files = list(assets_dir.glob("*.mp3"))
                
                if music_files:
                    random_music_path = random.choice(music_files)
                    log.info(f"[AUDIO] Selected random hit: {random_music_path.name}")
                    
                    # –ì–†–û–ú–ö–û–°–¢–¨ 7% (–ë—ã–ª–æ 15%)
                    bg_music = AudioFileClip(str(random_music_path)).volumex(0.07)
                    
                    # –ó–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –º—É–∑—ã–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –∫–æ—Ä–æ—á–µ –≤–∏–¥–µ–æ
                    video_duration = final_video.duration
                    music_duration = bg_music.duration
                    
                    if music_duration < video_duration:
                        # –í—ã—á–∏—Å–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –Ω—É–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –º—É–∑—ã–∫—É
                        loops_needed = int(video_duration / music_duration) + 1
                        log.info(f"[AUDIO] Music ({music_duration:.2f}s) shorter than video ({video_duration:.2f}s). Looping {loops_needed} times.")
                        
                        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ø–∏–π –º—É–∑—ã–∫–∏ –¥–ª—è –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
                        music_clips = [bg_music] * loops_needed
                        bg_music = concatenate_audioclips(music_clips)
                    
                    # –û–±—Ä–µ–∑–∞–µ–º –º—É–∑—ã–∫—É —Ç–æ—á–Ω–æ –ø–æ–¥ –¥–ª–∏–Ω—É –≤–∏–¥–µ–æ
                    bg_music = bg_music.subclip(0, video_duration)
                    
                    final_audio = CompositeAudioClip([voice_track, bg_music])
                else:
                    log.warning("[AUDIO] No mp3 files found in assets folder. Using voice only.")
                    final_audio = voice_track

                final_video = final_video.set_audio(final_audio)
                
            except Exception as audio_err:
                log.error(f"[AUDIO] Mixing failed: {audio_err}")
                if original_audio is not None:
                    final_video = final_video.set_audio(original_audio)
                else:
                    # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ—Å –±–µ–∑ –º—É–∑—ã–∫–∏
                    try:
                        final_video = final_video.set_audio(voiceover_audio)
                    except:
                        pass
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –æ–∑–≤—É—á–∫–∏ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        if voiceover_path and Path(voiceover_path).exists():
            try:
                Path(voiceover_path).unlink()
                log.info("[ELEVENLABS] Voiceover file cleaned up after applying")
            except Exception as e:
                log.warning(f"[ELEVENLABS] Failed to delete voiceover file: {e}")
        elif 'voiceover_path_full' in locals() and voiceover_path_full.exists():
            try:
                voiceover_path_full.unlink()
                log.info("[ELEVENLABS] Generated voiceover file cleaned up")
            except Exception as e:
                log.warning(f"[ELEVENLABS] Failed to delete generated voiceover file: {e}")
        elif clip.audio is not None:
            try:
                audio_track = clip.audio
                
                # Smart Pitch Shift: -0.2 –¥–æ +0.2 –ø–æ–ª—É—Ç–æ–Ω–∞ (–≤—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º)
                semitones = random.uniform(-0.2, 0.2)
                pitch_factor = 2 ** (semitones / 12)
                original_fps = audio_track.fps or 44100
                new_fps = int(original_fps * pitch_factor)
                
                # –ò–∑–º–µ–Ω—è–µ–º fps –∞—É–¥–∏–æ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∞ pitch shift
                audio_track = audio_track.with_fps(new_fps)
                log.info(f"[PROFESSIONAL_AUDIO] Pitch shifted: {semitones:+.3f} semitones (fps: {original_fps} -> {new_fps})")
                
                # Tempo Shift: ¬±0.5% –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∞—É–¥–∏–æ
                tempo_change = random.uniform(0.995, 1.005)  # 99.5% - 100.5%
                if abs(tempo_change - 1.0) > 0.001:
                    # –ú–µ–Ω—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ speedx
                    audio_track = audio_track.with_effects([vfx.MultiplySpeed(tempo_change)])
                    log.info(f"[PROFESSIONAL_AUDIO] Tempo adjusted: {tempo_change:.4f}x ({(tempo_change-1)*100:+.2f}%)")
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                final_video = final_video.set_audio(audio_track)
                log.info("[PROFESSIONAL_AUDIO] High-quality audio processing applied (NO NOISE)")
            except Exception as audio_err:
                log.warning(f"[PROFESSIONAL_AUDIO] Failed to process audio: {audio_err}, using original audio")
        
        # –†–∞–∑–º—ã—Ç–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤: —Å–æ–∑–¥–∞–µ–º —Ä–∞–∑–º—ã—Ç—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –≤–Ω–∏–∑—É –≤–∏–¥–µ–æ (–≥–¥–µ –æ–±—ã—á–Ω–æ —Å—É–±—Ç–∏—Ç—Ä—ã)
        def add_blur_to_captions(clip):
            # –û–±—Ä–µ–∑–∞–µ–º –∫—É—Å–æ–∫ —Å–Ω–∏–∑—É, —Ä–∞–∑–º—ã–≤–∞–µ–º –µ–≥–æ –∏ –Ω–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
            overlay = clip.crop(y1=int(clip.h*0.8), y2=clip.h).fx(vfx.blur, 20)
            return CompositeVideoClip([clip, overlay.set_position(("center", "bottom"))])
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–∞–∑–º—ã—Ç–∏–µ –∫ –≤–∏–¥–µ–æ
        #final_video = add_blur_to_captions(final_video)
        final_video = final_video.set_duration(final_video.duration - 0.5)
        log.info("[BLUR] Blur applied to bottom 20% of video (captions area)")
        
        final_video.write_videofile(
            str(out_path),
            codec="libx264",
            audio_codec="aac",
            fps=30,
            preset="slow",
            bitrate="6000k",
            ffmpeg_params=[
                "-crf", "18",
                "-pix_fmt", "yuv420p"
            ],
            logger=None,
        )
        
        # --- –û–°–í–û–ë–û–ñ–î–ï–ù–ò–ï –§–ê–ô–õ–û–í –î–õ–Ø WINDOWS (–ó–ê–î–ê–ß–ê ‚Ññ3) ---
        log.info("[CLEANUP] Starting resource release...")
        try:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –≤–∏–¥–µ–æ
            if 'final_video' in locals() and final_video is not None:
                final_video.close()
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ –¥–æ—Ä–æ–∂–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
            if 'audio_track' in locals() and audio_track is not None:
                audio_track.close()
                
            if 'voiceover_audio' in locals() and voiceover_audio is not None:
                voiceover_audio.close()
                
            if 'original_audio' in locals() and original_audio is not None:
                original_audio.close()
                
            log.info("[CLEANUP] All resources released successfully")
        except Exception as cleanup_err:
            log.warning(f"[CLEANUP] Resource release issue: {cleanup_err}")
        # --------------------------------------------------
        
        log.info("INFO | [PROCESS] Video unique processing: Success")
        
        # üîÑ AUTO-COMPRESS: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∂–∞—Ç–∏–µ (SIZE GUARD)
        try:
            file_size_mb = out_path.stat().st_size / (1024 * 1024)
            max_size_mb = 50  # –õ–∏–º–∏—Ç –¥–ª—è Telegram –∏ Instagram
            
            if file_size_mb > max_size_mb:
                log.warning(f"[AUTO-COMPRESS] File too large: {file_size_mb:.2f} MB > {max_size_mb} MB")
                log.info("[AUTO-COMPRESS] Re-encoding with CRF 22 to reduce size...")
                
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–∂–∞—Ç–æ–π –≤–µ—Ä—Å–∏–∏
                compressed_path = out_path.parent / f"compressed_{out_path.name}"
                
                # –ü–ï–†–í–ê–Ø –ü–û–ü–´–¢–ö–ê: CRF 22, bitrate 4000k
                final_video.write_videofile(
                    str(compressed_path),
                    codec="libx264",
                    audio_codec="aac",
                    fps=30,
                    preset="medium",
                    bitrate="4000k",
                    ffmpeg_params=[
                        "-crf", "22",
                        "-pix_fmt", "yuv420p"
                    ],
                    logger=None,
                )
                
                compressed_size_mb = compressed_path.stat().st_size / (1024 * 1024)
                log.info(f"[AUTO-COMPRESS] New size with CRF 22: {compressed_size_mb:.2f} MB (was {file_size_mb:.2f} MB)")
                
                if compressed_size_mb <= max_size_mb:
                    # –£—Å–ø–µ—Ö! –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                    out_path.unlink()
                    compressed_path.rename(out_path)
                    log.info(f"‚úÖ [AUTO-COMPRESS] Success! File compressed to {compressed_size_mb:.2f} MB")
                else:
                    # –í–¢–û–†–ê–Ø –ü–û–ü–´–¢–ö–ê: CRF 24, bitrate 3000k
                    log.warning(f"[AUTO-COMPRESS] Still too large ({compressed_size_mb:.2f} MB), trying CRF 24...")
                    compressed_path.unlink()  # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—É—é –ø–æ–ø—ã—Ç–∫—É
                    
                    final_video.write_videofile(
                        str(compressed_path),
                        codec="libx264",
                        audio_codec="aac",
                        fps=30,
                        preset="medium",
                        bitrate="3000k",
                        ffmpeg_params=[
                            "-crf", "24",
                            "-pix_fmt", "yuv420p"
                        ],
                        logger=None,
                    )
                    
                    final_size_mb = compressed_path.stat().st_size / (1024 * 1024)
                    log.info(f"[AUTO-COMPRESS] Final size with CRF 24: {final_size_mb:.2f} MB")
                    
                    out_path.unlink()
                    compressed_path.rename(out_path)
                    log.info(f"‚úÖ [AUTO-COMPRESS] Compressed with CRF 24 to {final_size_mb:.2f} MB")
            else:
                log.info(f"‚úÖ [SIZE CHECK] File size OK: {file_size_mb:.2f} MB <= {max_size_mb} MB (HD quality preserved)")
        except Exception as compress_err:
            log.error(f"[AUTO-COMPRESS] Failed: {compress_err}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º
        
        # --- –û–°–í–û–ë–û–ñ–î–ï–ù–ò–ï –§–ê–ô–õ–û–í –î–õ–Ø WINDOWS (–®–ê–ì 1 - –§–ò–ù–ê–õ) ---
        try:
            log.info("[CLEANUP] Finalizing resource release...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ—Ç–¥–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏
            if 'final_video' in locals() and final_video is not None:
                try: final_video.close()
                except: pass
                
            if 'clip' in locals() and clip is not None:
                try: clip.close()
                except: pass
                
            if 'audio_track' in locals() and audio_track is not None:
                try: audio_track.close()
                except: pass
                
            if 'voiceover_audio' in locals() and voiceover_audio is not None:
                try: voiceover_audio.close()
                except: pass
                
            if 'original_audio' in locals() and original_audio is not None:
                try: original_audio.close()
                except: pass
                
            log.info("[CLEANUP] Resources released successfully")
        except Exception as cleanup_err:
            log.warning(f"[CLEANUP] Minor issue during release: {cleanup_err}")
        
        return out_path
    except Exception as e:
        log.error(f"Video processing failed, not sending original: {e}")
        try:
            clip.close()
        except Exception:
            pass
        return None


async def prepare_video_for_ready(application, item: dict) -> Path | None:
    """
    –°–ò–°–¢–ï–ú–ê –ö–û–ù–í–ï–ô–ï–†: –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –∑–∞—Ä–∞–Ω–µ–µ —Å —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–µ–π.
    - –°–∫–∞—á–∏–≤–∞–µ—Ç —Å—ã—Ä–æ–µ –≤–∏–¥–µ–æ –∏–∑ Telegram –ò–õ–ò –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Instagram-–∏—Å—Ç–æ—á–Ω–∏–∫
    - –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∏–∫—Ä–æ-–∑—É–º 2%, —Å–ª—É—á–∞–π–Ω—É—é –æ–±—Ä–µ–∑–∫—É, pitch ¬±0.5
    - –°–∂–∏–º–∞–µ—Ç –¥–æ 15-25 –ú–ë (bitrate 2500k)
    - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ ready_to_publish
    - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –≥–æ—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
    """
    try:
        tmp_dir = Path("tmp_media")
        tmp_dir.mkdir(exist_ok=True)
        
        video_file_id = item["file_id"]
        source = item.get("source", "telegram")  # –ò—Å–ø–æ–ª—å–∑—É–µ–º source –∏–∑ item
        is_instagram_source = (source == "instagram")
        
        # ‚úÖ –ü–†–û–í–ï–†–ö–ê: Instagram-–∏—Å—Ç–æ—á–Ω–∏–∫ –∏–ª–∏ Telegram
        if (source == "instagram" or video_file_id == "instagram_source") and item.get("instagram_video_path"):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –∏–∑ Instagram
            instagram_path = Path(item["instagram_video_path"])
            if not instagram_path.exists():
                log.error(f"[CONVEYOR] Instagram video not found: {instagram_path}")
                return None
            local_path = instagram_path
            is_instagram_source = True
            log.info(f"[CONVEYOR] Using Instagram video: {local_path.name}")
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å: —Å–∫–∞—á–∏–≤–∞–µ–º –∏–∑ Telegram
            file_obj = await application.bot.get_file(video_file_id)
            remote_path = getattr(file_obj, "file_path", "") or ""
            suffix = Path(remote_path).suffix or ".mp4"
            local_path = tmp_dir / f"{video_file_id}{suffix}"
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Å—ã—Ä–æ–µ –≤–∏–¥–µ–æ
            await file_obj.download_to_drive(custom_path=str(local_path))
            log.info(f"[CONVEYOR] Downloaded raw video: {local_path.name}")
        
        # –£–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è: –º–∏–∫—Ä–æ-–∑—É–º 2% + —Å–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ + pitch
        caption = item.get("caption", "")
        speed_mult = random.uniform(1.01, 1.03)  # –°–ª—É—á–∞–π–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å 1.01-1.03
        brightness = random.uniform(0.01, 0.03)  # –°–ª—É—á–∞–π–Ω–∞—è —è—Ä–∫–æ—Å—Ç—å
        voiceover_path = item.get("voiceover_path")  # üéôÔ∏è –ü—É—Ç—å –∫ –æ–∑–≤—É—á–∫–µ
        source = item.get("source", "telegram")  # –ò—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ item
        
        processed_path = process_video(
            local_path,
            caption,
            speed_multiplier=speed_mult,
            brightness_adjust=brightness,
            random_crop=True,  # –í—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º crop –¥–ª—è –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
            voiceover_path=voiceover_path,  # üéôÔ∏è –ü–µ—Ä–µ–¥–∞–µ–º –æ–∑–≤—É—á–∫—É
            source=source  # –ü–µ—Ä–µ–¥–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
        )
        
        if not processed_path or not Path(processed_path).exists():
            log.error(f"[CONVEYOR] Video processing failed for {video_file_id}")
            # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –ù–ï Instagram (–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª Telegram)
            if not is_instagram_source and local_path.exists():
                local_path.unlink()
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ready_to_publish —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
        ready_filename = f"ready_{uuid.uuid4().hex[:8]}_{int(time_module.time())}.mp4"
        ready_path = READY_TO_PUBLISH_DIR / ready_filename
        
        shutil.move(str(processed_path), str(ready_path))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (—Ü–µ–ª–µ–≤–æ–π 15-25 –ú–ë)
        file_size_mb = ready_path.stat().st_size / (1024 * 1024)
        log.info(f"[CONVEYOR] Ready video saved: {ready_filename} ({file_size_mb:.2f} MB)")
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if local_path.exists():
            local_path.unlink()
            if is_instagram_source:
                log.info("[CONVEYOR] Instagram source video cleaned up after processing")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (caption, file_id) –≤ JSON —Ä—è–¥–æ–º —Å –≤–∏–¥–µ–æ
        meta_path = ready_path.with_suffix('.json')
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump({
                'caption': caption,
                'original_file_id': video_file_id,
                'instagram_source': item.get('instagram_source'),  # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                'type': item.get('type', 'video'),
                'prepared_at': datetime.now().isoformat()
            }, f, ensure_ascii=False)
        
        return ready_path
        
    except Exception as e:
        error_msg = str(e)
        
        # üö® CRITICAL: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Invalid file_id (–ù–û –ù–ï –¥–ª—è Instagram!)
        if ("Invalid file_id" in error_msg or "file_id" in error_msg.lower()) and item.get('file_id') != "instagram_source":
            log.critical(f"üö® CRITICAL | [CONVEYOR] Skipping broken post due to Invalid file_id: {item.get('file_id', 'unknown')[:20]}")
            return None
        
        log.error(f"[CONVEYOR] prepare_video_for_ready failed: {e}")
        return None


def process_photo(local_path: Path) -> Path | None:
    """–ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç –ª–æ–≥–æ—Ç–∏–ø –Ω–∞ —Ñ–æ—Ç–æ (–Ω–∏–∂–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª, 15% —à–∏—Ä–∏–Ω—ã, –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π)."""
    try:
        img = Image.open(local_path).convert("RGBA")
        dark_palette = [
            (0, 0, 0),
            (10, 10, 20),
            (20, 20, 30),
            (12, 8, 24),
            (6, 12, 18),
        ]
        # –ó–¥–µ—Å—å –ª–æ–≥–æ—Ç–∏–ø —É–±—Ä–∞–Ω; –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª —Å –≤–æ–∑–º–æ–∂–Ω—ã–º –±—É–¥—É—â–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        out_path = local_path
        return out_path
    except Exception as e:
        log.error(f"Photo processing failed (logo): {e}")
        return None


def load_stats():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ñ–∞–π–ª–∞"""
    global DAILY_STATS
    if STATS_FILE.exists():
        try:
            with STATS_FILE.open("r", encoding="utf-8") as f:
                data = json.load(f)
                today = datetime.now().strftime("%Y-%m-%d")
                if data.get("date") == today:
                    DAILY_STATS.update(data)
                else:
                    # –ù–æ–≤—ã–π –¥–µ–Ω—å - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    reset_stats()
        except Exception as e:
            log.warning(f"Failed to load stats: {e}")
            reset_stats()
    else:
        reset_stats()


def save_stats():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Ñ–∞–π–ª"""
    try:
        with STATS_FILE.open("w", encoding="utf-8") as f:
            json.dump(DAILY_STATS, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f"Failed to save stats: {e}")


def reset_stats():
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞ –Ω–æ–≤—ã–π –¥–µ–Ω—å"""
    global DAILY_STATS
    today = datetime.now().strftime("%Y-%m-%d")
    DAILY_STATS = {
        "date": today,
        "morning": 0,
        "afternoon": 0,
        "video": 0,
        "photo": 0,
        "text": 0,
        "total": 0,
        "tokens": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
        },
        "cost_usd": 0.0
    }
    save_stats()


def log_tokens(prompt_tokens: int, completion_tokens: int, total_tokens: int):
    """–õ–æ–≥–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω—ã, –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞."""
    global DAILY_STATS, DAILY_COST_USD, TRANSLATION_LAST_COST
    today = datetime.now().strftime("%Y-%m-%d")
    
    if DAILY_STATS.get("date") != today:
        reset_stats()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á—ë—Ç—á–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
    DAILY_STATS["tokens"]["prompt_tokens"] += prompt_tokens
    DAILY_STATS["tokens"]["completion_tokens"] += completion_tokens
    DAILY_STATS["tokens"]["total_tokens"] += total_tokens
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è gpt-4o-mini
    # input: $0.15/1M, output: $0.60/1M
    input_cost = (prompt_tokens / 1_000_000) * 0.15
    output_cost = (completion_tokens / 1_000_000) * 0.60
    total_cost = input_cost + output_cost
    
    DAILY_STATS["cost_usd"] += total_cost
    DAILY_COST_USD += total_cost
    TRANSLATION_LAST_COST += total_cost
    
    log.info(f"TOKENS USED: prompt={prompt_tokens}, completion={completion_tokens}, total={total_tokens}, cost=${total_cost:.6f}")
    save_stats()
    return total_cost


def increment_stat(post_type: str):
    """–£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—á—ë—Ç—á–∏–∫ –¥–ª—è —Ç–∏–ø–∞ –ø–æ—Å—Ç–∞"""
    global DAILY_STATS
    today = datetime.now().strftime("%Y-%m-%d")
    
    # –ï—Å–ª–∏ –Ω–æ–≤—ã–π –¥–µ–Ω—å - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
    if DAILY_STATS.get("date") != today:
        reset_stats()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
    now = datetime.now()
    if now.hour < 14:
        DAILY_STATS["morning"] += 1
    else:
        DAILY_STATS["afternoon"] += 1
    
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ —Ç–∏–ø–∞
    if post_type in ["video", "photo", "text"]:
        DAILY_STATS[post_type] += 1
    
    DAILY_STATS["total"] += 1
    save_stats()


async def send_daily_report(application):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á—ë—Ç"""
    today = datetime.now().strftime("%Y-%m-%d")
    
    if DAILY_STATS.get("date") != today:
        return
    
    stats = DAILY_STATS
    tokens = stats.get("tokens", {})
    cost = stats.get("cost_usd", 0.0)
    
    report = (
        f"üìä –û—Ç—á—ë—Ç Haqiqat ({today})\n\n"
        f"–î–æ –æ–±–µ–¥–∞: {stats['morning']} –ø–æ—Å—Ç–æ–≤\n"
        f"–ü–æ—Å–ª–µ –æ–±–µ–¥–∞: {stats['afternoon']} –ø–æ—Å—Ç–æ–≤\n"
        f"–í–∏–¥–µ–æ: {stats['video']}\n"
        f"–§–æ—Ç–æ: {stats['photo']}\n"
        f"–¢–µ–∫—Å—Ç: {stats['text']}\n"
        f"–í—Å–µ–≥–æ –∑–∞ –¥–µ–Ω—å: {stats['total']}\n\n"
        f"–¢–æ–∫–µ–Ω—ã:\n"
        f"  Prompt: {tokens.get('prompt_tokens', 0):,}\n"
        f"  Completion: {tokens.get('completion_tokens', 0):,}\n"
        f"  –í—Å–µ–≥–æ: {tokens.get('total_tokens', 0):,}\n\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å: ${cost:.4f}"
    )
    
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á—ë—Ç –∞–¥–º–∏–Ω—É, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –∏–Ω–∞—á–µ –≤ –ª–æ–≥
        if ADMIN_CHAT_ID:
            await application.bot.send_message(
                chat_id=ADMIN_CHAT_ID,
                text=report
            )
            log.info("Daily report sent to admin")
        else:
            log.info(f"Daily report:\n{report}")
    except Exception as e:
        log.error(f"Failed to send daily report: {e}")
        log.info(f"Daily report (fallback):\n{report}")


async def send_progress_report(application):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞"""
    if not (REPORT_AFTER_POST and ADMIN_CHAT_ID):
        return

    stats = DAILY_STATS
    tokens = stats.get("tokens", {})

    report = (
        "‚úÖ –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\n"
        f"–í—Å–µ–≥–æ —Å–µ–≥–æ–¥–Ω—è: {stats.get('total', 0)}\n"
        f"–í–∏–¥–µ–æ: {stats.get('video', 0)}, —Ñ–æ—Ç–æ: {stats.get('photo', 0)}, —Ç–µ–∫—Å—Ç: {stats.get('text', 0)}\n"
        f"–¢–æ–∫–µ–Ω—ã: prompt {tokens.get('prompt_tokens', 0)}, completion {tokens.get('completion_tokens', 0)}\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å (–æ—Ü–µ–Ω–∫–∞): ${stats.get('cost_usd', 0.0):.4f}"
    )

    try:
        await application.bot.send_message(chat_id=ADMIN_CHAT_ID, text=report)
        log.info("Progress report sent to admin")
    except Exception as e:
        log.warning(f"Failed to send progress report: {e}")


async def send_daily_stats(application):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ 23:30 –ø–æ —Å–µ—Ä–≤–µ—Ä–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏."""
    today = datetime.now().strftime("%Y-%m-%d")
    if DAILY_STATS.get("date") != today:
        reset_stats()
    total_posts = DAILY_STATS.get("total", 0)
    cost = DAILY_STATS.get("cost_usd", 0.0)
    report = f"–í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤ —Å–µ–≥–æ–¥–Ω—è: {total_posts}. –ó–∞—Ç—Ä–∞—Ç—ã –Ω–∞ OpenAI: ${cost:.2f}."
    try:
        if ADMIN_CHAT_ID:
            await application.bot.send_message(chat_id=ADMIN_CHAT_ID, text=report)
            log.info("Daily stats sent to admin")
        else:
            log.info(f"Daily stats: {report}")
    except Exception as e:
        log.error(f"Failed to send daily stats: {e}")
        log.info(f"Daily stats (fallback): {report}")


async def daily_report_scheduler(application):
    """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á—ë—Ç–∞"""
    while True:
        now = datetime.now()
        target_time = datetime.combine(now.date(), time(hour=23, minute=30))

        if now >= target_time:
            await send_daily_stats(application)
            target_time = datetime.combine(now.date() + timedelta(days=1), time(hour=23, minute=30))

        wait_seconds = (target_time - datetime.now()).total_seconds()
        await asyncio.sleep(max(wait_seconds, 60))


async def history_log_scheduler():
    """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ history.log –≤ 23:50."""
    while True:
        now = datetime.now()
        target_time = datetime.combine(now.date(), time(hour=23, minute=50))

        if now >= target_time:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç –ø–µ—Ä–µ–¥ —Ä–æ—Ç–∞—Ü–∏–µ–π
            total_posts = DAILY_STATS.get("total", 0)
            cost = DAILY_STATS.get("cost_usd", 0.0)
            report_text = (
                f"üìä Kunlik hisobot\n"
                f"Postlar: {total_posts}\n"
                f"OpenAI xarajatlari: ${cost:.4f}\n"
            )
            send_report_message(report_text)
            rotate_history_log()
            target_time = datetime.combine(now.date() + timedelta(days=1), time(hour=23, minute=50))

        wait_seconds = (target_time - datetime.now()).total_seconds()
        await asyncio.sleep(max(wait_seconds, 60))


def load_ready_files_to_queue():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ –∏–∑ ready_to_publish –≤ POST_QUEUE.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ POST_QUEUE –ø—É—Å—Ç–∞—è, –Ω–æ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã.
    """
    ready_files = sorted(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
    
    if not ready_files:
        return 0
    
    log.info(f"[DEBUG] Queue empty, found {len(ready_files)} ready files on disk. Filling queue...")
    
    loaded_count = 0
    for ready_file in ready_files:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–∂–µ
        meta_file = ready_file.with_suffix(".json")
        if not meta_file.exists():
            log.warning(f"[QUEUE LOADER] Metadata missing for {ready_file.name}, skipping")
            continue
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            meta_data = json.loads(meta_file.read_text(encoding="utf-8"))
            
            # –°–æ–∑–¥–∞–µ–º item –¥–ª—è –æ—á–µ—Ä–µ–¥–∏
            item = {
                "type": "video",
                "file_id": meta_data.get("file_id", "unknown"),
                "caption": meta_data.get("caption", ""),
                "ready_file_path": str(ready_file),
                "ready_metadata": meta_data,
                "from_ready_folder": True  # –§–ª–∞–≥, —á—Ç–æ —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            }
            
            POST_QUEUE.append(item)
            loaded_count += 1
            log.info(f"[QUEUE LOADER] Added {ready_file.name} to queue")
            
        except Exception as e:
            log.error(f"[QUEUE LOADER] Failed to load metadata for {ready_file.name}: {e}")
            continue
    
    if loaded_count > 0:
        save_queue()
        log.info(f"[QUEUE LOADER] Loaded {loaded_count} ready files into queue. Queue size: {len(POST_QUEUE)}")
    
    return loaded_count


async def maintain_ready_posts_worker(application):
    """
    –°–ò–°–¢–ï–ú–ê –ö–û–ù–í–ï–ô–ï–†: –§–æ–Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è 5 –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤.
    - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ ready_to_publish
    - –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 5, –±–µ—Ä–µ—Ç –≤–∏–¥–µ–æ –∏–∑ POST_QUEUE –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç
    - –†–µ–Ω–¥–µ—Ä–∏—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É –∑–∞ —Ä–∞–∑
    """
    global IS_PREPARING
    
    log.info("[CONVEYOR] Maintain ready posts worker started")
    
    while True:
        try:
            # –°—á–∏—Ç–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ (—Ç–æ–ª—å–∫–æ .mp4 —Ñ–∞–π–ª—ã)
            ready_files = list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
            ready_count = len(ready_files)
            
            # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏
            if ready_count < TARGET_READY_POSTS and POST_QUEUE and not IS_PREPARING:
                IS_PREPARING = True
                log.info(f"[CONVEYOR] Ready posts: {ready_count}/{TARGET_READY_POSTS}. Preparing new video...")
                
                # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ –≤–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏ (—Ç–æ–ª—å–∫–æ –°–´–†–´–ï, –Ω–µ –≥–æ—Ç–æ–≤—ã–µ)
                video_item = None
                for idx, item in enumerate(POST_QUEUE):
                    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Å—ã—Ä—ã–µ –≤–∏–¥–µ–æ (–Ω–µ –∏–∑ ready_to_publish)
                    if item.get("type") == "video" and not item.get("from_ready_folder", False):
                        video_item = item
                        # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                        POST_QUEUE.remove(item)
                        save_queue()
                        log.info(f"[CONVEYOR] Took RAW video from queue position {idx}, queue size: {len(POST_QUEUE)}")
                        break
                
                if video_item:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
                    ready_path = await prepare_video_for_ready(application, video_item)
                    
                    if ready_path:
                        log.info(f"[CONVEYOR] Successfully prepared: {ready_path.name}")
                        # –£–¥–∞–ª—è–µ–º –∏–∑ –±—É—Ñ–µ—Ä–∞
                        try:
                            await delete_from_buffer(application, video_item)
                        except Exception as e:
                            log.warning(f"[CONVEYOR] Failed to delete from buffer: {e}")
                    else:
                        # –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å - prepare_video_for_ready –≤–µ—Ä–Ω—É–ª–∞ None –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏
                        log.critical(f"üö® CRITICAL | [CONVEYOR] Failed to prepare video, SKIPPING (not returning to queue)")
                        # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –∏–∑ –±—É—Ñ–µ—Ä–∞
                        try:
                            await delete_from_buffer(application, video_item)
                        except Exception as e:
                            log.warning(f"[CONVEYOR] Failed to delete from buffer: {e}")
                
                IS_PREPARING = False
                
            elif ready_count >= TARGET_READY_POSTS:
                log.info(f"[CONVEYOR] Ready posts: {ready_count}/{TARGET_READY_POSTS}. Target reached.")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            await asyncio.sleep(30)
            
        except Exception as e:
            log.error(f"[CONVEYOR] maintain_ready_posts_worker error: {e}")
            IS_PREPARING = False
            await asyncio.sleep(60)


def post_hash(item: dict) -> str:
    base = item.get("type", "")
    if item["type"] == "text":
        base += item.get("text", "")
    else:
        base += item.get("file_id", "") + (item.get("caption") or "")

    return hashlib.sha256(base.encode("utf-8")).hexdigest()


def clean_text_before_translation(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ —Ö–≤–æ—Å—Ç—ã (–Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤, –ø–æ–¥–ø–∏—Å–∏) –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º"""
    if not text:
        return text
    
    import re
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ö–≤–æ—Å—Ç–æ–≤
    patterns_to_remove = [
        r"–¶–µ—Ä–µ–±—Ä–∞[^\n]*",
        r"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å[^\n]*",
        r"–ü–æ–¥–ø–∏—Å–∫–∞[^\n]*",
        r"–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è[^\n]*",
        r"–ö–∞–Ω–∞–ª[^\n]*",
        r"@[a-zA-Z0-9_]+",  # –£–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤
        r"https?://[^\s]+",  # –°—Å—ã–ª–∫–∏
        r"t\.me/[^\s]+",  # Telegram —Å—Å—ã–ª–∫–∏
        r"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è[^\n]*",
        r"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å –Ω–∞[^\n]*",
        r"–ü–æ–¥–ø–∏—à–∏—Å—å[^\n]*",
        r"–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞[^\n]*",
    ]
    
    cleaned = text
    for pattern in patterns_to_remove:
        cleaned = re.sub(pattern, "", cleaned, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –º—ã—Å–ª–∏ (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
    lines = cleaned.split('\n')
    seen_lines = set()
    unique_lines = []
    for line in lines:
        line_stripped = line.strip().lower()
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ
        if len(line_stripped) < 10:
            unique_lines.append(line)
            continue
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç—å (–µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —É–∂–µ –±—ã–ª–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
        if line_stripped not in seen_lines:
            seen_lines.add(line_stripped)
            unique_lines.append(line)
    
    return '\n'.join(unique_lines).strip()


# ==================== STATE MANAGEMENT (post_counter + CTA) ====================

STATE_FILE = Path("state.json")

def load_state() -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ state.json"""
    if STATE_FILE.exists():
        try:
            with STATE_FILE.open("r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            log.warning(f"Failed to load state: {e}, using defaults")
    return {"post_counter": 0}


def save_state(state: dict) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ state.json"""
    try:
        with STATE_FILE.open("w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.error(f"Failed to save state: {e}")


def next_post_cta_rule() -> tuple[bool, Optional[str], int]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å CTA –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ—Å—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (use_cta, cta_text, post_counter)
    CTA –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 2 –ø–æ—Å—Ç–∞ (post_counter % 2 == 0).
    """
    state = load_state()
    post_counter = state.get("post_counter", 0)
    
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
    post_counter += 1
    state["post_counter"] = post_counter
    save_state(state)
    
    # CTA –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 2 –ø–æ—Å—Ç–∞ (–Ω–∞ 2, 4, 6, ...)
    use_cta = (post_counter % 2 == 0)
    
    # –í–∞—Ä–∏–∞–Ω—Ç—ã CTA (—Ç–æ—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏)
    cta_variants = [
        "Biz bilang bo'ling,\nOldinda yana qiziqarlilari bor.",
        "Agar video yoqqan bo'lsa,\nlayk bosish esdan chiqmasin.",
        "video yoqgan bo'lsa,\ntanishlarga jo'natib qo'yamiz"
    ]
    
    cta_text = None
    if use_cta:
        cta_text = random.choice(cta_variants)
        log.info(f"[CTA] Post #{post_counter}: CTA enabled, variant chosen: {cta_text[:30]}...")
    else:
        log.info(f"[CTA] Post #{post_counter}: CTA disabled")
    
    return use_cta, cta_text, post_counter


# ==================== PARSING & BUILDING FUNCTIONS ====================

def parse_model_blocks(text: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –±–ª–æ–∫–∏ VOICE_UZ, CAPTION_UZ, EXTRA_HASHTAGS.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"voice": str, "caption": str, "extra_hashtags": str}
    """
    result = {
        "voice": "",
        "caption": "",
        "extra_hashtags": ""
    }
    
    if not text:
        return result
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º VOICE_UZ
    if "VOICE_UZ:" in text:
        voice_start = text.find("VOICE_UZ:") + len("VOICE_UZ:")
        voice_end = text.find("CAPTION_UZ:", voice_start)
        if voice_end == -1:
            voice_end = text.find("EXTRA_HASHTAGS:", voice_start)
        if voice_end == -1:
            voice_end = len(text)
        result["voice"] = text[voice_start:voice_end].strip()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º CAPTION_UZ
    if "CAPTION_UZ:" in text:
        caption_start = text.find("CAPTION_UZ:") + len("CAPTION_UZ:")
        caption_end = text.find("EXTRA_HASHTAGS:", caption_start)
        if caption_end == -1:
            caption_end = len(text)
        result["caption"] = text[caption_start:caption_end].strip()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º EXTRA_HASHTAGS
    if "EXTRA_HASHTAGS:" in text:
        hashtags_start = text.find("EXTRA_HASHTAGS:") + len("EXTRA_HASHTAGS:")
        hashtags_text = text[hashtags_start:].strip()
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        hashtags_text = hashtags_text.replace("<", "").replace(">", "").strip()
        result["extra_hashtags"] = hashtags_text
    
    # Fallback –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è
    if not result["voice"]:
        lines = text.split('\n')
        result["voice"] = lines[0].strip() if lines else "Qiziqarli video."
    if not result["caption"]:
        result["caption"] = result["voice"]
    
    return result


def build_voice_for_tts(voice_uz: str, cta_text: Optional[str]) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç —Ç–µ–∫—Å—Ç –¥–ª—è TTS –∏–∑ VOICE_UZ + CTA (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ).
    –£–¥–∞–ª—è–µ—Ç —Ö—ç—à—Ç–µ–≥–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—Ä–æ–±–µ–ª—ã.
    """
    if not voice_uz:
        voice_uz = "Qiziqarli video."
    
    # –£–¥–∞–ª—è–µ–º —Ö—ç—à—Ç–µ–≥–∏ –∏–∑ voice
    import re
    voice_uz = re.sub(r'#\w+', '', voice_uz)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã (—É–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
    voice_uz = re.sub(r'\n\s*\n+', '\n', voice_uz).strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º CTA –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if cta_text:
        voice_uz = f"{voice_uz}\n\n{cta_text}"
    
    return voice_uz.strip()


def build_caption_for_post(caption_uz: str, base_hashtags: str, extra_hashtags: str, footer_html: str) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π caption –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.
    –í–∫–ª—é—á–∞–µ—Ç: caption_uz + extra_hashtags + base_hashtags + footer_html
    """
    parts = []
    
    if caption_uz:
        parts.append(caption_uz.strip())
    
    if extra_hashtags:
        parts.append(extra_hashtags.strip())
    
    if base_hashtags:
        parts.append(base_hashtags.strip())
    
    if footer_html:
        parts.append(footer_html.strip())
    
    return '\n'.join(parts)


# ==================== SOURCE DETECTION ====================

def detect_source_from_input(input_str: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ –≤—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (URL –∏–ª–∏ —Ç–µ–∫—Å—Ç).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: "instagram" –∏–ª–∏ "telegram"
    """
    if not input_str:
        return "telegram"
    
    import re
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ Instagram URL
    instagram_pattern = r'https?://(?:www\.)?(?:instagram\.com|instagr\.am)'
    if re.search(instagram_pattern, input_str, re.IGNORECASE):
        return "instagram"
    
    return "telegram"


async def translate_text(caption_ru: str, asr_ru: str, base_hashtags: str) -> dict:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–Ω–æ–º —Å—Ç–∏–ª–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {'voice': str, 'caption': str, 'hashtags': str}
    CTA –ù–ï –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∑–¥–µ—Å—å - —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è –≤ –∫–æ–¥–µ —á–µ—Ä–µ–∑ next_post_cta_rule()
    """
    try:
        # –ü–†–û–ú–ü–¢: –ö–ò–ù–ï–ú–ê–¢–û–ì–†–ê–§–ò–ß–ù–´–ô –°–¢–ò–õ–¨ (–ë–ï–ó CTA)
        system_prompt = (
            "–¢—ã ‚Äî –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∏ SMM-—Ä–µ–¥–∞–∫—Ç–æ—Ä.\n"
            "–ú–æ–π —Å—Ç–∏–ª—å: —Ç—ë–ø–ª—ã–π, —Å–ø–æ–∫–æ–π–Ω—ã–π, —Å–æ–∑–µ—Ä—Ü–∞—Ç–µ–ª—å–Ω—ã–π, –∫–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–Ω—ã–π.\n"
            "–ü–∏—à–µ—à—å –ø—Ä–æ—Å—Ç–æ, –ø–æ —Å—É—Ç–∏, –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ñ—Ä–∞–∑–∞–º–∏, —É–¥–æ–±–Ω–æ –¥–ª—è –æ–∑–≤—É—á–∫–∏.\n\n"
            "–ó–∞–¥–∞—á–∞:\n"
            "–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —É–∑–±–µ–∫—Å–∫—É—é (–ª–∞—Ç–∏–Ω–∏—Ü–∞) –û–ó–í–£–ß–ö–£ –∏ –û–ü–ò–°–ê–ù–ò–ï –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.\n"
            "–í—Å–µ –º–µ–¥–∏–∞—Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –≤—ã—Ö–æ–¥–∏—Ç—å —Å –æ–∑–≤—É—á–∫–æ–π.\n\n"
            "–ù—É–∂–Ω–æ –≤—ã–¥–∞—Ç—å 3 –±–ª–æ–∫–∞:\n"
            "1) VOICE_UZ ‚Äî —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏\n"
            "2) CAPTION_UZ ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ–¥ –ø–æ—Å—Ç\n"
            "3) EXTRA_HASHTAGS ‚Äî 2‚Äì3 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–∞ –ø–æ —Ç–µ–º–µ\n\n"
            "–õ–û–ì–ò–ö–ê:\n"
            "- –ï—Å–ª–∏ ASR_RU –Ω–µ –ø—É—Å—Ç–æ–π ‚Üí –ø–µ—Ä–µ–≤–µ–¥–∏ –µ–≥–æ –≤ VOICE_UZ, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–º—ã—Å–ª –∏ —Ç—ë–ø–ª—ã–π —Ç–æ–Ω.\n"
            "- –ï—Å–ª–∏ ASR_RU –ø—É—Å—Ç–æ–π ‚Üí —Å–æ–∑–¥–∞–π VOICE_UZ –Ω–∞ –æ—Å–Ω–æ–≤–µ CAPTION_RU –∏–ª–∏ —Å–º—ã—Å–ª–∞ —Å—Ü–µ–Ω—ã, –±–µ–∑ –≤—ã–¥—É–º–æ–∫ –∏ –±–µ–∑ –≤–æ–¥—ã.\n"
            "- –ï—Å–ª–∏ CAPTION_RU –ø—É—Å—Ç–æ–π ‚Üí —Å–æ–∑–¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π CAPTION_UZ –Ω–∞ –æ—Å–Ω–æ–≤–µ VOICE_UZ.\n\n"
            "–°–¢–ò–õ–¨ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û):\n"
            "‚Äî —Ç—ë–ø–ª—ã–π, —Å–ø–æ–∫–æ–π–Ω—ã–π\n"
            "‚Äî –æ—â—É—â–µ–Ω–∏–µ –º–æ–º–µ–Ω—Ç–∞\n"
            "‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏\n"
            "‚Äî –±–µ–∑ –≤–æ–¥—ã, –±–µ–∑ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö —Å–ª–æ–≤\n"
            "‚Äî –±–µ–∑ —Å–ª–µ–Ω–≥–∞\n"
            "‚Äî –±–µ–∑ \"SHOK\", \"DAHSHAT\"\n"
            "‚Äî –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è –ø–∞—É–∑—ã\n\n"
            "–í–ê–ñ–ù–û: –ù–ï –¥–æ–±–∞–≤–ª—è–π CTA –≤ VOICE_UZ. CTA –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –æ—Ç–¥–µ–ª—å–Ω–æ –≤ –∫–æ–¥–µ.\n\n"
            "–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:\n"
            "‚Äî VOICE_UZ: 2‚Äì7 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å—Ç—Ä–æ–∫\n"
            "‚Äî VOICE_UZ –ë–ï–ó —Ö—ç—à—Ç–µ–≥–æ–≤\n"
            "‚Äî VOICE_UZ –ë–ï–ó CTA\n"
            "‚Äî CAPTION_UZ: 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n"
            "‚Äî EXTRA_HASHTAGS: —Å—Ç—Ä–æ–≥–æ 2‚Äì3, –ø–æ —Ç–µ–º–µ, –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ BASE_HASHTAGS\n\n"
            "–§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û):\n\n"
            "VOICE_UZ:\n"
            "<—Ç–µ–∫—Å—Ç>\n\n"
            "CAPTION_UZ:\n"
            "<—Ç–µ–∫—Å—Ç>\n\n"
            "EXTRA_HASHTAGS:\n"
            "<#... #... #...>"
        )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        user_content = (
            f"–í–•–û–î:\n"
            f"CAPTION_RU:\n\"\"\" {caption_ru or '(–ø—É—Å—Ç–æ)'} \"\"\"\n\n"
            f"ASR_RU:\n\"\"\" {asr_ru or '(–ø—É—Å—Ç–æ)'} \"\"\"\n\n"
            f"BASE_HASHTAGS:\n\"\"\" {base_hashtags or ''} \"\"\""
        )
        
        # –ó–∞–ø—Ä–æ—Å –∫ AI
        if not openai_client:
            # Fallback –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞
            return {
                'voice': "Qiziqarli video. Oxirigacha ko'ring.",
                'caption': "Qiziqarli video. Oxirigacha ko'ring.",
                'hashtags': ""
            }
        
        response = openai_client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ]
        )
        
        # –ü–ê–†–°–ï–†: –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —Ñ—É–Ω–∫—Ü–∏—é parse_model_blocks
        gpt_response = response.choices[0].message.content or ""
        blocks = parse_model_blocks(gpt_response)
        
        return {
            'voice': blocks['voice'],
            'caption': blocks['caption'],
            'hashtags': blocks['extra_hashtags']
        }
        
    except Exception as e:
        log.error(f"[OPENAI] Translation error: {e}")
        # –ê–≤–∞—Ä–∏–π–Ω—ã–π –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ GPT —Å–ª–æ–º–∞–ª—Å—è
        return {
            'voice': "Qiziqarli video. Oxirigacha ko'ring.",
            'caption': "Qiziqarli video. Oxirigacha ko'ring.",
            'hashtags': ""
        }


# ==================== WHISPER AUDIO-TO-TEXT ====================

def extract_audio_from_video(video_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É –∏–∑ –≤–∏–¥–µ–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π mp3 —Ñ–∞–π–ª.
    
    Args:
        video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
        
    Returns:
        –ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        from moviepy.editor import VideoFileClip
        
        tmp_audio_path = Path("tmp_media") / "whisper_temp.mp3"
        tmp_audio_path.parent.mkdir(exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ
        video = VideoFileClip(str(video_path))
        if video.audio is None:
            log.warning(f"[WHISPER] No audio track in video: {video_path}")
            video.close()
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        video.audio.write_audiofile(
            str(tmp_audio_path),
            codec='mp3',
            bitrate='128k',
            logger=None  # –û—Ç–∫–ª—é—á–∞–µ–º verbose –ª–æ–≥–∏
        )
        video.close()
        
        log.info(f"[WHISPER] Audio extracted: {tmp_audio_path.name} ({tmp_audio_path.stat().st_size / 1024:.1f} KB)")
        return tmp_audio_path
        
    except Exception as e:
        log.error(f"[WHISPER] Audio extraction failed: {e}")
        return None


def get_video_transcript(video_path):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ OpenAI Whisper API.
    
    Args:
        video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
        
    Returns:
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not openai_client:
        log.warning("[WHISPER] OpenAI client not initialized")
        return None
    
    audio_path = None
    try:
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
        audio_path = extract_audio_from_video(video_path)
        if not audio_path or not audio_path.exists():
            log.warning("[WHISPER] Audio extraction failed, skipping transcription")
            return None
        
        # 2. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Whisper API
        log.info("[WHISPER] Sending audio to Whisper API...")
        with open(audio_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"  # –£–∫–∞–∑—ã–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–π –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            )
        
        transcript_text = transcript.text.strip()
        log.info(f"[WHISPER] Transcription received: {len(transcript_text)} chars")
        log.info(f"[WHISPER] Preview: {transcript_text[:100]}...")
        
        return transcript_text
        
    except Exception as e:
        log.error(f"[WHISPER] Transcription failed: {e}")
        return None
        
    finally:
        # 3. Cleanup: –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª
        if audio_path and audio_path.exists():
            try:
                audio_path.unlink()
                log.info("[WHISPER] Temporary audio file deleted")
            except Exception as e:
                log.warning(f"[WHISPER] Failed to delete temp audio: {e}")


# ==================== END WHISPER ====================


# ==================== ELEVENLABS VOICE ====================

def generate_voiceover(text):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–∑–≤—É—á–∫—É —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ ElevenLabs API.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (—É–∑–±–µ–∫—Å–∫–∏–π)
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not ELEVENLABS_API_KEY:
        log.warning("[ELEVENLABS] API key not configured, skipping voiceover")
        return None
    
    try:
        from elevenlabs import VoiceSettings
        from elevenlabs.client import ElevenLabs
        
        client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        
        # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–∑–≤—É—á–∫–∏
        tmp_voiceover_path = Path("tmp_media") / "voiceover.mp3"
        tmp_voiceover_path.parent.mkdir(exist_ok=True)
        
        log.info(f"[ELEVENLABS] Generating voiceover for {len(text)} chars...")
        log.info(f"[ELEVENLABS] Text preview: {text[:100]}...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–∑–≤—É—á–∫—É
        response = client.text_to_speech.convert(
            voice_id=ELEVENLABS_VOICE_ID,
            output_format="mp3_44100_128",
            text=text,
            model_id="eleven_multilingual_v2",
            voice_settings=VoiceSettings(
                stability=0.5,
                similarity_boost=0.75,
                style=0.0,
                use_speaker_boost=True
            )
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ
        with open(tmp_voiceover_path, "wb") as f:
            for chunk in response:
                if chunk:
                    f.write(chunk)
        
        file_size_kb = tmp_voiceover_path.stat().st_size / 1024
        log.info(f"[ELEVENLABS] ‚úÖ Voiceover generated: {tmp_voiceover_path.name} ({file_size_kb:.1f} KB)")
        
        return tmp_voiceover_path
        
    except ImportError:
        log.error("[ELEVENLABS] elevenlabs package not installed. Run: pip install elevenlabs")
        return None
    except Exception as e:
        log.error(f"[ELEVENLABS] Voiceover generation failed: {e}")
        return None


# ==================== END ELEVENLABS ====================


# ==================== SMART INSTAGRAM DOWNLOADER ====================

def download_from_instagram(url):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –∏–∑ Instagram —á–µ—Ä–µ–∑ yt-dlp.
    
    Args:
        url: URL Instagram –ø–æ—Å—Ç–∞/reels
        
    Returns:
        –ü—É—Ç—å –∫ —Å–∫–∞—á–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        import yt_dlp
        
        tmp_dir = Path("tmp_media")
        tmp_dir.mkdir(exist_ok=True)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        import hashlib
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        output_template = str(tmp_dir / f"instagram_{url_hash}.%(ext)s")
        
        ydl_opts = {
            'format': 'best[ext=mp4]/best',
            'outtmpl': output_template,
            'quiet': True,
            'no_warnings': True,
            'extract_flat': False,
        }
        
        log.info(f"[INSTAGRAM] Downloading video from: {url[:50]}...")
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            filename = ydl.prepare_filename(info)
            
        if not Path(filename).exists():
            log.error(f"[INSTAGRAM] Downloaded file not found: {filename}")
            return None
        
        file_size_mb = Path(filename).stat().st_size / (1024 * 1024)
        log.info(f"[INSTAGRAM] ‚úÖ Video downloaded: {Path(filename).name} ({file_size_mb:.1f} MB)")
        
        return Path(filename)
        
    except ImportError:
        log.error("[INSTAGRAM] yt-dlp package not installed. Run: pip install yt-dlp")
        return None
    except Exception as e:
        log.error(f"[INSTAGRAM] Download failed: {e}")
        return None


# ==================== END INSTAGRAM DOWNLOADER ====================


# ==================== MIXED QUEUE 4+4 LOGIC ====================

def get_next_post_from_queue():
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –ø–æ –ª–æ–≥–∏–∫–µ 4+4:
    - 4 –ø–æ—Å—Ç–∞ —Å voiceover: True
    - 4 –ø–æ—Å—Ç–∞ —Å voiceover: False
    - –ï—Å–ª–∏ –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞ –Ω–µ—Ç, –±–µ—Ä—ë—Ç —Ç–æ, —á—Ç–æ –µ—Å—Ç—å
    
    Returns:
        –ü–æ—Å—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –∏–ª–∏ None
    """
    global VOICEOVER_POSTS_COUNT, NO_VOICEOVER_POSTS_COUNT, CURRENT_BLOCK_TYPE
    
    if not POST_QUEUE:
        return None
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π —Ç–∏–ø –ø–æ—Å—Ç–∞ –Ω—É–∂–µ–Ω —Å–µ–π—á–∞—Å
    if CURRENT_BLOCK_TYPE == "voiceover":
        target_voiceover = True
        needed = 4 - VOICEOVER_POSTS_COUNT
    else:
        target_voiceover = False
        needed = 4 - NO_VOICEOVER_POSTS_COUNT
    
    log.info(f"[MIXED QUEUE] Current block: {CURRENT_BLOCK_TYPE}, progress: {VOICEOVER_POSTS_COUNT if CURRENT_BLOCK_TYPE == 'voiceover' else NO_VOICEOVER_POSTS_COUNT}/4")
    
    # –ò—â–µ–º –ø–æ—Å—Ç –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞
    for idx, item in enumerate(POST_QUEUE):
        if item.get("voiceover", False) == target_voiceover:
            # –ù–∞—à–ª–∏ –Ω—É–∂–Ω—ã–π —Ç–∏–ø
            post = POST_QUEUE[idx]
            del POST_QUEUE[idx]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á—ë—Ç—á–∏–∫–∏
            if target_voiceover:
                VOICEOVER_POSTS_COUNT += 1
                log.info(f"[MIXED QUEUE] Selected voiceover post ({VOICEOVER_POSTS_COUNT}/4)")
                if VOICEOVER_POSTS_COUNT >= 4:
                    CURRENT_BLOCK_TYPE = "no_voiceover"
                    VOICEOVER_POSTS_COUNT = 0
                    log.info("[MIXED QUEUE] ‚úÖ Voiceover block complete, switching to no_voiceover")
            else:
                NO_VOICEOVER_POSTS_COUNT += 1
                log.info(f"[MIXED QUEUE] Selected no_voiceover post ({NO_VOICEOVER_POSTS_COUNT}/4)")
                if NO_VOICEOVER_POSTS_COUNT >= 4:
                    CURRENT_BLOCK_TYPE = "voiceover"
                    NO_VOICEOVER_POSTS_COUNT = 0
                    log.info("[MIXED QUEUE] ‚úÖ No_voiceover block complete, switching to voiceover")
            
            return post
    
    # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞ –Ω–µ—Ç, –±–µ—Ä—ë–º —á—Ç–æ –µ—Å—Ç—å
    log.warning(f"[MIXED QUEUE] No {CURRENT_BLOCK_TYPE} posts available, taking any post")
    return POST_QUEUE.popleft()


# ==================== END MIXED QUEUE ====================


SYSTEM_PROMPT_UZ = (
    "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏—Å—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —É–∑–±–µ–∫—Å–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ (SCENARIST MODE). "
    "–í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∏–∑ –≤–∏–¥–µ–æ) –∫–∞–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫. –°–æ–∑–¥–∞–π –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ –≤–æ–≤–ª–µ–∫–∞—é—â–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∞ —É–∑–±–µ–∫—Å–∫–æ–º —è–∑—ã–∫–µ (–ª–∞—Ç–∏–Ω–∏—Ü–∞). "
    "\n"
    "üé£ –ö–†–Æ–ß–û–ö (HOOK) ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û! –ù–∞—á–Ω–∏ —Ç–µ–∫—Å—Ç —Å –æ–¥–Ω–æ–≥–æ –∏–∑ —ç—Ç–∏—Ö –∫—Ä—é—á–∫–æ–≤, –≤—ã–±–µ—Ä–∏ —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∏–¥–µ–æ:\n"
    "1. Siz buni bilarmidingiz... (–ê –≤—ã –∑–Ω–∞–ª–∏...)\n"
    "2. Bunga ishonish qiyin, lekin bu haqiqat... (–¢—Ä—É–¥–Ω–æ –ø–æ–≤–µ—Ä–∏—Ç—å, –Ω–æ —ç—Ç–æ –ø—Ä–∞–≤–¥–∞...)\n"
    "3. Buni ko'pchilikdan yashirishgan! (–≠—Ç–æ —Å–∫—Ä—ã–≤–∞–ª–∏ –æ—Ç –º–Ω–æ–≥–∏—Ö!)\n"
    "4. Oxirigacha ko'ring, natijasi hayratlanarli! (–î–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ –∫–æ–Ω—Ü–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Ä–∞–∑–∏—Ç–µ–ª–µ–Ω!)\n"
    "5. Sizningcha, bu qanday sodir bo'ldi? (–ö–∞–∫ –≤—ã –¥—É–º–∞–µ—Ç–µ, –∫–∞–∫ —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ?)\n"
    "6. Hech kim kutmagan voqea sodir bo'ldi... (–°–ª—É—á–∏–ª–æ—Å—å —Ç–æ, —á–µ–≥–æ –Ω–∏–∫—Ç–æ –Ω–µ –æ–∂–∏–¥–∞–ª...)\n"
    "7. Buni ko'rib hayratda qolasiz! (–í—ã –±—É–¥–µ—Ç–µ –≤ —à–æ–∫–µ, —É–≤–∏–¥–µ–≤ —ç—Ç–æ!)\n"
    "8. Dunyodagi eng g'alati narsalardan biri... (–û–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö —Å—Ç—Ä–∞–Ω–Ω—ã—Ö –≤–µ—â–µ–π –≤ –º–∏—Ä–µ...)\n"
    "9. Siz buni o'z ko'zingiz bilan ko'rishingiz kerak! (–í—ã –¥–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å —ç—Ç–æ —Å–≤–æ–∏–º–∏ –≥–ª–∞–∑–∞–º–∏!)\n"
    "\n"
    "–ê–¥–∞–ø—Ç–∏—Ä—É–π –∫—Ä—é—á–æ–∫ –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —É–¥–µ—Ä–∂–∞–Ω–∏—è –≤ –ø–µ—Ä–≤—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã. "
    "–°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª –æ—Ä–∏–≥–∏–Ω–∞–ª–∞, –Ω–æ –∞–¥–∞–ø—Ç–∏—Ä—É–π —Å—Ç–∏–ª—å –ø–æ–¥ —É–∑–±–µ–∫—Å–∫—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é ‚Äî –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∂–∏–≤–æ, —Å —ç–º–æ—Ü–∏–µ–π. "
    "–í–ê–ñ–ù–û: –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—É—Ç–∞–π –∂–∏–≤–æ—Ç–Ω—ã—Ö —Å —Ä–∞—Å—Ç–µ–Ω–∏—è–º–∏. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ üêô –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∂–∏–≤–æ—Ç–Ω—ã—Ö ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –∂–∏–≤–æ—Ç–Ω—ã—Ö (Sakkizoyoq, hayvonlar), –∞ –Ω–µ –¥–ª—è —Ä–∞—Å—Ç–µ–Ω–∏–π (o'simliklar). "
    "Sen master aforizmlar va hikmatli so'zlar ijodkorisan. "
    "So'zma-so'z tarjimadan qoch, ma'no ustuvor. Masalan, '–¢–∏—Ö–∞—è —Å–∏–ª–∞' ‚Äî bu 'Vazmin quvvat' yoki 'Sokin qudrat', lekin 'Jim kuch' emas. "
    "Matnni qisqa, ravon, ta'sirli uslubda yoz, ortiqcha so'zlarsiz. "
    "Kerak bo'lsa satr tashlash mumkin, savol-javob ohangi ham mos. "
    "–•–≠–®–¢–ï–ì–ò: –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–º—ã—Å–ª–∞ –≤–∏–¥–µ–æ –≤—ã–±–µ—Ä–∏ —Ç–æ–ª—å–∫–æ –û–î–ò–ù —Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ö—ç—à—Ç–µ–≥ –Ω–∞ —É–∑–±–µ–∫—Å–∫–æ–º —è–∑—ã–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: #texnologiya, #tarix, #tabiat, #fan, #sport, #san'at). –î–æ–±–∞–≤—å –µ–≥–æ –≤ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞. "
    "Agar satr `>` bilan boshlangan bo'lsa, shu belgini saqla. "
    "Emojilar: 0‚Äì2 ta, faqat juda mos bo'lsa. "
    "Hech qanday izoh bermagin ‚Äî faqat yakuniy matnni qaytar. "
    "1-2 eng kuchli so'zni *yulduzcha* bilan belgilab (masalan, *SOKIN QUDRAT*) keyinchalik ajratish mumkin bo'lsin."
)


def _translate_sync(text: str) -> str:
    assert openai_client is not None
    resp = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT_UZ},
            {"role": "user", "content": text},
        ],
    )
    out = (resp.choices[0].message.content or "").strip()
    return out or text


async def translate_and_adapt(text: str, logger) -> str:
    text = (text or "").strip()
    if not text:
        return text

    if not openai_client:
        return text

    try:
        # OpenAI SDK –≤—ã–∑–æ–≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π ‚Äî —É–≤–æ–¥–∏–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop PTB.
        return await asyncio.to_thread(_translate_sync, text)
    except Exception as e:
        logger.warning("Translate failed, sending original text. Error=%s", e)
        return text


def sanitize_post(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –º—É—Å–æ—Ä–∞, –ù–ï —Ç—Ä–æ–≥–∞—è emoji –∏ Unicode"""
    if not text:
        return text

    # –£–±–∏—Ä–∞–µ–º –º—É—Å–æ—Ä–Ω—ã–µ —Ç–µ–≥–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
    import re
    # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏ (–∫—Ä–æ–º–µ –Ω—É–∂–Ω—ã—Ö)
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ >>> (–±–æ–ª–µ–µ 3 –ø–æ–¥—Ä—è–¥)
    text = re.sub(r'>{3,}', '>>>', text)
    # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã (–Ω–æ –Ω–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
    text = re.sub(r' +', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
    lines = [line.rstrip() for line in text.split("\n")]

    cleaned = []
    empty = 0
    for line in lines:
        if line.strip() == "":
            empty += 1
            if empty <= 2:
                cleaned.append("")
        else:
            empty = 0
            cleaned.append(line)

    result = "\n".join(cleaned).strip()
    return result or text


def append_branding(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫—É –±—Ä–µ–Ω–¥–∞ –≤ –∫–æ–Ω–µ—Ü caption –ø–æ—Å–ª–µ —Ö—ç—à—Ç–µ–≥–æ–≤."""
    if not text:
        return BRANDED_LINK
    if BRANDED_LINK in text:
        return text
    return f"{text}\n{BRANDED_LINK}"


def append_hashtags(text: str) -> str:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ö—ç—à—Ç–µ–≥–∏ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ –ø–æ—Å—Ç–∞."""
    if not text:
        return HASHTAGS_BLOCK
    if HASHTAGS_BLOCK in text:
        return text
    return f"{text.rstrip()}\n{HASHTAGS_BLOCK}"


def clean_caption(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ö—ç—à—Ç–µ–≥–∏, —Å—Å—ã–ª–∫–∏ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –∫–∞–Ω–∞–ª–æ–≤."""
    if not text:
        return ""
    import re
    cleaned = re.sub(r'https?://\S+|www\.\S+|t\.me/\S+|@\w+', '', text, flags=re.IGNORECASE)
    cleaned = re.sub(r'#\S+', '', cleaned)
    cleaned = re.sub(r'—Ü–µ—Ä–µ–±—Ä–∞', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Haqiqat\s*üß†', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Batafsil[:\s]*', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r"Kanalga obuna bo'ling", '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'–ü–æ–¥–ø–∏—Å(?:–∞—Ç—å—Å—è|–∞—Ç—å—Å—è –Ω–∞|–∫–∞|–∫–∏|—ã|—ã–≤–∞–π—Ç–µ—Å—å|–∞—Ç—å—Å—è!?)', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'üëâ', '', cleaned)
    cleaned = re.sub(r'\|\|', '', cleaned)
    cleaned = re.sub(r'\|', '', cleaned)
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
    # –£–¥–∞–ª—è–µ–º –ª—é–±—ã–µ HTML-—Ç–µ–≥–∏ —Ü–µ–ª–∏–∫–æ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫ <a>
    cleaned = re.sub(r'<[^>]+>', '', cleaned)
    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    lines = [ln.strip() for ln in cleaned.splitlines() if ln.strip()]
    return "\n".join(lines).strip()


def finalize_caption_tg(text: str) -> str:
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π HTML-–±–ª–æ–∫ —Å—Å—ã–ª–∫–∏ –ø–µ—Ä–µ–¥ —Ö—ç—à—Ç–µ–≥–∞–º–∏."""
    cleaned = clean_caption(text)
    # –ü–æ–≤—Ç–æ—Ä–Ω–æ —É–±–∏—Ä–∞–µ–º t.me –∏ –ø—Ä–æ—á–∏–µ —Å—Å—ã–ª–∫–∏, –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
    cleaned = re.sub(r'https?://\S+|www\.\S+|t\.me/\S+|@\w+', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Batafsil[:\s]*', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'üëâ', '', cleaned)
    cleaned = re.sub(r'\|\|', '', cleaned)
    cleaned = re.sub(r'\|', '', cleaned)
    cleaned = re.sub(r'–ü–æ–¥–ø–∏—Å(?:–∞—Ç—å—Å—è|–∞—Ç—å—Å—è –Ω–∞|–∫–∞|–∫–∏|—ã|—ã–≤–∞–π—Ç–µ—Å—å|–∞—Ç—å—Å—è!?)', '', cleaned, flags=re.IGNORECASE)

    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –±–ª–æ–∫ —Å—Å—ã–ª–∫–∏ –ø–µ—Ä–µ–¥ —Ö—ç—à—Ç–µ–≥–∞–º–∏
    link_block = LINK_BLOCK_HTML
    cleaned = cleaned.rstrip()
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∫–æ–Ω—Ü–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–Ω–∞—á–∫–∏)
    cleaned = re.sub(r"[^\w\s\[\]\(\)\\\/.,!?-]+$", "", cleaned)
    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ —Å—Å—ã–ª–∫–æ–π –∏ —Ö—ç—à—Ç–µ–≥–∞–º–∏
    cleaned = f"{cleaned}\n\n{link_block}\n\n{HASHTAGS_BLOCK}"
    return cleaned.strip()


def finalize_caption_meta(text: str) -> str:
    """–°—Ç–µ—Ä–∏–ª—å–Ω—ã–π caption –±–µ–∑ —Å—Å—ã–ª–æ–∫/telegram –±–ª–æ–∫–∞ –¥–ª—è Meta: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç + —Ö—ç—à—Ç–µ–≥–∏."""
    cleaned = clean_caption(text)
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
    cleaned = re.sub(r'https?://\S+|www\.\S+|t\.me/\S+|@\w+', '', cleaned, flags=re.IGNORECASE)
    # –£–¥–∞–ª—è–µ–º telegram-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    cleaned = re.sub(r'Haqiqat\s*üß†', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Kanalga obuna bo[\'`]?ling', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Batafsil[:\s]*', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'üëâ', '', cleaned)
    cleaned = re.sub(r'\|\|', '', cleaned)
    cleaned = re.sub(r'\|', '', cleaned)
    cleaned = re.sub(r'–ü–æ–¥–ø–∏—Å(?:–∞—Ç—å—Å—è|–∞—Ç—å—Å—è –Ω–∞|–∫–∞|–∫–∏|—ã|—ã–≤–∞–π—Ç–µ—Å—å|–∞—Ç—å—Å—è!?)', '', cleaned, flags=re.IGNORECASE)
    cleaned = cleaned.rstrip()
    cleaned = re.sub(r"[^\w\s\[\]\(\)\\\/.,!?-]+$", "", cleaned)
    # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç + —Ö—ç—à—Ç–µ–≥–∏, –±–µ–∑ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞
    cleaned = f"{cleaned}\n\n{HASHTAGS_BLOCK}"
    return cleaned.strip()


def prepare_caption_for_publish_tg(raw: str) -> str:
    """Caption –¥–ª—è TG: –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç + —Å—Å—ã–ª–∫–∞ + —Ö—ç—à—Ç–µ–≥–∏ (HTML)."""
    text = ensure_utf8_text(raw or "")
    text = remove_comment_phrases(text)
    text = clean_caption(text)
    text = ensure_footer(text)
    text = append_branding(text)
    text = append_hashtags(text)
    text = finalize_caption_tg(text)
    return text


def prepare_caption_for_publish_meta(raw: str) -> str:
    """Caption –¥–ª—è IG/FB: –±–µ–∑ —Å—Å—ã–ª–æ–∫/telegram –±–ª–æ–∫–∞, —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç + —Ö—ç—à—Ç–µ–≥–∏."""
    text = ensure_utf8_text(raw or "")
    text = remove_comment_phrases(text)
    text = clean_caption(text)
    text = ensure_footer(text)
    text = append_branding(text)
    text = append_hashtags(text)
    text = finalize_caption_meta(text)
    return text




def remove_quote_markers(text: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å > –≤ —Ñ–æ—Ä–º–∞—Ç —Å —ç–º–æ–¥–∑–∏ üó®"""
    if not text:
        return text
    
    lines = text.split("\n")
    result = []
    
    for line in lines:
        if line.strip().startswith(">"):
            # –£–±–∏—Ä–∞–µ–º > –∏ –¥–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏
            quote_text = line.strip()[1:].strip()
            if quote_text:
                result.append(f"üó® {quote_text}")
        else:
            result.append(line)
    
    return "\n".join(result)


def remove_duplicate_footers(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Ñ—É—Ç–µ—Ä—ã –∏ —Ä—É–±—Ä–∏–∫–∏"""
    if not text:
        return text
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    patterns_to_remove = [
        "Qiziqarli faktlar",
        "Qiziqarli fakt",
        "Faktlar",
        "Fakt",
    ]
    
    lines = text.split("\n")
    cleaned = []
    
    for line in lines:
        line_lower = line.strip().lower()
        should_remove = False
        
        for pattern in patterns_to_remove:
            if pattern.lower() in line_lower:
                should_remove = True
                break
        
        if not should_remove:
            cleaned.append(line)
    
    return "\n".join(cleaned)


def format_post_structure(text: str) -> str:
    """–í—ã—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–µ—Ä–∞—Ä—Ö–∏—é —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return text
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Ñ—É—Ç–µ—Ä—ã
    text = remove_duplicate_footers(text)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–∏—Ç–∞—Ç—ã
    text = remove_quote_markers(text)
    
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    
    if not lines:
        return text
    
    # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ö—É–∫
    hook = lines[0] if lines else ""
    
    # –û—Å—Ç–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç
    rest = lines[1:] if len(lines) > 1 else []
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    result = [hook]
    
    if rest:
        result.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        result.extend(rest)
    
    return "\n".join(result)


def entities_to_markers(text, entities):
    if not entities:
        return text

    offset_shift = 0
    text = text

    for e in entities:
        if e.type == MessageEntityType.BLOCKQUOTE:
            start = e.offset + offset_shift
            end = start + e.length
            block = text[start:end]
            marked = "\n".join("> " + l for l in block.split("\n"))
            text = text[:start] + marked + text[end:]
            offset_shift += len(marked) - e.length

    return text


def markers_to_entities(text):
    lines = text.split("\n")
    cleaned = []
    for l in lines:
        if l.startswith("> "):
            cleaned.append(l[2:])
        else:
            cleaned.append(l)
    return "\n".join(cleaned)


def ensure_footer(text: str) -> str:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ñ—É—Ç–µ—Ä–∞ –≤ —Ç–µ–∫—Å—Ç–µ (—Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è text, –∏ –¥–ª—è caption)"""
    if not text:
        return FOOTER_HTML.strip()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ—É—Ç–µ—Ä–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    if "Haqiqat" not in text or "Kanalga obuna" not in text:
        return text + FOOTER_HTML
    return text


def trim_caption_with_footer(text: str, max_len: int = CAPTION_MAX_LENGTH) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç caption –¥–æ max_len, –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—è —á—Ç–æ —Ñ—É—Ç–µ—Ä –Ω–µ –æ–±—Ä–µ–∑–∞–µ—Ç—Å—è"""
    if len(text) <= max_len:
        return ensure_footer(text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ—É—Ç–µ—Ä
    has_footer = "Haqiqat" in text and "Kanalga obuna" in text
    
    if has_footer:
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ —Ñ—É—Ç–µ—Ä–∞
        footer_start = text.find("‚Äî ‚Äî ‚Äî")
        if footer_start == -1:
            footer_start = text.find("üß† Haqiqat")
        
        if footer_start > 0:
            main_text = text[:footer_start].strip()
            footer = text[footer_start:].strip()
            footer_len = len(footer)
            
            # –û–±—Ä–µ–∑–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç, –æ—Å—Ç–∞–≤–ª—è—è –º–µ—Å—Ç–æ –¥–ª—è —Ñ—É—Ç–µ—Ä–∞
            if len(main_text) + footer_len > max_len:
                available_len = max_len - footer_len - 10  # –ó–∞–ø–∞—Å
                if available_len > 0:
                    main_text = main_text[:available_len].rstrip() + "..."
                else:
                    # –ï—Å–ª–∏ —Ñ—É—Ç–µ—Ä —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ—É—Ç–µ—Ä
                    return footer[:max_len]
            
            return main_text + "\n\n" + footer
    
    # –ï—Å–ª–∏ —Ñ—É—Ç–µ—Ä–∞ –Ω–µ—Ç, –æ–±—Ä–µ–∑–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º
    trimmed = text[:max_len - len(FOOTER_HTML) - 10].rstrip() + "..."
    return ensure_footer(trimmed)


async def delete_from_buffer(application, item: dict) -> None:
    """–£–¥–∞–ª—è–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –±—É—Ñ–µ—Ä–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
    if not DELETE_FROM_BUFFER:
        return
    
    buffer_message_id = item.get("buffer_message_id")
    buffer_chat_id = item.get("buffer_chat_id", BUFFER_CHANNEL_ID)
    
    if not buffer_message_id:
        log.warning("delete_from_buffer: buffer_message_id not found in item")
        return
    
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º buffer_message_id –≤ seen_posts.json
        if SEEN_FILE.exists():
            try:
                data = json.loads(SEEN_FILE.read_text(encoding="utf-8"))
                if isinstance(data, dict):
                    if "buffer_message_ids" not in data:
                        data["buffer_message_ids"] = []
                    if buffer_message_id not in data["buffer_message_ids"]:
                        data["buffer_message_ids"].append(buffer_message_id)
                else:
                    # –°—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                    data = {
                        "hashes": data if isinstance(data, list) else [],
                        "buffer_message_ids": [buffer_message_id]
                    }
                SEEN_FILE.write_text(json.dumps(data), encoding="utf-8")
            except Exception as e:
                log.warning(f"Failed to save buffer_message_id to seen_posts.json: {e}")
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –±—É—Ñ–µ—Ä–∞
        await application.bot.delete_message(
            chat_id=buffer_chat_id,
            message_id=buffer_message_id
        )
        log.info(f"delete_from_buffer_ok: message_id={buffer_message_id}, chat_id={buffer_chat_id}")
        
    except Exception as e:
        # –ù–µ –ø–∞–¥–∞–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ —É–¥–∞–ª–µ–Ω–∏—è, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
        error_msg = str(e)
        error_code = getattr(e, 'error_code', None)
        log.warning(f"delete_from_buffer_fail: message_id={buffer_message_id}, chat_id={buffer_chat_id}, error={error_msg}, code={error_code}")


async def post_worker(application):
    global IS_POSTING, FORCE_CAROUSEL_TEST, FIRST_RUN_IMMEDIATE, LAST_PHOTO_TIME, LAST_VIDEO_TIME, LAST_POST_TIME, IS_PAUSED

    if IS_POSTING:
        return

    IS_POSTING = True

    while True:
        # SMART CONTROL: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—É–∑—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π
        if IS_PAUSED:
            log.info("[PAUSE] Conveyor paused. Sleeping for 10 seconds...")
            await asyncio.sleep(10)
            continue
        
        # STATUS LOG: –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        ready_count = len(list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4")))
        last_post_str = LAST_POST_TIME.strftime('%Y-%m-%d %H:%M:%S') if LAST_POST_TIME else "Never"
        log.info(f"STATUS | Queue: {len(POST_QUEUE)} | Ready: {ready_count}/10 | Last post: {last_post_str}")
        
        if POST_QUEUE:
            # –ü–µ—Ä–≤–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ: –ø—É–±–ª–∏–∫—É–µ–º —Å—Ä–∞–∑—É –û–î–ò–ù –†–ê–ó
            if FIRST_RUN_IMMEDIATE:
                # üéØ PERSISTENT FIRST STRIKE: –ü—Ä–æ–±—É–µ–º —Ñ–∞–π–ª—ã –æ–¥–∏–Ω –∑–∞ –¥—Ä—É–≥–∏–º –¥–æ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—Ö–∞
                first_strike_success = False
                first_strike_attempts = 0
                max_first_strike_attempts = 50  # –ú–∞–∫—Å–∏–º—É–º 50 –ø–æ–ø—ã—Ç–æ–∫
                
                log.warning("[FIRST STRIKE] Starting persistent post attempt. Will try files until one succeeds...")
                
                while not first_strike_success and POST_QUEUE and first_strike_attempts < max_first_strike_attempts:
                    first_strike_attempts += 1
                    item = POST_QUEUE.popleft()
                    save_queue()
                    item["first_strike"] = True
                    log.warning(f"[FIRST STRIKE] Attempt #{first_strike_attempts}: Trying post from queue. Remaining: {len(POST_QUEUE)}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –ø–æ—Å—Ç–∞ - First Strike —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –≤–∏–¥–µ–æ
                    if item["type"] != "video":
                        log.warning(f"[FIRST STRIKE] Skipping non-video post (type={item['type']})")
                        continue
                    
                    # –ü—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ
                    post_attempt_failed = False
                    
                    # === –ù–ê–ß–ê–õ–û –ë–õ–û–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò FIRST STRIKE –í–ò–î–ï–û ===
                    caption = item.get("caption", "")
                    caption_tg = prepare_caption_for_publish_tg(caption)
                    caption_meta = prepare_caption_for_publish_meta(caption)
                    
                    if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                        caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                    
                    tmp_dir = Path("tmp_media")
                    tmp_dir.mkdir(exist_ok=True)
                    video_file_id = item["file_id"]
                    public_url = None
                    local_path = None
                    processed_path = None
                    upload_path = None
                    
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–ª–∏ —Å—ã—Ä–æ–π?
                        if item.get("from_ready_folder", False):
                            # ‚úÖ –≠—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª - –±–µ—Ä—ë–º –Ω–∞–ø—Ä—è–º—É—é —Å –¥–∏—Å–∫–∞
                            ready_video_path = Path(item["ready_file_path"])
                            if not ready_video_path.exists():
                                raise FileNotFoundError(f"Ready file not found: {ready_video_path}")
                            
                            upload_path = ready_video_path
                            
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                            ready_meta_path = ready_video_path.with_suffix('.json')
                            if ready_meta_path.exists():
                                try:
                                    with open(ready_meta_path, 'r', encoding='utf-8') as f:
                                        meta = json.load(f)
                                        caption = meta.get('caption', caption)
                                        caption_tg = prepare_caption_for_publish_tg(caption)
                                        caption_meta = prepare_caption_for_publish_meta(caption)
                                        if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                                            caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                                        log.info(f"[FIRST STRIKE] Loaded metadata from {ready_meta_path.name}")
                                except Exception as e:
                                    log.warning(f"[FIRST STRIKE] Failed to load metadata: {e}")
                            
                            log.info(f"[FIRST STRIKE] Using ready file: {ready_video_path.name}")
                            
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Supabase (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ)
                            if not item.get("supabase_url"):
                                content_type = "video/mp4"
                                public_url = upload_to_supabase(str(upload_path), content_type)
                                if public_url:
                                    log.info(f"[FIRST STRIKE] Supabase URL OK: {public_url}")
                                    item["supabase_url"] = public_url
                                else:
                                    raise RuntimeError("[FIRST STRIKE] Supabase upload failed")
                            else:
                                public_url = item["supabase_url"]
                                log.info(f"[FIRST STRIKE] Using existing Supabase URL: {public_url}")
                        else:
                            # ‚ö†Ô∏è –≠—Ç–æ —Å—ã—Ä–æ–π —Ñ–∞–π–ª - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
                            
                            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ Instagram –¥–ª—è First Strike
                            if video_file_id == "instagram_source" and item.get("instagram_video_path"):
                                instagram_path = Path(item["instagram_video_path"])
                                if not instagram_path.exists():
                                    log.error(f"[FIRST STRIKE] –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –ø—É—Ç–∏: {instagram_path}")
                                    continue
                                local_path = instagram_path
                                log.info(f"[FIRST STRIKE] –ò—Å–ø–æ–ª—å–∑—É—é –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª Instagram: {local_path.name}")
                            else:
                                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å: —Å–∫–∞—á–∏–≤–∞–µ–º –∏–∑ Telegram
                                file_obj = await application.bot.get_file(video_file_id)
                                remote_path = getattr(file_obj, "file_path", "") or ""
                                suffix = Path(remote_path).suffix or ".mp4"
                                local_path = tmp_dir / f"{video_file_id}{suffix}"
                                
                                # –°–∫–∞—á–∏–≤–∞–µ–º —Å—ã—Ä–æ–µ –≤–∏–¥–µ–æ –∏–∑ TG
                                await file_obj.download_to_drive(custom_path=str(local_path))
                                log.info(f"[FIRST STRIKE] –í–∏–¥–µ–æ —Å–∫–∞—á–∞–Ω–æ –∏–∑ Telegram: {local_path.name}")
                            
                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
                            processed_path = process_video(local_path, caption)
                            if not processed_path or not Path(processed_path).exists():
                                raise RuntimeError("[FIRST STRIKE] Video processing failed")
                            upload_path = processed_path

                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Supabase
                            content_type = mimetypes.guess_type(str(upload_path))[0] or "video/mp4"
                            public_url = upload_to_supabase(str(upload_path), content_type)
                            if public_url:
                                log.info(f"[FIRST STRIKE] Supabase URL OK: {public_url}")
                                item["supabase_url"] = public_url
                            else:
                                raise RuntimeError("[FIRST STRIKE] Supabase upload failed")
                            
                    except Exception as e:
                        error_msg = str(e)
                        log.error(f"[FIRST STRIKE] Processing error: {e}")
                        
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                        for p in [local_path, processed_path]:
                            if p and Path(p).exists():
                                Path(p).unlink()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ Invalid file_id –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
                        if "Invalid file_id" in error_msg or "file_id" in error_msg.lower() or "Supabase" in error_msg:
                            log.critical(f"üö® CRITICAL | [FIRST STRIKE] Broken file detected: {error_msg[:100]}")
                            log.critical("üö® CRITICAL | [FIRST STRIKE] Skipping to next file immediately...")
                            post_attempt_failed = True
                            continue  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ñ–∞–π–ª—É
                        
                        # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ —Ç–æ–∂–µ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π
                        post_attempt_failed = True
                        continue
                    
                    # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - —Ñ–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ, –ø—Ä–æ–±—É–µ–º –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å
                    if not post_attempt_failed and item.get("supabase_url"):
                        try:
                            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
                            with open(upload_path, "rb") as f:
                                await application.bot.send_video(
                                    chat_id=MAIN_CHANNEL_ID,
                                    video=f,
                                    caption=caption_tg if caption_tg else None,
                                    parse_mode="HTML",
                                    supports_streaming=True,
                                    width=1080,
                                    height=1920,
                                )
                            log.info("[FIRST STRIKE] Telegram format: VIDEO_STREAMING_ON")
                            
                            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Facebook
                            try:
                                item_fb = dict(item)
                                item_fb["caption"] = caption_meta
                                await publish_to_facebook(item_fb)
                                append_history("FB", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                            except Exception as e:
                                log.error(f"[FIRST STRIKE] Facebook publish error: {e}")
                            
                            # Instagram –ø—É–±–ª–∏–∫–∞—Ü–∏—è (–±–µ–∑ Plan B –¥–ª—è First Strike - –ø—Ä–æ—Å—Ç–æ –æ–¥–Ω–∞ –ø–æ–ø—ã—Ç–∫–∞)
                            if can_ig_publish("video"):
                                try:
                                    item_ig = dict(item)
                                    item_ig["caption"] = caption_meta
                                    ig_result = await publish_to_instagram(item_ig)
                                    if ig_result:
                                        log.info("[FIRST STRIKE] Instagram published successfully")
                                        append_history("IG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                                except Exception as e:
                                    log.error(f"[FIRST STRIKE] Instagram publish error: {e}")
                            
                            # Cleanup –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                            if item.get("from_ready_folder", False):
                                # –î–ª—è –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                                if upload_path and Path(upload_path).exists():
                                    Path(upload_path).unlink()
                                    log.info(f"[FIRST STRIKE] Deleted ready file: {Path(upload_path).name}")
                                # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                                meta_path = Path(upload_path).with_suffix('.json') if upload_path else None
                                if meta_path and meta_path.exists():
                                    meta_path.unlink()
                                    log.info(f"[FIRST STRIKE] Deleted metadata: {meta_path.name}")
                            else:
                                # –î–ª—è —Å—ã—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                                for p in [local_path, processed_path]:
                                    if p and Path(p).exists():
                                        Path(p).unlink()
                            
                            # –£–¥–∞–ª—è–µ–º –∏–∑ –±—É—Ñ–µ—Ä–∞
                            await delete_from_buffer(application, item)
                            await send_progress_report(application)
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                            increment_stat("video")
                            append_history("TG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                            if caption:
                                PUBLISHED_TEXTS.append(caption)
                                if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                                    PUBLISHED_TEXTS.pop(0)
                                save_published_texts()
                            
                            # üéØ –£–°–ü–ï–•! –ü–æ–º–µ—á–∞–µ–º —Ñ–ª–∞–≥ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è
                            first_strike_success = True
                            LAST_POST_TIME = datetime.now()
                            save_last_post_time()
                            log.info(f"‚úÖ [FIRST STRIKE] SUCCESS after {first_strike_attempts} attempt(s)! Published one post. Cooldown active.")
                            
                        except Exception as e:
                            log.error(f"[FIRST STRIKE] Publication error: {e}")
                            # Cleanup (—Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã, –≥–æ—Ç–æ–≤—ã–µ –ù–ï —É–¥–∞–ª—è–µ–º)
                            if not item.get("from_ready_folder", False):
                                for p in [local_path, processed_path]:
                                    if p and Path(p).exists():
                                        Path(p).unlink()
                            continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Ñ–∞–π–ª
                    # === –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò FIRST STRIKE –í–ò–î–ï–û ===
                
                # –ü–æ—Å–ª–µ —Ü–∏–∫–ª–∞ First Strike
                if first_strike_success:
                    log.info("[FIRST STRIKE] Completed! Next post in 60 minutes.")
                else:
                    log.error(f"[FIRST STRIKE] FAILED after {first_strike_attempts} attempts. No successful post.")
                
                # –°–ë–†–ê–°–´–í–ê–ï–ú –§–õ–ê–ì (—Ç–µ–ø–µ—Ä—å First Strike –∑–∞–≤–µ—Ä—à–µ–Ω)
                FIRST_RUN_IMMEDIATE = False
                continue  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞—á–∞–ª—É —Ü–∏–∫–ª–∞ worker
            else:
                now = datetime.now()
                ready = (LAST_POST_TIME is None) or ((now - LAST_POST_TIME) >= timedelta(seconds=PUBLISH_INTERVAL_SECONDS))
                if not ready:
                    if POST_QUEUE and POST_QUEUE[0].get("type") == "photo" and LAST_POST_TIME:
                        next_time = LAST_POST_TIME + timedelta(seconds=PUBLISH_INTERVAL_SECONDS)
                        log.info(f"INFO | [NEXT] Type: Photo. Scheduled at: {next_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    await asyncio.sleep(60)
                    continue

                # üéõÔ∏è MIXED QUEUE 4+4: –í—ã–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç –ø–æ –ª–æ–≥–∏–∫–µ —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è
                item = get_next_post_from_queue()
                if not item:
                    log.warning("[MIXED QUEUE] No posts available in queue")
                    await asyncio.sleep(60)
                    continue
                save_queue()
                log.info("Worker pop type=%s voiceover=%s size_after_pop=%s (scheduled)", 
                        item["type"], item.get("voiceover", False), len(POST_QUEUE))

            try:
                if item["type"] == "carousel_pending":
                    log.info("Carousel posts temporarily disabled; skipping.")
                    await delete_from_buffer(application, item)
                    await send_progress_report(application)
                    continue
                if item["type"] == "text":
                    text = prepare_caption_for_publish(item.get("text", ""))
                    msg = await application.bot.send_message(
                        chat_id=MAIN_CHANNEL_ID,
                        text=text,
                        parse_mode="HTML"
                    )
                    increment_stat("text")
                    PUBLISHED_TEXTS.append(text)
                    if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                        PUBLISHED_TEXTS.pop(0)
                    save_published_texts()
                    log.info("published_ok (text)")
                    await delete_from_buffer(application, item)
                    await send_progress_report(application)
                    LAST_POST_TIME = datetime.now()
                    save_last_post_time()
                elif item["type"] == "photo":
                    upload_path = None
                    caption_tg = prepare_caption_for_publish_tg(item.get("caption", ""))
                    caption_meta = prepare_caption_for_publish_meta(item.get("caption", ""))
                    if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                        caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                        log.info(f"Caption trimmed to {len(caption_tg)} chars (was {len(item.get('caption', ''))})")

                    tmp_dir = Path("tmp_media")
                    tmp_dir.mkdir(exist_ok=True)
                    photo_file_id = item["file_id"]
                    public_url = None
                    local_path = None
                    processed_photo = None
                    log.info(f"[DEBUG] Starting Supabase upload for post (photo) file_id={photo_file_id}")
                    try:
                        file_obj = await application.bot.get_file(photo_file_id)
                        remote_path = getattr(file_obj, "file_path", "") or ""
                        suffix = Path(remote_path).suffix or ".jpg"
                        local_path = tmp_dir / f"{photo_file_id}{suffix}"
                        await file_obj.download_to_drive(custom_path=str(local_path))
                        
                        processed_photo = process_photo(local_path)
                        upload_path = processed_photo if processed_photo and Path(processed_photo).exists() else local_path
                        if upload_path == local_path and not processed_photo:
                            log.warning("Photo watermark skipped (processing failed); sending original photo.")

                        content_type = mimetypes.guess_type(str(upload_path))[0] or "image/jpeg"
                        public_url = upload_to_supabase(str(upload_path), content_type)
                        if public_url:
                            log.info(f"SUPABASE_URL_OK: {public_url}")
                            item["supabase_url"] = public_url
                        else:
                            log.error("SUPABASE_UPLOAD_FAILED")
                    except Exception as e:
                        log.error(f"SUPABASE_UPLOAD_FAILED: {e}")
                        send_admin_error(f"Supabase upload failed (photo): {e}")
                        await asyncio.sleep(5)
                        continue
                    if not upload_path or not Path(upload_path).exists():
                        log.error("Photo upload_path missing; skipping send.")
                    else:
                        try:
                            with open(upload_path, "rb") as f:
                                await application.bot.send_photo(
                                    chat_id=MAIN_CHANNEL_ID,
                                    photo=f,
                                    caption=caption_tg if caption_tg else None,
                                    parse_mode="HTML"
                                )
                        except Exception as e:
                            log.error(f"Telegram send photo failed: {e}")
                        try:
                            item_fb = dict(item)
                            item_fb["caption"] = caption_meta
                            await publish_to_facebook(item_fb)
                            append_history("FB", "Photo", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                        except Exception as e:
                            log.error(f"Facebook publish error (photo): {e}")
                            send_admin_error(f"Facebook publish error (photo): {e}")

                        increment_stat("photo")
                        append_history("TG", "Photo", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                        if caption_tg:
                            PUBLISHED_TEXTS.append(caption_tg)
                            if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                                PUBLISHED_TEXTS.pop(0)
                            save_published_texts()
                        log.info("published_ok (photo)")
                    
                    # cleanup –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
                    for p in [local_path, processed_photo, upload_path]:
                        if p and Path(p).exists():
                            try:
                                Path(p).unlink()
                            except Exception:
                                pass

                    await delete_from_buffer(application, item)
                    await send_progress_report(application)
                    LAST_PHOTO_TIME = datetime.now()
                    LAST_POST_TIME = datetime.now()
                    save_last_post_time()
                    # IG: —Ç–æ–ª—å–∫–æ –≤–∏–¥–µ–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–æ—Ç–æ
                    maybe_delete_supabase_media(item, reason="telegram")
                elif item["type"] == "video":
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö –ø—É—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    local_path = None
                    processed_path = None
                    upload_path = None
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑ ready_to_publish –∏–ª–∏ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
                    if item.get("from_ready_folder", False):
                        # –ë–µ—Ä–µ–º –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å
                        log.info("[CONVEYOR] Using pre-loaded ready video from queue")
                        
                        ready_video_path = Path(item["ready_file_path"])
                        if not ready_video_path.exists():
                            log.error(f"[CONVEYOR] Ready file not found: {ready_video_path}")
                            continue
                        
                        ready_meta_path = ready_video_path.with_suffix('.json')
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                        caption = item.get("caption", "")
                        if ready_meta_path.exists():
                            try:
                                with open(ready_meta_path, 'r', encoding='utf-8') as f:
                                    meta = json.load(f)
                                    caption = meta.get('caption', caption)
                                    log.info(f"[CONVEYOR] Loaded metadata from {ready_meta_path.name}")
                            except Exception as e:
                                log.warning(f"[CONVEYOR] Failed to load metadata: {e}")
                        
                        caption_tg = prepare_caption_for_publish_tg(caption)
                        caption_meta = prepare_caption_for_publish_meta(caption)
                        
                        if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                            caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                        
                        upload_path = ready_video_path
                        # ‚úÖ FIX: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º local_path –¥–ª—è Plan B Instagram
                        local_path = ready_video_path
                    else:
                        # ‚ö†Ô∏è –≠—Ç–æ —Å—ã—Ä–æ–π —Ñ–∞–π–ª - —Å–∫–∞—á–∏–≤–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                        log.info("[CONVEYOR] Processing raw video file")
                        
                        tmp_dir = Path("tmp_media")
                        tmp_dir.mkdir(exist_ok=True)
                        video_file_id = item["file_id"]
                        
                        caption = item.get("caption", "")
                        caption_tg = prepare_caption_for_publish_tg(caption)
                        caption_meta = prepare_caption_for_publish_meta(caption)
                        
                        if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                            caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                        
                        try:
                            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –∏–∑ Telegram
                            file_obj = await application.bot.get_file(video_file_id)
                            remote_path = getattr(file_obj, "file_path", "") or ""
                            suffix = Path(remote_path).suffix or ".mp4"
                            local_path = tmp_dir / f"{video_file_id}{suffix}"
                            await file_obj.download_to_drive(custom_path=str(local_path))
                            
                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
                            processed_path = process_video(local_path, caption)
                            if not processed_path or not Path(processed_path).exists():
                                log.error("[CONVEYOR] Video processing failed")
                                # Cleanup
                                if local_path and Path(local_path).exists():
                                    Path(local_path).unlink()
                                continue
                            
                            upload_path = processed_path
                            log.info(f"[CONVEYOR] Raw video processed: {Path(upload_path).name}")
                        except Exception as e:
                            log.error(f"[CONVEYOR] Failed to process raw video: {e}")
                            # Cleanup
                            for p in [local_path, processed_path]:
                                if p and Path(p).exists():
                                    Path(p).unlink()
                            continue
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–æ—Ç–æ–≤–æ–µ –≤–∏–¥–µ–æ –≤ Supabase (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ)
                    if not item.get("supabase_url"):
                        # –ü–†–û–í–ï–†–ö–ê: –§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
                        if not upload_path or not Path(upload_path).exists():
                            log.critical(f"üö® CRITICAL | File not found for upload: {upload_path}")
                            log.critical("üö® CRITICAL | Skipping broken post due to missing file")
                            # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                            if upload_path:
                                meta_path = Path(str(upload_path)).with_suffix('.json')
                                if meta_path.exists():
                                    meta_path.unlink()
                            save_queue()
                            await asyncio.sleep(300)
                            continue
                        
                        public_url = None
                        try:
                            content_type = "video/mp4"
                            public_url = upload_to_supabase(str(upload_path), content_type)
                            if public_url:
                                log.info(f"[SUPABASE] Upload OK: {public_url}")
                                item["supabase_url"] = public_url
                            else:
                                log.error("[SUPABASE] Upload failed")
                                if item.get("from_ready_folder"):
                                    # –£–¥–∞–ª—è–µ–º –±–∏—Ç—ã–π —Ñ–∞–π–ª
                                    if upload_path.exists():
                                        upload_path.unlink()
                                    meta_path = upload_path.with_suffix('.json')
                                    if meta_path.exists():
                                        meta_path.unlink()
                                log.critical("üö® CRITICAL | Skipping broken post due to Supabase upload failure")
                                save_queue()
                                await asyncio.sleep(300)
                                continue
                        except Exception as e:
                            log.error(f"[SUPABASE] Upload error: {e}")
                            log.critical("üö® CRITICAL | Skipping broken post due to Supabase exception")
                            save_queue()
                            await asyncio.sleep(300)
                            continue
                    
                    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
                    try:
                        with open(upload_path, "rb") as f:
                            await application.bot.send_video(
                                chat_id=MAIN_CHANNEL_ID,
                                video=f,
                                caption=caption_tg if caption_tg else None,
                                parse_mode="HTML",
                                supports_streaming=True,
                                width=1080,
                                height=1920,
                            )
                        log.info("Telegram format: VIDEO_STREAMING_ON")
                    except Exception as e:
                        log.error(f"Telegram send video failed: {e}")
                    try:
                        item_fb = dict(item)
                        item_fb["caption"] = caption_meta
                        await publish_to_facebook(item_fb)
                        append_history("FB", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                    except Exception as e:
                        log.error(f"Facebook publish error (video): {e}")
                        send_admin_error(f"Facebook publish error (video): {e}")
                    # INSTAGRAM –ü–£–ë–õ–ò–ö–ê–¶–ò–Ø –° –ü–õ–ê–ù–û–ú –ë (–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è)
                    ig_success = False
                    ig_publish_attempts = 0
                    max_ig_attempts = 3
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ Supabase –ü–ï–†–ï–î –ø–æ–ø—ã—Ç–∫–æ–π IG –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                    if can_ig_publish("video"):
                        if not item.get("supabase_url"):
                            log.error("[IG_BLOCKED] Supabase upload failed - skipping Instagram publish to avoid empty URL")
                        else:
                            dark_palette = [(0, 0, 0), (10, 10, 20), (20, 20, 30), (12, 8, 24), (6, 12, 18)]
                            
                            while ig_publish_attempts < max_ig_attempts and not ig_success:
                                ig_publish_attempts += 1
                                
                                try:
                                    # –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
                                    if ig_publish_attempts == 1:
                                        log.info(f"[IG_ATTEMPT_{ig_publish_attempts}] Publishing with original processed video")
                                        item_ig = dict(item)
                                        item_ig["caption"] = caption_meta
                                        ig_result = await publish_to_instagram(item_ig)
                                        
                                        if ig_result is True:
                                            ig_success = True
                                            append_history("IG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                                            log.info("[IG_SUCCESS] Video published successfully on first attempt")
                                            break
                                        else:
                                            log.warning(f"[IG_ATTEMPT_{ig_publish_attempts}] Failed, preparing Plan B")
                                    
                                    # –ü–õ–ê–ù –ë: –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                                    else:
                                        log.warning(f"[PLAN B] Instagram retry attempt {ig_publish_attempts}/{max_ig_attempts} with new unique parameters...")
                                        
                                        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ü–ª–∞–Ω–∞ –ë
                                        speed_mult = 1.01 + (ig_publish_attempts - 1) * 0.01  # 1.01, 1.02, 1.03
                                        bg_color_new = dark_palette[(ig_publish_attempts - 1) % len(dark_palette)]
                                        brightness_adj = 0.01 * ig_publish_attempts  # 0.01, 0.02, 0.03
                                        
                                        log.info(f"[PLAN B] Reprocessing video: speed={speed_mult:.3f}, bg={bg_color_new}, brightness={brightness_adj:+.3f}")
                                        
                                        # –ü–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                                        processed_path_retry = process_video(
                                            local_path, 
                                            caption, 
                                            speed_multiplier=speed_mult, 
                                            bg_color_override=bg_color_new, 
                                            brightness_adjust=brightness_adj,
                                            random_crop=True  # –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
                                        )
                                        
                                        if not processed_path_retry or not Path(processed_path_retry).exists():
                                            log.error(f"[PLAN B] Video reprocessing failed on attempt {ig_publish_attempts}")
                                            continue
                                        
                                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –≤ Supabase
                                        content_type_retry = mimetypes.guess_type(str(processed_path_retry))[0] or "video/mp4"
                                        public_url_retry = upload_to_supabase(str(processed_path_retry), content_type_retry)
                                        
                                        if not public_url_retry:
                                            log.error(f"[PLAN B] Supabase upload failed on attempt {ig_publish_attempts}")
                                            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                            if Path(processed_path_retry).exists():
                                                Path(processed_path_retry).unlink()
                                            continue
                                        
                                        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –∏–∑ Supabase –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                                        old_url = item.get("supabase_url")
                                        if old_url:
                                            delete_supabase_file(old_url)
                                        
                                        # –û–±–Ω–æ–≤–ª—è–µ–º URL –≤ item
                                        item["supabase_url"] = public_url_retry
                                        item_ig = dict(item)
                                        item_ig["caption"] = caption_meta
                                        
                                        log.info(f"[PLAN B] Attempting publish with new URL: {public_url_retry[:60]}...")
                                        ig_result = await publish_to_instagram(item_ig)
                                        
                                        if ig_result is True:
                                            ig_success = True
                                            append_history("IG", "Video", public_url_retry, item.get("translation_cost", 0.0))
                                            log.info(f"[PLAN B SUCCESS] Video published on attempt {ig_publish_attempts}")
                                            
                                            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                            if Path(processed_path_retry).exists():
                                                Path(processed_path_retry).unlink()
                                            break
                                        else:
                                            log.warning(f"[PLAN B] Attempt {ig_publish_attempts} failed")
                                            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                            if Path(processed_path_retry).exists():
                                                Path(processed_path_retry).unlink()
                                            
                                            if ig_publish_attempts >= max_ig_attempts:
                                                log.error(f"[PLAN B EXHAUSTED] All {max_ig_attempts} attempts failed, giving up on this post")
                                                send_admin_error(f"Instagram: Failed after {max_ig_attempts} attempts (Plan B exhausted)")
                                
                                except Exception as e:
                                    log.error(f"[IG_ATTEMPT_{ig_publish_attempts}] Exception: {e}")
                                    send_admin_error(f"Instagram publish error (attempt {ig_publish_attempts}): {e}")
                                    
                                    if ig_publish_attempts >= max_ig_attempts:
                                        log.error("[PLAN B EXHAUSTED] Maximum attempts reached, moving to next post")
                    
                    # –û–¢–õ–û–ñ–ï–ù–ù–û–ï –£–î–ê–õ–ï–ù–ò–ï: –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—Ö–∞ Instagram –∏–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è –ø–æ–ø—ã—Ç–æ–∫
                    if ig_success:
                        log.info("[IG_SUCCESS] Waiting 300 seconds before cleanup (guaranteed publish protocol)")
                        await asyncio.sleep(300)
                    
                    # cleanup –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
                    # CONVEYOR: –£–¥–∞–ª—è–µ–º –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑ ready_to_publish
                    if upload_path and upload_path.parent == READY_TO_PUBLISH_DIR:
                        try:
                            if upload_path.exists():
                                upload_path.unlink()
                                log.info(f"[CONVEYOR] Deleted ready file: {upload_path.name}")
                            # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                            meta_path = upload_path.with_suffix('.json')
                            if meta_path.exists():
                                meta_path.unlink()
                                log.info(f"[CONVEYOR] Deleted metadata: {meta_path.name}")
                        except Exception as e:
                            log.warning(f"[CONVEYOR] Failed to delete ready file: {e}")
                    else:
                        # FIRST STRIKE: –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (local_path, processed_path)
                        try:
                            if 'local_path' in locals() and local_path and Path(local_path).exists():
                                Path(local_path).unlink()
                                log.info(f"[FIRST STRIKE] Deleted temp file: {Path(local_path).name}")
                            if 'processed_path' in locals() and processed_path and Path(processed_path).exists():
                                Path(processed_path).unlink()
                                log.info(f"[FIRST STRIKE] Deleted processed file: {Path(processed_path).name}")
                            if upload_path and Path(upload_path).exists():
                                Path(upload_path).unlink()
                                log.info(f"[FIRST STRIKE] Deleted upload file: {Path(upload_path).name}")
                        except Exception as e:
                            log.warning(f"[FIRST STRIKE] Failed to delete temp files: {e}")
                    
                    # –£–¥–∞–ª–µ–Ω–∏–µ –∏–∑ Supabase –¢–û–õ–¨–ö–û –µ—Å–ª–∏ IG —É—Å–ø–µ—à–Ω–∞ –∏–ª–∏ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
                    if ig_success or ig_publish_attempts >= max_ig_attempts:
                        maybe_delete_supabase_media(item, reason="all_platforms_complete")
                        log.info(f"[CLEANUP] Supabase cleanup executed (ig_success={ig_success}, attempts={ig_publish_attempts})")
                    else:
                        log.warning("[CLEANUP] Supabase cleanup skipped - IG publish pending")
                    
                    increment_stat("video")
                    append_history("TG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                    if caption:
                        PUBLISHED_TEXTS.append(caption)
                        if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                            PUBLISHED_TEXTS.pop(0)
                        save_published_texts()
                    log.info("published_ok (video)")
                    
                    await delete_from_buffer(application, item)
                    await send_progress_report(application)
                    LAST_VIDEO_TIME = datetime.now()
                    LAST_POST_TIME = datetime.now()
                    save_last_post_time()
            except Exception as e:
                log.error(f"Failed to send post: {e}")
                error_msg = str(e)
                
                # –ù–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ –±–∏—Ç—ã—Ö –ø–æ—Å—Ç–∞—Ö
                if isinstance(e, BadRequest) or "Bad Request" in error_msg or "Invalid file_id" in error_msg:
                    log.critical("üö® CRITICAL | Skipping broken post due to BadRequest/Invalid file_id")
                    try:
                        maybe_delete_supabase_media(item, reason="bad_request")
                        await delete_from_buffer(application, item)
                        await send_progress_report(application)
                    except Exception as e2:
                        log.error(f"Failed to cleanup after BadRequest: {e2}")
                    # –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                    save_queue()
                    await asyncio.sleep(300)
                else:
                    # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                    POST_QUEUE.appendleft(item)
                    save_queue()
                    await asyncio.sleep(60)
        else:
            # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞—è - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            loaded = load_ready_files_to_queue()
            if loaded == 0:
                log.info("[DEBUG] Queue empty and no ready files. Waiting...")
            await asyncio.sleep(60)


async def restart_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–£–¥–∞–ª–µ–Ω–Ω—ã–π —Ä–µ—Å—Ç–∞—Ä—Ç –±–æ—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized restart attempt from user_id={user_id}")
        return
    
    log.info(f"[RESTART] Remote restart initiated by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "üöÄ –†–µ—Å—Ç–∞—Ä—Ç –∑–∞–ø—É—â–µ–Ω... –û–±–Ω–æ–≤–ª—è—é —Å–∏—Å—Ç–µ–º—É.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[RESTART] Failed to send confirmation message: {e}")
    
    # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ Python
    log.info("[RESTART] Executing restart...")
    os.execv(sys.executable, ['python'] + sys.argv)


async def stop_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–£–¥–∞–ª–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized stop attempt from user_id={user_id}")
        return
    
    log.info(f"[STOP] Remote shutdown initiated by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "üõë –°–∏—Å—Ç–µ–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∞–¥–º–∏–Ω–æ–º. –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞...",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[STOP] Failed to send confirmation message: {e}")
    
    # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ (–ø—Ä–µ–∫—Ä–∞—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö —Ñ–æ–Ω–æ–≤—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤)
    log.info("[STOP] Executing shutdown... All workers and conveyor system will be terminated.")
    os._exit(0)


async def pause_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°—Ç–∞–≤–∏—Ç –∫–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ –ø–∞—É–∑—É (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    global IS_PAUSED
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized pause attempt from user_id={user_id}")
        return
    
    IS_PAUSED = True
    log.info(f"[PAUSE] Conveyor paused by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "‚è∏ –ö–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ –ø–∞—É–∑–µ. –ü–æ—Å—Ç—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[PAUSE] Failed to send confirmation message: {e}")


async def resume_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ—Ç —Ä–∞–±–æ—Ç—É –∫–æ–Ω–≤–µ–π–µ—Ä–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    global IS_PAUSED
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized resume attempt from user_id={user_id}")
        return
    
    IS_PAUSED = False
    log.info(f"[RESUME] Conveyor resumed by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "‚ñ∂Ô∏è –ö–æ–Ω–≤–µ–π–µ—Ä –∑–∞–ø—É—â–µ–Ω! –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[RESUME] Failed to send confirmation message: {e}")


async def interval_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ò–∑–º–µ–Ω—è–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–π (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    global PUBLISH_INTERVAL_SECONDS
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized interval attempt from user_id={user_id}")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥—ã
    try:
        if not context.args or len(context.args) == 0:
            await update.message.reply_text(
                "‚ùå –£–∫–∞–∂–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö.\n–ü—Ä–∏–º–µ—Ä: /interval 60",
                parse_mode='HTML'
            )
            return
        
        new_interval_minutes = int(context.args[0])
        
        if new_interval_minutes < 1 or new_interval_minutes > 1440:
            await update.message.reply_text(
                "‚ùå –ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 1440 –º–∏–Ω—É—Ç (24 —á–∞—Å–∞).",
                parse_mode='HTML'
            )
            return
        
        PUBLISH_INTERVAL_SECONDS = new_interval_minutes * 60
        log.info(f"[INTERVAL] Changed to {new_interval_minutes} minutes by admin (user_id={user_id})")
        
        await update.message.reply_text(
            f"‚è∞ –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω: {new_interval_minutes} –º–∏–Ω. –°–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ–¥ —ç—Ç–æ –≤—Ä–µ–º—è.",
            parse_mode='HTML'
        )
    except ValueError:
        await update.message.reply_text(
            "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –£–∫–∞–∂–∏—Ç–µ —á–∏—Å–ª–æ.\n–ü—Ä–∏–º–µ—Ä: /interval 60",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[INTERVAL] Error: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞.",
            parse_mode='HTML'
        )


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized status attempt from user_id={user_id}")
        return
    
    try:
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        status_text = "‚úÖ –†–ê–ë–û–¢–ê–ï–¢" if not IS_PAUSED else "‚è∏ –ü–ê–£–ó–ê"
        
        # –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö
        interval_minutes = PUBLISH_INTERVAL_SECONDS // 60
        
        # –í—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ—Å—Ç–∞
        if LAST_POST_TIME is None:
            time_remaining = "‚ö° –ì–æ—Ç–æ–≤ –∫ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"
        else:
            next_post_time = LAST_POST_TIME + timedelta(seconds=PUBLISH_INTERVAL_SECONDS)
            now = datetime.now()
            time_diff = next_post_time - now
            
            if time_diff.total_seconds() <= 0:
                time_remaining = "‚ö° –ì–æ—Ç–æ–≤ –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"
            else:
                minutes = int(time_diff.total_seconds() // 60)
                seconds = int(time_diff.total_seconds() % 60)
                time_remaining = f"{minutes:02d}:{seconds:02d}"
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ—Ç–æ–≤—ã—Ö –≤–∏–¥–µ–æ –Ω–∞ —Å–∫–ª–∞–¥–µ
        ready_files = list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
        ready_count = len(ready_files)
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏
        queue_count = len(POST_QUEUE)
        video_queue_count = sum(1 for item in POST_QUEUE if item.get("type") == "video")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        status_message = (
            f"üìä <b>–ú–û–ù–ò–¢–û–†–ò–ù–ì –°–ò–°–¢–ï–ú–´:</b>\n\n"
            f"‚óè –°—Ç–∞—Ç—É—Å: {status_text}\n"
            f"‚óè –ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval_minutes} –º–∏–Ω.\n"
            f"‚óè –°–õ–ï–î–£–Æ–©–ò–ô –ü–û–°–¢ –ß–ï–†–ï–ó: {time_remaining}\n"
            f"‚óè –ì–æ—Ç–æ–≤—ã—Ö HD-–≤–∏–¥–µ–æ (—Å–∫–ª–∞–¥): {ready_count}/5\n"
            f"‚óè –í–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏ (–±–∞–∑–∞): {video_queue_count}\n"
            f"‚óè –í—Å–µ–≥–æ –≤ –æ—á–µ—Ä–µ–¥–∏: {queue_count}\n"
        )
        
        await update.message.reply_text(
            status_message,
            parse_mode='HTML'
        )
        
        log.info(f"[STATUS] System status requested by admin (user_id={user_id})")
        
    except Exception as e:
        log.error(f"[STATUS] Error: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã.",
            parse_mode='HTML'
        )


async def handle_channel_post(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    msg = update.channel_post
    if not msg:
        return

    chat_id = msg.chat_id
    message_id = msg.message_id

    log.info(f"channel_post received: chat_id={chat_id}, message_id={message_id}")

    # —Ä–µ–∞–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ –±—É—Ñ–µ—Ä–Ω—ã–π –∫–∞–Ω–∞–ª
    if chat_id != BUFFER_CHANNEL_ID:
        log.info(f"Ignored channel_post from chat_id={chat_id} (not BUFFER)")
        return

    # –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
    post = update.channel_post
    text_for_translate = ensure_utf8_text(post.text or post.caption or "")
    entities = post.entities or post.caption_entities
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ translate_text –∫–∞–∫ caption_ru
    caption_ru_original = text_for_translate
    
    # üîç –û–ü–†–ï–î–ï–õ–Ø–ï–ú SOURCE –¢–û–õ–¨–ö–û –ü–û –†–ï–ê–õ–¨–ù–û–ú–£ –í–•–û–î–£ (–Ω–∞ —ç—Ç–∞–ø–µ enqueue)
    # source –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ –Ω–∞–ª–∏—á–∏—é Instagram URL –≤ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú —Ç–µ–∫—Å—Ç–µ –ø–æ—Å—Ç–∞
    # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º text_for_translate –ø–æ—Å–ª–µ Whisper, —Ç.–∫. –æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–º–µ–Ω–µ–Ω –Ω–∞ transcript –±–µ–∑ —Å—Å—ã–ª–æ–∫
    instagram_url = None
    instagram_video_path = None
    
    # –ò—â–µ–º Instagram URL –≤ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú —Ç–µ–∫—Å—Ç–µ –ø–æ—Å—Ç–∞ –ò –≤ entities
    import re
    instagram_pattern = r'(?:https?://)?(?:www\.)?(?:instagram\.com|instagr\.am)/(?:p|reel|reels|stories|tv)/[^\s]*'
    
    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º entities (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) - URL –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–∞–º –¥–∞–∂–µ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç
    if entities and text_for_translate:
        for entity in entities:
            if entity.type == MessageEntityType.URL:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø–æ offset –∏ length
                try:
                    url_text = text_for_translate[entity.offset:entity.offset + entity.length]
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ Instagram
                    if re.search(instagram_pattern, url_text, re.IGNORECASE):
                        instagram_url = url_text
                        # –î–æ–±–∞–≤–ª—è–µ–º https:// –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                        if not instagram_url.startswith('http'):
                            instagram_url = 'https://' + instagram_url
                        log.info(f"[SMART ROUTING] Instagram URL found in entities: {instagram_url[:50]}...")
                        break
                except (IndexError, AttributeError) as e:
                    log.warning(f"[SMART ROUTING] Error extracting URL from entity: {e}")
                    continue
    
    # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ entities, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π regex)
    if not instagram_url and text_for_translate:
        match = re.search(instagram_pattern, text_for_translate, re.IGNORECASE)
        if match:
            instagram_url = match.group(0)
            # –î–æ–±–∞–≤–ª—è–µ–º https:// –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            if not instagram_url.startswith('http'):
                instagram_url = 'https://' + instagram_url
            log.info(f"[SMART ROUTING] Instagram URL found in text: {instagram_url[:50]}...")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º source: –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω Instagram URL ‚Üí "instagram", –∏–Ω–∞—á–µ ‚Üí "telegram"
    # –≠—Ç–æ –ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –º–µ—Å—Ç–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è source - –¥–∞–ª—å—à–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ item["source"]
    source = "instagram" if instagram_url else "telegram"
    log.info(f"[SOURCE] Determined at enqueue (by input): {source} (instagram_url={'found' if instagram_url else 'not found'})")
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ Instagram (–µ—Å–ª–∏ —ç—Ç–æ Instagram –∏—Å—Ç–æ—á–Ω–∏–∫)
    if instagram_url:
        try:
            instagram_video_path = download_from_instagram(instagram_url)
            if not instagram_video_path:
                error_msg = f"‚ùå [INSTAGRAM] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ URL: {instagram_url}"
                log.error(error_msg)
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –∞–¥–º–∏–Ω—É
                try:
                    await context.bot.send_message(
                        chat_id=ADMIN_TELEGRAM_ID,
                        text=f"üö® <b>Instagram Download Failed</b>\n\n{error_msg}",
                        parse_mode='HTML'
                    )
                except:
                    pass
                return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            log.info(f"[SMART ROUTING] ‚úÖ Video downloaded from Instagram: {instagram_video_path.name}")
            # –ü–ï–†–ï–û–ü–†–ï–î–ï–õ–Ø–ï–ú source: –µ—Å–ª–∏ –≤–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ –∏–∑ Instagram, —ç—Ç–æ —Ç–æ—á–Ω–æ Instagram –∏—Å—Ç–æ—á–Ω–∏–∫
            source = "instagram"
            log.info(f"[SOURCE] Re-determined after successful Instagram download: {source}")
        except Exception as e:
            error_msg = f"‚ùå [INSTAGRAM] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {e}"
            log.error(error_msg)
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –∞–¥–º–∏–Ω—É
            try:
                await context.bot.send_message(
                    chat_id=ADMIN_TELEGRAM_ID,
                    text=f"üö® <b>Instagram Download Error</b>\n\n{error_msg}",
                    parse_mode='HTML'
                )
            except:
                pass
            return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É

    # üé§ WHISPER: –ï—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ (Telegram –∏–ª–∏ Instagram), –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
    whisper_transcript = None
    video_source_path = None
    
    if instagram_video_path:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–∞—á–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –∏–∑ Instagram
        video_source_path = instagram_video_path
        log.info("[WHISPER] Processing Instagram video...")
    elif post.video:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏–¥–µ–æ –∏–∑ Telegram
        log.info("[WHISPER] Processing Telegram video...")
    
    if video_source_path or post.video:
        try:
            if not video_source_path:
                # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ Telegram
                log.info("[WHISPER] Video detected, attempting transcription...")
                tmp_dir = Path("tmp_media")
                tmp_dir.mkdir(exist_ok=True)
                video_file = await context.bot.get_file(post.video.file_id)
                tmp_video_path = tmp_dir / f"whisper_video_{post.video.file_id[:10]}.mp4"
                await video_file.download_to_drive(custom_path=str(tmp_video_path))
                video_source_path = tmp_video_path
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
            whisper_transcript = get_video_transcript(video_source_path)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –∏–∑ Telegram, Instagram —É–¥–∞–ª–∏–º –ø–æ–∑–∂–µ)
            if post.video and video_source_path.exists():
                video_source_path.unlink()
                log.info("[WHISPER] Temporary Telegram video file deleted")
            
            if whisper_transcript:
                log.info(f"[WHISPER] ‚úÖ Transcription successful: {len(whisper_transcript)} chars")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
                text_for_translate = whisper_transcript
            else:
                log.warning("[WHISPER] Transcription failed, using caption text")
        except Exception as e:
            log.error(f"[WHISPER] Video transcription error: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ

    log.info("RAW before translate: %s", text_for_translate[:200] if text_for_translate else "(empty)")

    # –ì–ê–†–ê–ù–¢–ò–†–£–ï–ú –ø–µ—Ä–µ–≤–æ–¥ –í–°–ï–• –ø–æ—Å—Ç–æ–≤
    translation_result = None
    if caption_ru_original.strip() or whisper_transcript:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º entities –≤ –º–∞—Ä–∫–µ—Ä—ã –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º (—Ç–æ–ª—å–∫–æ –¥–ª—è caption_ru)
        caption_ru_prepared = entities_to_markers(caption_ru_original, entities) if caption_ru_original else ""
        # –í—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é —Å —Ç—Ä–µ–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        translation_result = await translate_text(
            caption_ru=caption_ru_prepared,
            asr_ru=whisper_transcript or "",
            base_hashtags=HASHTAGS_BLOCK
        )
    else:
        # Fallback –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
        translation_result = {
            'voice': "Qiziqarli video. Oxirigacha ko'ring.",
            'caption': "Qiziqarli video. Oxirigacha ko'ring.",
            'hashtags': ""
        }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è
    voice_uz = translation_result.get('voice', '')
    caption_uz = translation_result.get('caption', '')
    extra_hashtags = translation_result.get('hashtags', '')
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º CTA –ø—Ä–∞–≤–∏–ª–æ (–∫–∞–∂–¥—ã–µ 2 –ø–æ—Å—Ç–∞)
    use_cta, cta_text, post_counter = next_post_cta_rule()
    log.info(f"[CTA] Post #{post_counter}: use_cta={use_cta}, cta_text={cta_text[:30] if cta_text else None}...")
    
    # –°—Ç—Ä–æ–∏–º —Ç–µ–∫—Å—Ç –¥–ª—è TTS (VOICE_UZ + CTA, –ë–ï–ó footer –∏ —Ö—ç—à—Ç–µ–≥–æ–≤)
    text_for_voice = build_voice_for_tts(voice_uz, cta_text if use_cta else None)
    log.info(f"[TTS] Voice text length: {len(text_for_voice)} chars")
    
    # üéôÔ∏è ELEVENLABS: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–∑–≤—É—á–∫—É –¥–ª—è –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ (–Ω–µ —Ç–æ–ª—å–∫–æ Instagram)
    voiceover_path = None
    has_voiceover = False
    
    if text_for_voice.strip():
        try:
            log.info(f"[ELEVENLABS] Generating voiceover for source={source}...")
            voiceover_path = generate_voiceover(text_for_voice)
            
            if voiceover_path:
                has_voiceover = True
                log.info(f"[ELEVENLABS] ‚úÖ Voiceover ready: {voiceover_path.name} (voiceover: True)")
            else:
                log.warning("[ELEVENLABS] Voiceover generation failed, continuing without voice")
        except Exception as e:
            log.error(f"[ELEVENLABS] Voiceover generation error: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –æ–∑–≤—É—á–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º caption
    caption_uz = sanitize_post(caption_uz)
    caption_uz = remove_comment_phrases(caption_uz)
    
    # –°—Ç—Ä–æ–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π caption –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (caption + hashtags + footer)
    final_text = build_caption_for_post(
        caption_uz=caption_uz,
        base_hashtags=HASHTAGS_BLOCK,
        extra_hashtags=extra_hashtags,
        footer_html=FOOTER_HTML
    )
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    final_text = format_post_structure(final_text)
    final_text = clean_caption(final_text)
    final_text = ensure_footer(final_text)
    final_text = append_branding(final_text)
    
    log.info("FINAL after translate: %s", final_text[:200] if final_text else "(empty)")

    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª
    if post.photo:
        # –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        item = {
            "type": "photo",
            "file_id": post.photo[-1].file_id,
            "caption": final_text,
            "buffer_message_id": message_id,
            "buffer_chat_id": chat_id,
            "translation_cost": TRANSLATION_LAST_COST,
            "source": source,  # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        }
    elif post.video or instagram_video_path:
        # –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ (Telegram –∏–ª–∏ Instagram), –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        item = {
            "type": "video",
            "file_id": post.video.file_id if post.video else "instagram_source",
            "caption": final_text,
            "instagram_video_path": str(instagram_video_path) if instagram_video_path else None,
            "buffer_message_id": message_id,
            "buffer_chat_id": chat_id,
            "translation_cost": TRANSLATION_LAST_COST,
            "voiceover": has_voiceover,  # üéôÔ∏è –§–ª–∞–≥ –¥–ª—è Smart Routing
            "voiceover_path": str(voiceover_path) if voiceover_path else None,  # üéôÔ∏è –ü—É—Ç—å –∫ –æ–∑–≤—É—á–∫–µ
            "instagram_source": instagram_url if instagram_url else None,
            "source": source,  # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        }
    else:
        # –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –≤–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –∫–∞—Ä—É—Å–µ–ª–∏
        log.info("[DEBUG] –†–µ–∂–∏–º –∫–∞—Ä—É—Å–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∞–∫—Ç–∏–≤–µ–Ω")
        item = {
            "type": "carousel_pending",
            "text": final_text,
            "buffer_message_id": message_id,
            "buffer_chat_id": chat_id,
            "translation_cost": TRANSLATION_LAST_COST,
            "source": source,  # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–µ–π –≤–∫–ª—é—á–µ–Ω–∞
    h = post_hash(item)
    if h in SEEN_HASHES:
        log.info("Duplicate skipped")
        return
    SEEN_HASHES.add(h)
    save_seen()
    log.info("Queue push type=%s size_before=%s", item["type"], len(POST_QUEUE))
    POST_QUEUE.append(item)
    save_queue()
    log.info("Post queued. Queue size=%s", len(POST_QUEUE))
    
    # üéôÔ∏è –û–ó–í–£–ß–ö–ê: –ù–ï —É–¥–∞–ª—è–µ–º - –æ–Ω–∞ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ –≤ CONVEYOR
    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ prepare_video_for_ready
    if voiceover_path:
        log.info(f"[ELEVENLABS] Voiceover saved for later use: {voiceover_path.name}")
    
    # ‚úÖ Instagram –≤–∏–¥–µ–æ –ù–ï —É–¥–∞–ª—è–µ–º - –æ–Ω–æ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ CONVEYOR
    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤ prepare_video_for_ready


def main() -> None:
    load_queue()
    load_seen()
    load_stats()
    load_published_texts()
    load_last_post_time()
    log.info(f"INFO | [CONFIG] Current publish interval: {PUBLISH_INTERVAL_SECONDS // 60} minutes")
    log.info("System ready. All social networks optimized.")
    log.info("Golden Template Active. Content Separated.")
    video_count = sum(1 for it in POST_QUEUE if it.get("type") == "video")
    est_hours = (video_count + 59) // 60  # 1 per hour -> videos count hours
    log.info(f"INFO | [QUEUE] Found {video_count} posts for Instagram. Estimated completion time: {est_hours} hours.")

    async def post_init(app: Application) -> None:
        # üö® TOTAL QUEUE PURGE: –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ
        global POST_QUEUE
        try:
            original_size = len(POST_QUEUE)
            POST_QUEUE.clear()  # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            save_queue()
            
            if original_size > 0:
                log.info(f"üßπ [TOTAL PURGE] Cleared entire queue ({original_size} old items removed)")
            else:
                log.info("[TOTAL PURGE] Queue was already empty.")
        except Exception as e:
            log.error(f"[TOTAL PURGE] Error during queue cleanup: {e}")
        
        # üîÑ STARTUP SYNC: –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∏–∑ ready_to_publish
        try:
            log.info("[STARTUP] Loading fresh ready files from disk...")
            loaded = load_ready_files_to_queue()
            if loaded > 0:
                log.info(f"‚úÖ [SUCCESS] Queue refreshed from disk. Starting instant post with 4 hashtags (incl. #qiziqarli) + AI tag.")
                log.info(f"‚úÖ [STARTUP] Loaded {loaded} ready files into queue. First Strike ready.")
            else:
                log.warning("[STARTUP] No ready files found on disk.")
        except Exception as e:
            log.error(f"[STARTUP] Error loading ready files: {e}")
        
        # –†–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ Supabase –æ—Ç —Å–∏—Ä–æ—Ç—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º
        try:
            await cleanup_supabase_orphans(dry_run=False)
        except Exception as e:
            log.error(f"[Supabase] cleanup_supabase_orphans failed at startup: {e}")
        
        log.info("[CONVEYOR] System initialization...")
        
        # AUTO-PURGE: –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª—ã–µ —Ñ–∞–π–ª—ã –∏–∑ ready_to_publish
        try:
            ready_files = list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
            purged_count = 0
            for ready_file in ready_files:
                file_size_mb = ready_file.stat().st_size / (1024 * 1024)
                if file_size_mb > 95:
                    log.warning(f"[AUTO-PURGE] Deleting oversized file: {ready_file.name} ({file_size_mb:.2f} MB)")
                    ready_file.unlink()
                    # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–∂–µ
                    meta_file = ready_file.with_suffix('.json')
                    if meta_file.exists():
                        meta_file.unlink()
                    purged_count += 1
            if purged_count > 0:
                log.info(f"[AUTO-PURGE] Removed {purged_count} oversized files. Conveyor will regenerate them.")
            else:
                log.info("[AUTO-PURGE] No oversized files found. All clear.")
        except Exception as e:
            log.error(f"[AUTO-PURGE] Error during cleanup: {e}")
        
        # üßπ TMP_MEDIA CLEANUP: –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        try:
            tmp_media_dir = Path("tmp_media")
            if tmp_media_dir.exists():
                old_files = []
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ .mp4 –∏ .MP4 —Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ –ø–æ–¥–ø–∞–ø–æ–∫)
                for pattern in ["*.mp4", "*.MP4"]:
                    for file in tmp_media_dir.glob(pattern):
                        if file.is_file():
                            try:
                                file.unlink()
                                old_files.append(file.name)
                            except Exception as e:
                                log.warning(f"[TMP_CLEANUP] Failed to delete {file.name}: {e}")
                
                if old_files:
                    log.info(f"üßπ [TMP_CLEANUP] Removed {len(old_files)} old temporary files from tmp_media/")
                else:
                    log.info("[TMP_CLEANUP] No old temporary files found in tmp_media/")
        except Exception as e:
            log.error(f"[TMP_CLEANUP] Error during tmp_media cleanup: {e}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º workers
        asyncio.create_task(post_worker(app))
        asyncio.create_task(daily_report_scheduler(app))
        asyncio.create_task(history_log_scheduler())
        asyncio.create_task(maintain_ready_posts_worker(app))  # CONVEYOR worker
        
        log.info("[CONVEYOR] All workers started. First Strike and Conveyor system active.")

    app = (
        Application.builder()
        .token(TELEGRAM_BOT_TOKEN)
        .read_timeout(60)
        .connect_timeout(60)
        .pool_timeout(60)
        .write_timeout(60)
        .post_init(post_init)
        .build()
    )

    # –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)
    app.add_handler(CommandHandler("restart", restart_command))
    app.add_handler(CommandHandler("stop", stop_command))
    app.add_handler(CommandHandler("pause", pause_command))
    app.add_handler(CommandHandler("resume", resume_command))
    app.add_handler(CommandHandler("interval", interval_command))
    app.add_handler(CommandHandler("status", status_command))

    # –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ—Å—Ç–æ–≤ –∏–∑ –∫–∞–Ω–∞–ª–æ–≤
    app.add_handler(MessageHandler(filters.UpdateType.CHANNEL_POST, handle_channel_post))

    log.info("‚úÖ Bot is running. Waiting for channel posts...")
    log.info("üîß Remote management active. New Instagram schedule applied.")
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
