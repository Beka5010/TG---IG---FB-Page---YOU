import os
import sys
import json
import logging
import asyncio
import time as time_module
import hashlib
import random
import uuid
import mimetypes
import textwrap
import re
import shutil
import subprocess
from typing import Optional
from collections import deque
from pathlib import Path
from datetime import datetime, time, timedelta
import numpy as np
from dotenv import load_dotenv

import requests
from PIL import Image, ImageDraw, ImageFont
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS
import moviepy.editor as mpe
from moviepy.editor import VideoFileClip, AudioFileClip, ColorClip, TextClip, CompositeVideoClip, ImageClip, concatenate_videoclips, concatenate_audioclips, CompositeAudioClip
from moviepy.video.fx import all as vfx_all
from moviepy.audio.fx import all as afx_all
from openai import OpenAI
from telegram import Update
from telegram.constants import MessageEntityType
from telegram.ext import Application, MessageHandler, CommandHandler, ContextTypes, filters
from telegram.error import BadRequest
from supabase import create_client, Client

load_dotenv()

logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(message)s",
    level=logging.INFO
)
log = logging.getLogger(__name__)


def get_env_str(name: str) -> str:
    v = os.getenv(name, "").strip()
    if not v:
        raise RuntimeError(f"Missing env var: {name}")
    return v


def get_env_int(name: str) -> int:
    v = os.getenv(name, "").strip()
    if not v:
        raise RuntimeError(f"Missing env var: {name}")
    return int(v)


TELEGRAM_BOT_TOKEN = get_env_str("TELEGRAM_BOT_TOKEN")
BUFFER_CHANNEL_ID = get_env_int("BUFFER_CHANNEL_ID")
MAIN_CHANNEL_ID = get_env_int("MAIN_CHANNEL_ID")
ADMIN_TELEGRAM_ID = int(os.getenv("ADMIN_ID", "5675979056") or 5675979056)
REPORT_CHAT_ID = int(os.getenv("REPORT_CHAT_ID", "5675979056") or 0)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()

# ElevenLabs settings
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY", "").strip()
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "s756tFIFJ9r8dOGB5rlK").strip()

# Supabase settings
SUPABASE_URL = os.getenv("SUPABASE_URL", "").strip()
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY", "").strip()
SUPABASE_BUCKET = os.getenv("SUPABASE_BUCKET", "").strip()
SUPABASE_TIMEOUT_SECONDS = int(os.getenv("SUPABASE_TIMEOUT_SECONDS", "120"))

# Instagram settings
ENABLE_INSTAGRAM = os.getenv("ENABLE_INSTAGRAM", "1").strip()
IG_USER_ID = os.getenv("IG_USER_ID", "").strip()
IG_ACCESS_TOKEN = os.getenv("IG_ACCESS_TOKEN", "").strip()
IG_GRAPH_VERSION = os.getenv("IG_GRAPH_VERSION", "v21.0").strip()
IG_TIMEOUT_SECONDS = int(os.getenv("IG_TIMEOUT_SECONDS", "300"))
IG_POLL_SECONDS = int(os.getenv("IG_POLL_SECONDS", "30"))
IG_POLL_MAX_TRIES = int(os.getenv("IG_POLL_MAX_TRIES", "10"))

# Facebook settings
ENABLE_FB = os.getenv("ENABLE_FB", "1").strip() or "1"
FB_PAGE_ID = os.getenv("FB_PAGE_ID", "").strip()
FB_PAGE_TOKEN = os.getenv("FB_PAGE_TOKEN", "").strip()
FB_GRAPH_VERSION = os.getenv("FB_GRAPH_VERSION", "v21.0").strip()
FB_TIMEOUT_SECONDS = int(os.getenv("FB_TIMEOUT_SECONDS", "300"))

POST_DELAY_SECONDS_RAW = int(os.getenv("POST_DELAY_SECONDS", "1800"))  # 30 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: 1 —á–∞—Å (3600 —Å–µ–∫) –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
POST_DELAY_SECONDS = max(POST_DELAY_SECONDS_RAW, 3600)

# –§–ª–∞–≥ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –±—É—Ñ–µ—Ä–∞ –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
DELETE_FROM_BUFFER = int(os.getenv("DELETE_FROM_BUFFER", "1"))  # –í–∫–ª—é—á–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –§–ª–∞–≥ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —É—Å–ø–µ—à–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
REPORT_AFTER_POST = int(os.getenv("REPORT_AFTER_POST", "1"))

CHANNEL_LINK = "https://t.me/+19xSNtVpJx1hZGQy"
FOOTER_HTML = f"\n\n| <a href=\"{CHANNEL_LINK}\">Haqiqat üß†</a> | <a href=\"{CHANNEL_LINK}\">Kanalga obuna bo'ling</a>"
BRANDED_LINK = f"üëâ Batafsil: {CHANNEL_LINK}"
HASHTAGS_BLOCK = "#haqiqat #uzbekistan #qiziqarli"
PUBLISH_INTERVAL_SECONDS = 3600  # 60 –º–∏–Ω—É—Ç
LINK_BLOCK_HTML = '| <a href="https://t.me/+19xSNtVpjx1hZGQy">Haqiqat üß† | Kanalga obuna bo\'ling</a> |'
CAPTION_MAX_LENGTH = 900  # –õ–∏–º–∏—Ç –¥–ª—è caption

# –ê–¥–º–∏–Ω-—á–∞—Ç –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
ADMIN_CHAT_ID = os.getenv("ADMIN_CHAT_ID", "").strip()
if ADMIN_CHAT_ID:
    try:
        ADMIN_CHAT_ID = int(ADMIN_CHAT_ID)
    except ValueError:
        ADMIN_CHAT_ID = None
else:
    ADMIN_CHAT_ID = None

openai_client = None
if os.getenv("OPENAI_API_KEY"):
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

supabase_client: Optional[Client] = None

# message_id -> {emoji: count}
REACTIONS = {}
# message_id -> {user_id: emoji}
USER_REACTIONS = {}


POST_QUEUE = deque()
VIDEO_PROCESSING_QUEUE = asyncio.Queue()  # FIX B: –û—á–µ—Ä–µ–¥—å –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
IS_POSTING = False
# –ü–µ—Ä–≤–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ä–µ—Å—Ç–∞—Ä—Ç–∞ ‚Äî –ø—É–±–ª–∏–∫—É–µ–º —Å—Ä–∞–∑—É –ø–µ—Ä–≤—ã–π –ø–æ—Å—Ç –±–µ–∑ –æ–∂–∏–¥–∞–Ω–∏–π
FIRST_RUN_IMMEDIATE = True

# üéõÔ∏è MIXED QUEUE 4+4: –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
VOICEOVER_POSTS_COUNT = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ—Å—Ç–æ–≤ —Å –æ–∑–≤—É—á–∫–æ–π
NO_VOICEOVER_POSTS_COUNT = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ—Å—Ç–æ–≤ –±–µ–∑ –æ–∑–≤—É—á–∫–∏
CURRENT_BLOCK_TYPE = "voiceover"  # –¢–µ–∫—É—â–∏–π —Ç–∏–ø –±–ª–æ–∫–∞: "voiceover" –∏–ª–∏ "no_voiceover"
# SMART CONTROL: –°–∏—Å—Ç–µ–º–∞ –ø–∞—É–∑—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π
IS_PAUSED = False

# –°–ò–°–¢–ï–ú–ê –ö–û–ù–í–ï–ô–ï–†: –ü–∞–ø–∫–∞ –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
READY_TO_PUBLISH_DIR = Path("ready_to_publish")
READY_TO_PUBLISH_DIR.mkdir(exist_ok=True)
TARGET_READY_POSTS = 10  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º 10 –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ (5 –¥–Ω–µ–π –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã)
IS_PREPARING = False  # –§–ª–∞–≥ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏


async def safe_unlink(path: Path | str, retries: int = 10, delay: float = 0.4):
    """Async-safe unlink with retries to handle Windows file locks (WinError 32).
    Does not raise; only logs on failure.
    """
    p = Path(path)
    if not p.exists():
        return
    for i in range(retries):
        try:
            p.unlink()
            return
        except PermissionError:
            await asyncio.sleep(delay)
        except Exception:
            log.exception(f"[CLEANUP] Failed to delete {path}")
            return
    log.error(f"[CLEANUP] Still locked after retries: {path}")


def _clamp_t(t: float, duration: float, eps: float = 0.25) -> float:
    if duration is None:
        return t
    return max(0.0, min(float(t), max(0.0, float(duration) - eps)))

QUEUE_FILE = Path("post_queue.json")
SEEN_FILE = Path("seen_posts.json")
SEEN_HASHES = set()
SEEN_FILE_IDS = set()

# IG —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–π (–≤ –ø–∞–º—è—Ç–∏, –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ)
IG_SCHEDULE = {
    "date": None,
    "morning_videos": 0,      # –¥–æ 14:00, –º–∞–∫—Å–∏–º—É–º 3
    "afternoon_videos": 0,    # –ø–æ—Å–ª–µ 16:00, –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ 1 –≤ —á–∞—Å
    "afternoon_carousels": 0  # –ø–æ—Å–ª–µ 15:00, –º–∞–∫—Å–∏–º—É–º 2
}

# –†–∞–∑–æ–≤—ã–π —Ñ–æ—Ä—Å-—Ç–µ—Å—Ç –∫–∞—Ä—É—Å–µ–ª–∏ (–∏–≥–Ω–æ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è/–∑–∞–¥–µ—Ä–∂–µ–∫ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ carousel_pending)
FORCE_CAROUSEL_TEST = True

# –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –ø—É–±–ª–∏–∫–∞—Ü–∏–π
LAST_PHOTO_TIME = None
LAST_VIDEO_TIME = None
LAST_POST_TIME = None
LAST_POST_TIME_FILE = Path("last_post_time.json")
FORCE_POST_NOW = False  # –§–ª–∞–≥ –¥–ª—è —Ñ–æ—Ä—Å-–ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (/postnow)
POSTNOW_EVENT = asyncio.Event()  # Event –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è –≤–æ—Ä–∫–µ—Ä–∞
VIDEO_MIRROR_TOGGLE = False


async def sleep_or_postnow(seconds: int) -> bool:
    """
    True  -> –ø—Ä–æ—Å–Ω—É–ª–∏—Å—å –∏–∑-–∑–∞ /postnow
    False -> –¥–æ—Å–∏–¥–µ–ª–∏ —Ç–∞–π–º–µ—Ä –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
    """
    global FORCE_POST_NOW
    # –ï—Å–ª–∏ /postnow –∞–∫—Ç–∏–≤–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞—É–∑—É –∏ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –ø—Ä–æ—Å–Ω—É–ª–∏—Å—å –ø–æ POSTNOW
    if FORCE_POST_NOW:
        log.info("[SCHEDULER] POSTNOW override: skip cooldown sleep")
        return True
    try:
        await asyncio.wait_for(POSTNOW_EVENT.wait(), timeout=seconds)
        POSTNOW_EVENT.clear()  # –í–ê–ñ–ù–û: —Å–±—Ä–æ—Å–∏—Ç—å, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç ¬´–≤–µ—á–Ω–æ –≤–∫–ª—é—á—ë–Ω¬ª
        return True
    except asyncio.TimeoutError:
        return False


# –•—Ä–∞–Ω–∏–ª–∏—â–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
PUBLISHED_TEXTS_FILE = Path("published_texts.json")
PUBLISHED_TEXTS = []  # –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
MAX_PUBLISHED_TEXTS = 50  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –ø–æ—Å—Ç–æ–≤

# –ò—Å—Ç–æ—Ä–∏—è –∏ –æ—Ç—á—ë—Ç—ã
HISTORY_LOG = Path("history.log")
REPORTS_DIR = Path("reports")
DAILY_COST_USD = 0.0
TRANSLATION_LAST_COST = 0.0

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
PUBLISHED_TEXTS_FILE = Path("published_texts.json")
PUBLISHED_TEXTS = []  # –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
MAX_PUBLISHED_TEXTS = 50  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –ø–æ—Å—Ç–æ–≤


def get_supabase_client() -> Optional[Client]:
    """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase –∫–ª–∏–µ–Ω—Ç–∞."""
    global supabase_client
    if supabase_client:
        return supabase_client
    
    if not (SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY):
        log.warning("Supabase credentials are not set")
        return None
    
    try:
        supabase_client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
    except Exception as e:
        log.error(f"Failed to create Supabase client: {e}")
        supabase_client = None
    
    return supabase_client


def upload_to_supabase(local_file_path: str, content_type: str) -> Optional[str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –≤ Supabase Storage –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É–±–ª–∏—á–Ω—ã–π URL.
    –ù–µ –º–µ–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –±–æ—Ç–∞.
    """
    client = get_supabase_client()
    if not client:
        return None
    
    if not SUPABASE_BUCKET:
        log.warning("Supabase bucket name is not set")
        return None
    
    path_obj = Path(local_file_path)
    if not path_obj.exists():
        log.warning(f"Supabase upload skipped, file not found: {local_file_path}")
        return None
    
    size_mb = path_obj.stat().st_size / (1024 * 1024)
    log.info(f"[DEBUG] File size: {size_mb:.2f} MB")

    unique_name = f"{int(datetime.now().timestamp() * 1000)}_{uuid.uuid4().hex}{path_obj.suffix}"
    upload_url = f"{SUPABASE_URL.rstrip('/')}/storage/v1/object/{SUPABASE_BUCKET}/{unique_name}"
    headers = {
        "Authorization": f"Bearer {SUPABASE_SERVICE_ROLE_KEY}",
        "apikey": SUPABASE_SERVICE_ROLE_KEY,
        "Content-Type": content_type or "application/octet-stream",
        "x-upsert": "false",
    }
    
    try:
        with path_obj.open("rb") as f:
            resp = requests.post(
                upload_url,
                data=f,
                headers=headers,
                timeout=SUPABASE_TIMEOUT_SECONDS,
            )
        resp.raise_for_status()
        public_url = client.storage.from_(SUPABASE_BUCKET).get_public_url(unique_name)
        log.info(f"[Supabase] File uploaded: {public_url}")
        return public_url
    except Exception as e:
        log.error(f"Supabase upload failed: {e}")
        return None


def delete_supabase_file(public_url: str):
    """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ Supabase –ø–æ –ø—É–±–ª–∏—á–Ω–æ–º—É URL."""
    client = get_supabase_client()
    if not client:
        return
    if not (public_url and SUPABASE_BUCKET):
        return

    marker = "/storage/v1/object/public/"
    try:
        if marker not in public_url:
            raise ValueError("public url format unexpected")
        path_part = public_url.split(marker, 1)[1]
        bucket_from_url, key = path_part.split("/", 1)
        if bucket_from_url != SUPABASE_BUCKET:
            log.warning(f"[Supabase] Bucket mismatch when deleting: url_bucket={bucket_from_url}, env_bucket={SUPABASE_BUCKET}")
        if not key:
            raise ValueError("empty storage key")
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏–∑ –±–∞–∫–µ—Ç–∞ (–∫–ª—é—á –±–µ–∑ –∏–º–µ–Ω–∏ –±–∞–∫–µ—Ç–∞)
        client.storage.from_(SUPABASE_BUCKET).remove([key])
        log.info(f"INFO | [CLEANUP] Supabase storage cleared for file: {key}")
    except Exception as e:
        log.warning(f"[Supabase] File delete failed: {e}")


def delete_supabase_files(urls: list[str]):
    """–£–¥–∞–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –∏–∑ Supabase."""
    for url in urls or []:
        delete_supabase_file(url)


def supabase_key_from_url(public_url: str) -> Optional[str]:
    marker = "/storage/v1/object/public/"
    if not public_url or marker not in public_url:
        return None
    try:
        path_part = public_url.split(marker, 1)[1]
        bucket_from_url, key = path_part.split("/", 1)
        if bucket_from_url != SUPABASE_BUCKET:
            return None
        return key
    except Exception:
        return None


def maybe_delete_supabase_media(item: dict, reason: str):
    """
    –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ Supabase, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —É–¥–∞–ª—ë–Ω.
    –ß—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å FB –ø—É–±–ª–∏–∫–∞—Ü–∏—é, –ø–æ—Å–ª–µ IG —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ FB –æ—Ç–∫–ª—é—á—ë–Ω.
    """
    if not item or item.get("supabase_deleted"):
        return
    public_url = item.get("supabase_url")
    if not public_url:
        return

    if reason == "instagram" and ENABLE_FB == "1" and not item.get("fb_published"):
        log.info("[DEBUG] Skip delete after IG publish because FB is enabled; will delete after FB.")
        return

    delete_supabase_file(public_url)
    item["supabase_deleted"] = True


async def cleanup_supabase_orphans(dry_run: bool = True) -> list[str]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–∞–∫–µ—Ç–∞ media —Å —Ç–µ–∫—É—â–µ–π POST_QUEUE –∏ —É–¥–∞–ª—è–µ—Ç (–∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç) –ª–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã.
    dry_run=True ‚Äî —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–∏—Ä–æ—Ç.
    """
    client = get_supabase_client()
    if not client:
        log.warning("[Supabase] cleanup aborted: client not available")
        return []
    if not SUPABASE_BUCKET:
        log.warning("[Supabase] cleanup aborted: bucket not configured")
        return []

    keep_keys = set()
    for it in POST_QUEUE:
        k = supabase_key_from_url(it.get("supabase_url"))
        if k:
            keep_keys.add(k)

    orphans: list[str] = []
    offset = 0
    page_size = 1000
    while True:
        try:
            files = client.storage.from_(SUPABASE_BUCKET).list(
                path="",
                options={"limit": page_size, "offset": offset, "sortBy": {"column": "name", "order": "asc"}},
            )
        except Exception as e:
            log.error(f"[Supabase] cleanup list failed: {e}")
            break
        if not files:
            break
        for f in files:
            name = f.get("name")
            if name and name not in keep_keys:
                orphans.append(name)
        if len(files) < page_size:
            break
        offset += page_size

    if dry_run:
        log.info(f"[Supabase] cleanup dry-run: orphans={orphans}")
        return orphans

    for name in orphans:
        try:
            client.storage.from_(SUPABASE_BUCKET).remove([name])
            log.info(f"INFO | [CLEANUP] Supabase storage cleared for file: {name}")
        except Exception as e:
            log.warning(f"[Supabase] cleanup remove failed for {name}: {e}")
    return orphans


def ig_post(path: str, data: dict) -> dict:
    """POST –∫ Instagram Graph API —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://graph.facebook.com/{IG_GRAPH_VERSION}/{path.lstrip('/')}"
    try:
        resp = requests.post(url, data=data, timeout=IG_TIMEOUT_SECONDS)
        text = (resp.text or "")[:500]
        log.info(f"IG_POST url={url} status={resp.status_code} resp={text}")
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        log.error(f"IG_POST_FAIL url={url} error={e}")
        return {}


def ig_get(path: str, params: dict) -> dict:
    """GET –∫ Instagram Graph API —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://graph.facebook.com/{IG_GRAPH_VERSION}/{path.lstrip('/')}"
    try:
        resp = requests.get(url, params=params, timeout=IG_TIMEOUT_SECONDS)
        text = (resp.text or "")[:500]
        log.info(f"IG_GET url={resp.url} status={resp.status_code} resp={text}")
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        log.error(f"IG_GET_FAIL url={url} error={e}")
        return {}


async def publish_to_instagram(item: dict):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ–¥–∏–∞ –≤ Instagram –ø–æ –ø—É–±–ª–∏—á–Ω–æ–º—É URL –∏–∑ Supabase. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
    if ENABLE_INSTAGRAM != "1":
        return True
    if not IG_USER_ID or not IG_ACCESS_TOKEN:
        log.warning("Instagram disabled: missing IG_USER_ID or IG_ACCESS_TOKEN")
        return True

    media_type = item.get("type")
    if media_type == "text":
        log.info("Instagram skip: text post")
        return True
    
    if media_type not in ("video",):
        log.info(f"Instagram skip: unsupported type {media_type}")
        return True
    
    supabase_url = item.get("supabase_url")
    if not supabase_url:
        log.warning("Instagram skip: no supabase_url")
        return True
    
    caption = item.get("caption") or item.get("text") or ""
    # Clean strong-markdown and log final caption for IG
    caption = (caption or "").replace("**", "")
    log.info(f"CAPTION_TO_IG: {caption[:300]}")
    safe_caption = clean_social_text(caption)
    log.info(f"IG_CAPTION len={len(safe_caption)} text={safe_caption[:300]}")

    # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
    if media_type == "photo":
        payload = {
            "image_url": supabase_url,
            "caption": safe_caption,
            "access_token": IG_ACCESS_TOKEN,
        }
    else:
        payload = {
            "media_type": "REELS",
            "video_url": supabase_url,
            "caption": safe_caption,
            "audio_type": "ORIGINAL",
            "access_token": IG_ACCESS_TOKEN,
        }
    
    res = ig_post(f"{IG_USER_ID}/media", payload)
    log.info(f"IG_CREATE_RESP: {res}")
    creation_id = res.get("id")
    if not creation_id:
        log.error(f"IG_CREATE_CONTAINER_FAIL resp={res}")
        return False
    log.info(f"IG_CREATE_CONTAINER_OK creation_id={creation_id}")

    # –î–ª—è –≤–∏–¥–µ–æ –∂–¥—ë–º, –ø–æ–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç—Å—è
    if media_type == "video":
        tries = IG_POLL_MAX_TRIES
        while tries > 0:
            status_res = ig_get(creation_id, {"fields": "status_code", "access_token": IG_ACCESS_TOKEN})
            status_code = status_res.get("status_code")
            log.info(f"IG_STATUS creation_id={creation_id} status_code={status_code} resp={status_res}")
            if status_code == "FINISHED":
                break
            if status_code in ("ERROR", "FAILED", "EXPIRED"):
                # –û–¥–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –ø–æ—Å–ª–µ 30 —Å–µ–∫—É–Ω–¥
                await asyncio.sleep(30)
                status_res_retry = ig_get(creation_id, {"fields": "status_code", "access_token": IG_ACCESS_TOKEN})
                status_code_retry = status_res_retry.get("status_code")
                log.info(f"IG_STATUS_RETRY creation_id={creation_id} status_code={status_code_retry} resp={status_res_retry}")
                if status_code_retry == "FINISHED":
                    break
                log.error(f"IG_STATUS_FAIL creation_id={creation_id} status_code={status_code_retry} - Smart Skip activated")
                return False
            tries -= 1
            await asyncio.sleep(IG_POLL_SECONDS)
        if tries == 0:
            log.warning(f"IG_STATUS_TIMEOUT creation_id={creation_id} after 5 minutes - trying media_publish anyway (Smart Skip improved)")
    
    # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–µ–π, —á—Ç–æ–±—ã Meta —É—Å–ø–µ–ª–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
    time_module.sleep(10)

    # –ü—É–±–ª–∏–∫—É–µ–º
    publish_res = ig_post(f"{IG_USER_ID}/media_publish", {"creation_id": creation_id, "access_token": IG_ACCESS_TOKEN})
    log.info(f"IG_PUBLISH_RESP: {publish_res}")
    media_id = publish_res.get("id")
    if media_id:
        log.info(f"IG_PUBLISH_OK media_id={media_id}")
        item["ig_published"] = True
        ig_mark_published("video")
        return True
    else:
        log.error("IG_PUBLISH_FAIL - Smart Skip activated")
        return False


async def publish_to_instagram_carousel(item: dict, image_urls: list[str]):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–∞—Ä—É—Å–µ–ª–∏ (–∞–ª—å–±–æ–º) –≤ Instagram."""
    if ENABLE_INSTAGRAM != "1":
        return
    if not IG_USER_ID or not IG_ACCESS_TOKEN:
        log.warning("Instagram disabled: missing IG_USER_ID or IG_ACCESS_TOKEN")
        return
    if not image_urls:
        log.warning("Instagram carousel: no images to publish")
        return

    caption = item.get("caption") or item.get("text") or ""
    caption = (caption or "").replace("**", "")
    log.info(f"CAPTION_TO_IG: {caption[:300]}")
    safe_caption = clean_social_text(caption)

    child_ids = []
    for url in image_urls:
        res = ig_post(
            f"{IG_USER_ID}/media",
            {
                "image_url": url,
                "is_carousel_item": "true",
                "access_token": IG_ACCESS_TOKEN,
            },
        )
        media_id = res.get("id")
        if media_id:
            child_ids.append(media_id)
        else:
            log.error("IG_CAROUSEL_CHILD_FAIL")

    if not child_ids:
        log.error("IG_CAROUSEL_CHILDREN_EMPTY")
        return

    parent_res = ig_post(
        f"{IG_USER_ID}/media",
        {
            "media_type": "CAROUSEL",
            "children": child_ids,
            "caption": safe_caption,
            "access_token": IG_ACCESS_TOKEN,
        },
    )
    creation_id = parent_res.get("id")
    if not creation_id:
        log.error("IG_CAROUSEL_PARENT_FAIL")
        return

    publish_res = ig_post(
        f"{IG_USER_ID}/media_publish",
        {"creation_id": creation_id, "access_token": IG_ACCESS_TOKEN},
    )
    media_id = publish_res.get("id")
    if media_id:
        log.info(f"IG_PUBLISH_CAROUSEL_OK media_id={media_id}")
        item["ig_published"] = True
        ig_mark_published("carousel")
        if ENABLE_FB != "1":
            delete_supabase_files(image_urls)
    else:
        log.error("IG_PUBLISH_CAROUSEL_FAIL")


def fb_post(path: str, data: dict) -> dict:
    """POST –∫ Facebook Graph API (Page) —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
    url = f"https://graph.facebook.com/{FB_GRAPH_VERSION}/{path.lstrip('/')}"
    try:
        resp = requests.post(url, data=data, timeout=FB_TIMEOUT_SECONDS)
        text = (resp.text or "")[:500]
        log.info(f"FB_POST url={url} status={resp.status_code} resp={text}")
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        log.error(f"FB_POST_FAIL url={url} error={e}")
        return {}


async def publish_to_facebook(item: dict):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–µ–¥–∏–∞ –≤ Facebook Page –ø–æ –ø—É–±–ª–∏—á–Ω–æ–º—É URL –∏–∑ Supabase."""
    if ENABLE_FB != "1":
        return
    if not FB_PAGE_ID or not FB_PAGE_TOKEN:
        log.warning("Facebook disabled: missing FB_PAGE_ID or FB_PAGE_TOKEN")
        return

    media_type = item.get("type")
    if media_type == "text":
        log.info("Facebook skip: text post")
        return
    
    if media_type not in ("photo", "video"):
        log.info(f"Facebook skip: unsupported type {media_type}")
        return
    
    supabase_url = item.get("supabase_url")
    if not supabase_url:
        log.warning("Facebook skip: no supabase_url")
        return
    
    caption = item.get("caption") or item.get("text") or ""
    caption = (caption or "").replace("**", "")
    log.info(f"CAPTION_TO_IG: {caption[:300]}")
    safe_caption = clean_social_text(caption)

    try:
        if media_type == "photo":
            res = fb_post(f"{FB_PAGE_ID}/photos", {
                "url": supabase_url,
                "caption": safe_caption,
                "access_token": FB_PAGE_TOKEN,
            })
            media_id = res.get("id")
            if media_id:
                log.info(f"FB_PUBLISH_PHOTO_OK id={media_id}")
            else:
                log.error("FB_PUBLISH_PHOTO_FAIL")
        else:
            res = fb_post(f"{FB_PAGE_ID}/videos", {
                "file_url": supabase_url,
                "description": safe_caption,
                "access_token": FB_PAGE_TOKEN,
            })
            media_id = res.get("id")
            if media_id:
                log.info(f"FB_PUBLISH_VIDEO_OK id={media_id}")
                item["fb_published"] = True
            else:
                log.error("FB_PUBLISH_VIDEO_FAIL")
    except Exception as e:
        log.error(f"Facebook publish error: {e}")


async def publish_to_facebook_carousel(item: dict, image_urls: list[str]):
    """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞ —Ñ–æ—Ç–æ –∫–∞–∫ –∞–ª—å–±–æ–º/—Å–µ—Ä–∏—è –≤ Facebook Page."""
    if ENABLE_FB != "1":
        return
    if not FB_PAGE_ID or not FB_PAGE_TOKEN:
        log.warning("Facebook disabled: missing FB_PAGE_ID or FB_PAGE_TOKEN")
        return
    if not image_urls:
        log.warning("Facebook carousel: no images to publish")
        return

    caption = item.get("caption") or item.get("text") or ""
    safe_caption = clean_social_text(caption)

    success = False
    for idx, url in enumerate(image_urls):
        res = fb_post(
            f"{FB_PAGE_ID}/photos",
            {
                "url": url,
                "caption": safe_caption if idx == 0 else "",
                "access_token": FB_PAGE_TOKEN,
            },
        )
        media_id = res.get("id")
        if media_id:
            success = True
            log.info(f"FB_PUBLISH_CAROUSEL_PHOTO_OK id={media_id} idx={idx}")
        else:
            log.error(f"FB_PUBLISH_CAROUSEL_PHOTO_FAIL idx={idx}")

    if success:
        item["fb_published"] = True
        delete_supabase_files(image_urls)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
STATS_FILE = Path("daily_stats.json")
DAILY_STATS = {
    "date": None,  # –¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞
    "morning": 0,  # –î–æ –æ–±–µ–¥–∞ (–¥–æ 14:00)
    "afternoon": 0,  # –ü–æ—Å–ª–µ –æ–±–µ–¥–∞ (—Å 14:00)
    "video": 0,
    "photo": 0,
    "text": 0,
    "total": 0,
    "tokens": {
        "prompt_tokens": 0,
        "completion_tokens": 0,
        "total_tokens": 0
    },
    "cost_usd": 0.0
}


def save_queue():
    try:
        with QUEUE_FILE.open("w", encoding="utf-8") as f:
            json.dump(list(POST_QUEUE), f, ensure_ascii=False)
    except Exception as e:
        print("Failed to save queue", e)


def load_queue():
    if not QUEUE_FILE.exists():
        return
    try:
        with QUEUE_FILE.open("r", encoding="utf-8") as f:
            items = json.load(f)
            for it in items:
                POST_QUEUE.append(it)
    except Exception as e:
        print("Failed to load queue", e)


def load_seen():
    if SEEN_FILE.exists():
        try:
            data = json.loads(SEEN_FILE.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                # –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {"hashes": [...], "buffer_message_ids": [...], "file_ids": [...]}
                SEEN_HASHES.update(data.get("hashes", []))
                SEEN_FILE_IDS.update(data.get("file_ids", []))
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ message_id (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if "buffer_message_ids" in data:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç–∏–≤–Ω–æ
                    pass
            else:
                # –°—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ —Ö–µ—à–µ–π
                SEEN_HASHES.update(data)
        except Exception:
            pass


def save_seen():
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    data = {
        "hashes": list(SEEN_HASHES),
        "file_ids": list(SEEN_FILE_IDS),
        "buffer_message_ids": []  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    }
    SEEN_FILE.write_text(json.dumps(data), encoding="utf-8")


def load_last_post_time():
    global LAST_POST_TIME
    if LAST_POST_TIME_FILE.exists():
        try:
            data = json.loads(LAST_POST_TIME_FILE.read_text(encoding="utf-8"))
            if isinstance(data, dict) and data.get("last_post_time"):
                LAST_POST_TIME = datetime.fromisoformat(data["last_post_time"])
        except Exception:
            pass


def save_last_post_time():
    if LAST_POST_TIME:
        try:
            LAST_POST_TIME_FILE.write_text(
                json.dumps({"last_post_time": LAST_POST_TIME.isoformat()}),
                encoding="utf-8"
            )
        except Exception as e:
            log.warning(f"Failed to save last_post_time: {e}")


def mark_file_id_seen(file_id: str):
    if not file_id:
        return
    if file_id in SEEN_FILE_IDS:
        return
    SEEN_FILE_IDS.add(file_id)
    save_seen()


def reset_ig_schedule_if_needed():
    today = datetime.now().strftime("%Y-%m-%d")
    if IG_SCHEDULE["date"] != today:
        IG_SCHEDULE["date"] = today
        IG_SCHEDULE["morning_videos"] = 0
        IG_SCHEDULE["afternoon_videos"] = 0
        IG_SCHEDULE["afternoon_carousels"] = 0


def can_ig_publish(media_kind: str, force: bool = False) -> bool:
    """
    IG —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ (9 –ø–æ—Å—Ç–æ–≤/–¥–µ–Ω—å):
    - –¢–æ–ª—å–∫–æ video (Reels)
    - –£—Ç—Ä–æ (–¥–æ 14:00): –º–∞–∫—Å–∏–º—É–º 3 –ø–æ—Å—Ç–∞
    - –ü–∞—É–∑–∞ (14:00-16:00): –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–µ—â–µ–Ω–∞
    - –í–µ—á–µ—Ä (16:00-21:00): –º–∞–∫—Å–∏–º—É–º 6 –ø–æ—Å—Ç–æ–≤ (–ø–æ 1 –∫–∞–∂–¥—ã–π —á–∞—Å)
    - –ü–æ—Å–ª–µ 21:00: –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–µ—â–µ–Ω–∞ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–Ω—è
    - –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª 60 –º–∏–Ω—É—Ç –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏
    """
    if force:
        log.info("[IG_SCHEDULE] POSTNOW override: force publish (ignoring working hours)")
        return True

    if media_kind != "video":
        return False
    
    reset_ig_schedule_if_needed()
    
    now = datetime.now()
    current_time = now.time()
    current_hour = now.hour
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞
    # –ü–æ—Å–ª–µ 21:00 - –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–µ—â–µ–Ω–∞
    if current_hour > 21 or current_hour < 8:
        log.info(f"[IG_SCHEDULE] DENY: outside working hours (current_hour={current_hour})")
        return False
    
    # –ü–∞—É–∑–∞ 14:00-16:00
    if 14 <= current_hour < 16:
        log.info(f"[IG_SCHEDULE] DENY: pause window 14:00-16:00 (current_hour={current_hour})")
        return False
    
    # –£—Ç—Ä–æ (–¥–æ 14:00): –º–∞–∫—Å–∏–º—É–º 3 –ø–æ—Å—Ç–∞
    if current_hour < 14:
        if IG_SCHEDULE["morning_videos"] >= 3:
            log.info(f"[IG_SCHEDULE] DENY: morning limit reached ({IG_SCHEDULE['morning_videos']}/3)")
            return False
    # –í–µ—á–µ—Ä (16:00-21:00): –º–∞–∫—Å–∏–º—É–º 6 –ø–æ—Å—Ç–æ–≤
    elif 16 <= current_hour <= 21:
        if IG_SCHEDULE["afternoon_videos"] >= 6:
            log.info(f"[IG_SCHEDULE] DENY: evening limit reached ({IG_SCHEDULE['afternoon_videos']}/6)")
            return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª 60 –º–∏–Ω—É—Ç –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏ (–¥–ª—è IG –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ—Å—Ç)
    if LAST_POST_TIME is not None:
        time_since_last = (now - LAST_POST_TIME).total_seconds()
        if time_since_last < 3600:  # 60 –º–∏–Ω—É—Ç = 3600 —Å–µ–∫—É–Ω–¥
            remaining = 3600 - time_since_last
            log.info(f"[IG_SCHEDULE] DENY: cooldown active ({remaining:.0f}s remaining)")
            return False
    
    log.info(f"[IG_SCHEDULE] ALLOW: can publish (hour={current_hour}, morning={IG_SCHEDULE['morning_videos']}/3, evening={IG_SCHEDULE['afternoon_videos']}/6)")
    return True


def ig_mark_published(media_kind: str):
    """–û—Ç–º–µ—á–∞–µ—Ç, —á—Ç–æ –ø–æ—Å—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω, –∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—á—ë—Ç—á–∏–∫ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫."""
    reset_ig_schedule_if_needed()
    
    if media_kind == "video":
        now = datetime.now()
        current_hour = now.hour
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π —Å—á—ë—Ç—á–∏–∫ —É–≤–µ–ª–∏—á–∏—Ç—å, –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        if current_hour < 14:
            # –£—Ç—Ä–æ (–¥–æ 14:00)
            IG_SCHEDULE["morning_videos"] += 1
            log.info(f"[IG_SCHEDULE] Morning video published. Counter: {IG_SCHEDULE['morning_videos']}/3")
        elif 16 <= current_hour <= 21:
            # –í–µ—á–µ—Ä (16:00-21:00)
            IG_SCHEDULE["afternoon_videos"] += 1
            log.info(f"[IG_SCHEDULE] Evening video published. Counter: {IG_SCHEDULE['afternoon_videos']}/6")
        else:
            # –í–Ω–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è (14:00-16:00 –∏–ª–∏ –ø–æ—Å–ª–µ 21:00) - –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å
            log.warning(f"[IG_SCHEDULE] Video published outside schedule window (hour={current_hour})")


def load_published_texts():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    global PUBLISHED_TEXTS
    if PUBLISHED_TEXTS_FILE.exists():
        try:
            with PUBLISHED_TEXTS_FILE.open("r", encoding="utf-8") as f:
                PUBLISHED_TEXTS = json.load(f)
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ MAX_PUBLISHED_TEXTS
                if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                    PUBLISHED_TEXTS = PUBLISHED_TEXTS[-MAX_PUBLISHED_TEXTS:]
        except Exception as e:
            log.warning(f"Failed to load published texts: {e}")
            PUBLISHED_TEXTS = []


def save_published_texts():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    try:
        with PUBLISHED_TEXTS_FILE.open("w", encoding="utf-8") as f:
            json.dump(PUBLISHED_TEXTS, f, ensure_ascii=False)
    except Exception as e:
        log.warning(f"Failed to save published texts: {e}")


async def check_similar_content(text: str) -> tuple[bool, float]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç semantic similarity —Å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ—Å—Ç–∞–º–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_similar, similarity_score)"""
    if not openai_client or not text or not PUBLISHED_TEXTS:
        return (False, 0.0)
    
    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –ø–æ—Å—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (—É–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)
    recent_texts = PUBLISHED_TEXTS[-20:] if len(PUBLISHED_TEXTS) > 20 else PUBLISHED_TEXTS
    
    if not recent_texts:
        return (False, 0.0)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ OpenAI semantic similarity
        resp = openai_client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—é –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ Telegram-–∫–∞–Ω–∞–ª–µ.\n\n"
                        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –î–£–ë–õ–ò–ö–ê–¢–û–ú —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞.\n\n"
                        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
                        '{"is_similar": true/false, "similarity_score": 0.0-1.0, "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"}\n\n'
                        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: is_similar = true, –µ—Å–ª–∏:\n"
                        "1. –û–î–ò–ù–ê–ö–û–í–ê–Ø –¢–ï–ú–ê/–ò–î–ï–Ø (–¥–∞–∂–µ –µ—Å–ª–∏ —Å–ª–æ–≤–∞ —Ä–∞–∑–Ω—ã–µ):\n"
                        "   - '–∏–∑–±–µ–≥–∞–π —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π' = '–¥–µ—Ä–∂–∏—Å—å –ø–æ–¥–∞–ª—å—à–µ –æ—Ç —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π' = '–Ω–µ –æ–±—â–∞–π—Å—è —Å —Ç–∞–∫–∏–º–∏'\n"
                        "   - '—Å–æ–≤–µ—Ç—ã –ø–æ —É—Å–ø–µ—Ö—É' = '–∫–∞–∫ –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞' = '–ø—Ä–∞–≤–∏–ª–∞ —É—Å–ø–µ—Ö–∞'\n"
                        "   - '–ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –ª—é–¥–µ–π' = '–∫–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –ø–ª–æ—Ö–∏—Ö –ª—é–¥–µ–π' = '–∏–∑–±–µ–≥–∞–π —ç—Ç–∏—Ö –ª—é–¥–µ–π'\n\n"
                        "2. –û–î–ò–ù–ê–ö–û–í–´–ï –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–´/–ü–†–ò–ú–ï–†–´:\n"
                        "   - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ø–∏—Å–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤/—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n"
                        "   - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã/—Å–∏—Ç—É–∞—Ü–∏–∏\n"
                        "   - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã/—Å–æ–≤–µ—Ç—ã\n\n"
                        "3. –ü–û–•–û–ñ–ò–ô –ü–ï–†–ï–í–û–î –û–î–ù–û–ì–û –ò –¢–û–ì–û –ñ–ï –ò–°–¢–û–ß–ù–ò–ö–ê:\n"
                        "   - –µ—Å–ª–∏ –æ–±–∞ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ —Ä—É—Å—Å–∫–æ–≥–æ –ø–æ—Å—Ç–∞\n"
                        "   - –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è\n\n"
                        "4. similarity_score >= 0.65 (—Å–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏)\n\n"
                        "is_similar = false –¢–û–õ–¨–ö–û –µ—Å–ª–∏:\n"
                        "- –†–ê–ó–ù–´–ï —Ç–µ–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ø—Ä–æ —É—Å–ø–µ—Ö' vs '–ø—Ä–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è')\n"
                        "- –†–ê–ó–ù–´–ï —Ñ–∞–∫—Ç—ã/–ø—Ä–∏–º–µ—Ä—ã\n"
                        "- –†–ê–ó–ù–ê–Ø –æ—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è\n"
                        "- similarity_score < 0.65\n\n"
                        "–ü–†–ò–ú–ï–†–´ –î–£–ë–õ–ò–ö–ê–¢–û–í (is_similar = true):\n"
                        "- '–ò–∑–±–µ–≥–∞–π —Ç–∞–∫–∏—Ö –ª—é–¥–µ–π: –æ–Ω–∏ –Ω–µ –¥–µ—Ä–∂–∞—Ç —Å–µ–∫—Ä–µ—Ç—ã' vs '–î–µ—Ä–∂–∏—Å—å –ø–æ–¥–∞–ª—å—à–µ –æ—Ç –ª—é–¥–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–º–µ—é—Ç —Ö—Ä–∞–Ω–∏—Ç—å —Ç–∞–π–Ω—ã'\n"
                        "- '5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –ª—é–¥–µ–π' vs '–ö–∞–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞: 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤'\n"
                        "- '–°–æ–≤–µ—Ç—ã –ø–æ —É—Å–ø–µ—Ö—É: —Ä–∞–±–æ—Ç–∞–π —É—Å–µ—Ä–¥–Ω–æ' vs '–ö–∞–∫ –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞: —É—Å–µ—Ä–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞'\n\n"
                        "–ü–†–ò–ú–ï–†–´ –ù–ï –î–£–ë–õ–ò–ö–ê–¢–û–í (is_similar = false):\n"
                        "- '–ö–∞–∫ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ–Ω—å–≥–∏' vs '–ö–∞–∫ –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—Ç—É'\n"
                        "- '–ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –ª—é–¥–µ–π' vs '–ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è'\n"
                        "- '–°–æ–≤–µ—Ç—ã –ø–æ –∫–∞—Ä—å–µ—Ä–µ' vs '–°–æ–≤–µ—Ç—ã –ø–æ –∑–¥–æ—Ä–æ–≤—å—é'\n\n"
                        "–ë–£–î–¨ –°–¢–†–û–ì–ò–ú: –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –º–∞–ª–µ–π—à–µ–µ —Å–æ–º–Ω–µ–Ω–∏–µ, —á—Ç–æ —ç—Ç–æ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø–æ—Å—Ç/—Ç–µ–º–∞ ‚Äî –≤–µ—Ä–Ω–∏ is_similar = true."
                    ),
                },
                {
                    "role": "user",
                    "content": f"–ù–æ–≤—ã–π —Ç–µ–∫—Å—Ç:\n{text}\n\n–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10):\n" + "\n---\n".join(recent_texts[:10])
                },
            ],
            response_format={"type": "json_object"},
        )
        
        result = json.loads(resp.choices[0].message.content or "{}")
        similarity_score = float(result.get("similarity_score", 0.0))
        is_similar = result.get("is_similar", False) or similarity_score >= 0.65  # –°–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ —Å 0.75 –¥–æ 0.65
        
        if is_similar:
            log.warning(f"SKIP: semantic duplicate (similarity={similarity_score:.2f}): {result.get('reason', '')}")
        
        return (is_similar, similarity_score)
        
    except Exception as e:
        log.warning(f"Failed to check similar content: {e}")
        return (False, 0.0)


def remove_comment_phrases(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Ñ—Ä–∞–∑—ã –ø—Ä–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return text
    
    import re
    phrases_to_remove = [
        r"–æ—Å—Ç–∞–≤—å—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π[^\n]*",
        r"–Ω–∞–ø–∏—à–∏—Ç–µ –Ω–∏–∂–µ[^\n]*",
        r"—á—Ç–æ –¥—É–º–∞–µ—Ç–µ[^\n]*",
        r"–≤–∞—à–µ –º–Ω–µ–Ω–∏–µ[^\n]*",
        r"–æ–±—Å—É–¥–∏–º[^\n]*",
        r"–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ[^\n]*",
        r"–ø–∏—à–∏—Ç–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö[^\n]*",
        r"fikringiz[^\n]*",
        r"yozing[^\n]*",
        r"muloqot[^\n]*",
    ]
    
    cleaned = text
    for phrase in phrases_to_remove:
        cleaned = re.sub(phrase, "", cleaned, flags=re.IGNORECASE)
    
    return cleaned.strip()


def clean_social_text(text: str) -> str:
    """
    –£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏ –∏ –æ–±—Ä–µ–∑–∞–µ—Ç –≤—Å—ë –ø–æ—Å–ª–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π —á–µ—Ä—Ç—ã –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π.
    –¢–µ–ª–µ–≥—Ä–∞–º –æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ‚Äî —ç—Ç–æ—Ç —Ñ–∏–ª—å—Ç—Ä –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ IG/FB.
    """
    if not text:
        return ""
    # –∂—ë—Å—Ç–∫–æ —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ —Å—Ä–∞–∑—É, –¥–æ –¥—Ä—É–≥–∏—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
    cleaned = re.sub(r"qiziqarlidunyo", "", text, flags=re.IGNORECASE)
    cleaned = re.sub(r"\bmain\.py\b", "", cleaned, flags=re.IGNORECASE)
    # —É–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏
    cleaned = re.sub(r"<[^>]+>", "", cleaned)
    # –æ–±—Ä–µ–∑–∞–µ–º –ø–æ –ø–µ—Ä–≤–æ–º—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—é |
    if "|" in cleaned:
        cleaned = cleaned.split("|", 1)[0]
    # —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –æ–±—Ä–µ–∑–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –ø–æ –∫—Ä–∞—è–º
    cleaned = re.sub(r"\s+", " ", cleaned).strip(" \t\r\n.,;:!-|")
    return cleaned.strip()


def ensure_utf8_text(text: str) -> str:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫—É –∫ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π UTF-8, —É–±–∏—Ä–∞—è –±–∏—Ç—ã–µ —Å–∏–º–≤–æ–ª—ã."""
    if text is None:
        return ""
    if isinstance(text, bytes):
        return text.decode("utf-8", errors="ignore")
    try:
        return text.encode("utf-8", errors="ignore").decode("utf-8", errors="ignore")
    except Exception:
        return str(text)


def split_text_for_carousel(text: str, max_chars: int = 700) -> list[str]:
    """–î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è —Å–ª–∞–π–¥–æ–≤, —á—Ç–æ–±—ã –∫–∞–∂–¥–∞—è –±—ã–ª–∞ —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞."""
    chunks = []
    current = []
    total = 0
    # —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    for sent in sentences:
        if not sent:
            continue
        if total + len(sent) > max_chars and current:
            chunks.append(" ".join(current).strip())
            current = [sent]
            total = len(sent)
        else:
            current.append(sent)
            total += len(sent)
    if current:
        chunks.append(" ".join(current).strip())
    return chunks or [text.strip()]


def wrap_lines_to_width(draw: ImageDraw.ImageDraw, text: str, font: ImageFont.FreeTypeFont, max_width: int) -> list[str]:
    """–ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ —Å —É—á—ë—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω—ã."""
    words = text.split()
    lines = []
    line = ""
    for word in words:
        candidate = (line + " " + word).strip()
        if not candidate:
            continue
        bbox = draw.textbbox((0, 0), candidate, font=font)
        width = bbox[2] - bbox[0]
        if width <= max_width:
            line = candidate
        else:
            if line:
                lines.append(line)
            line = word
    if line:
        lines.append(line)
    return lines


def parse_accent_tokens(text: str) -> list[tuple[str, bool]]:
    """–ü–∞—Ä—Å–∏—Ç *–≤—ã–¥–µ–ª–µ–Ω–Ω—ã–µ* —Å–ª–æ–≤–∞: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (token, is_accent)."""
    tokens = []
    parts = text.split("*")
    # –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π —á—ë—Ç–Ω–æ–µ, –∑–Ω–∞—á–∏—Ç –Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –ø–∞—Ä ‚Äî —Ç—Ä–∞–∫—Ç—É–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    if len(parts) < 3:
        return [(text, False)]
    accent = False
    for part in parts:
        if part == "":
            accent = not accent
            continue
        tokens.append((part, accent))
        accent = not accent
    return tokens


def wrap_tokens_to_width(draw: ImageDraw.ImageDraw, tokens: list[tuple[str, bool]], font: ImageFont.FreeTypeFont, max_width: int) -> list[list[tuple[str, bool]]]:
    """–ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ —Å —É—á—ë—Ç–æ–º —à–∏—Ä–∏–Ω—ã –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π."""
    lines: list[list[tuple[str, bool]]] = []
    line: list[tuple[str, bool]] = []

    def measure(line_tokens: list[tuple[str, bool]]) -> float:
        if not line_tokens:
            return 0
        joined = " ".join(t[0] for t in line_tokens)
        bbox = draw.textbbox((0, 0), joined, font=font)
        return bbox[2] - bbox[0]

    for tok in tokens:
        if not line:
            line.append(tok)
            if measure(line) > max_width and len(tok[0]) > 0:
                lines.append(line)
                line = []
            continue
        candidate = line + [tok]
        if measure(candidate) <= max_width:
            line.append(tok)
        else:
            lines.append(line)
            line = [tok]
    if line:
        lines.append(line)
    return lines


def create_carousel_images(text: str) -> list[str]:
    """
    –°–æ–∑–¥–∞—ë—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –∫–∞—Ä—É—Å–µ–ª–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –≤—Ä–µ–º–µ–Ω–Ω—ã–º PNG-—Ñ–∞–π–ª–∞–º.
    """
    base_dir = Path("D:/Project/Auto Telegramm")
    backgrounds_dir = base_dir / "backgrounds"
    fonts_dir = base_dir / "fonts"
    tmp_dir = Path("tmp_media") / "carousel"
    tmp_dir.mkdir(parents=True, exist_ok=True)

    bg_files = [p for p in backgrounds_dir.glob("*") if p.suffix.lower() in {".jpg", ".jpeg", ".png"}]
    font_files = [p for p in fonts_dir.glob("*.ttf")]
    if not bg_files or not font_files:
        log.error("Carousel assets missing: backgrounds or fonts not found")
        return []

    slides = []
    chunks = split_text_for_carousel(text)

    for idx, chunk in enumerate(chunks, start=1):
        bg_path = random.choice(bg_files)
        font_path = random.choice(font_files)
        img = Image.open(bg_path).convert("RGBA")
        draw = ImageDraw.Draw(img)

        max_text_width = int(img.width * 0.55)  # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞
        max_text_height = int(img.height * 0.8)

        # –ø–æ–¥–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞ (–∫—Ä—É–ø–Ω—ã–π, –Ω–µ –Ω–∏–∂–µ 50)
        font_size = 72
        min_font = 50
        chosen_lines = []
        chosen_font = ImageFont.truetype(str(font_path), font_size)

        while font_size >= min_font:
            font = ImageFont.truetype(str(font_path), font_size)
            lines = wrap_lines_to_width(draw, chunk, font, max_text_width)
            text_block = "\n".join(lines)
            bbox = draw.multiline_textbbox((0, 0), text_block, font=font, align="center")
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]

            if text_w <= max_text_width and text_h <= max_text_height and len(lines) <= 18:
                chosen_lines = lines
                chosen_font = font
                break
            font_size -= 2

        # –µ—Å–ª–∏ –Ω–µ —É–ª–æ–∂–∏–ª–∏—Å—å, –∂—ë—Å—Ç–∫–æ —Ä–µ–∂–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ 18
        if not chosen_lines:
            lines = wrap_lines_to_width(draw, chunk, chosen_font, max_text_width)
            chosen_lines = lines[:18]

        final_text = "\n".join(chosen_lines)
        bbox = draw.multiline_textbbox((0, 0), final_text, font=chosen_font, align="center")
        text_w = bbox[2] - bbox[0]
        text_h = bbox[3] - bbox[1]
        x = (img.width - text_w) / 2
        y = (img.height - text_h) / 2

        # —Ç–µ–Ω—å
        shadow_offset = 2
        draw.multiline_text(
            (x + shadow_offset, y + shadow_offset),
            final_text,
            font=chosen_font,
            fill="black",
            align="center",
        )
        # –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        draw.multiline_text(
            (x, y),
            final_text,
            font=chosen_font,
            fill="white",
            align="center",
        )

        out_path = tmp_dir / f"carousel_{uuid.uuid4().hex}.png"
        img.save(out_path, format="PNG")
        log.info(f"[PILLOW] –°–ª–∞–π–¥ ‚Ññ{idx} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        slides.append(str(out_path))

    return slides


def summarize_for_image(text: str) -> str:
    """–ö—Ä–∞—Ç–∫–æ–µ –∏ —ë–º–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–ª–∞–π–¥–∞ (—É–∑–±–µ–∫—Å–∫–∏–π, –∫–æ—Ä–æ—Ç–∫–æ)."""
    txt = (text or "").strip()
    if not txt:
        return ""
    if len(txt) <= 260:
        return txt
    if not openai_client:
        return txt[:260]


def append_history(social: str, media_type: str, url: str, cost: float):
    """–ü–∏—à–µ—Ç —Å—Ç—Ä–æ–∫—É –∏—Å—Ç–æ—Ä–∏–∏ –≤ history.log"""
    try:
        ts = datetime.now().strftime("%d.%m.%Y %H:%M")
        line = f"[{ts}] | –°–æ—Ü—Å–µ—Ç—å: {social} | –¢–∏–ø: {media_type} | –°—Å—ã–ª–∫–∞: {url or '-'} | –¶–µ–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: ${cost:.4f}\n"
        with HISTORY_LOG.open("a", encoding="utf-8") as f:
            f.write(line)
    except Exception as e:
        log.warning(f"Failed to append history: {e}")


def send_admin_error(error_message: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É –∞–¥–º–∏–Ω—É –≤ Telegram (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —á–µ—Ä–µ–∑ Telegram Bot API)."""
    if not ADMIN_TELEGRAM_ID:
        return
    try:
        ts = datetime.now().strftime("%d.%m.%Y %H:%M")
        payload = {
            "chat_id": ADMIN_TELEGRAM_ID,
            "text": f"[ERROR {ts}]\n{error_message}",
        }
        requests.post(f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage", data=payload, timeout=10)
    except Exception as e:
        log.warning(f"Failed to notify admin: {e}")


def send_report_message(text: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–Ω–µ–≤–Ω–æ–π –æ—Ç—á—ë—Ç –≤ REPORT_CHAT_ID."""
    chat_id = REPORT_CHAT_ID or ADMIN_TELEGRAM_ID
    if not chat_id:
        return
    try:
        requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
            data={"chat_id": chat_id, "text": text},
            timeout=15,
        )
    except Exception as e:
        log.warning(f"Failed to send report message: {e}")


def rotate_history_log():
    """–ö–æ–ø–∏—Ä—É–µ—Ç history.log –≤ reports/report_YYYY_MM_DD.log –∏ –æ—á–∏—â–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥."""
    try:
        if not HISTORY_LOG.exists():
            return
        REPORTS_DIR.mkdir(exist_ok=True)
        today = datetime.now().strftime("%Y_%m_%d")
        target = REPORTS_DIR / f"report_{today}.log"
        target.write_text(HISTORY_LOG.read_text(encoding="utf-8"), encoding="utf-8")
        HISTORY_LOG.write_text("", encoding="utf-8")
        log.info(f"History rotated to {target}")
    except Exception as e:
        log.warning(f"Failed to rotate history log: {e}")


def create_single_art_image(text: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ PNG —Ñ–∞–π–ª—É.
    """
    base_dir = Path("D:/Project/Auto Telegramm")
    backgrounds_dir = base_dir / "backgrounds"
    fonts_dir = base_dir / "fonts"
    tmp_dir = Path("tmp_media") / "single_art"
    tmp_dir.mkdir(parents=True, exist_ok=True)

    bg_files = [p for p in backgrounds_dir.glob("*") if p.suffix.lower() in {".jpg", ".jpeg", ".png"}]
    font_files = [p for p in fonts_dir.glob("*.ttf")]
    if not bg_files or not font_files:
        log.error("Single art assets missing: backgrounds or fonts not found")
        return ""

    bg_path = random.choice(bg_files)
    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ Bold-—à—Ä–∏—Ñ—Ç
    bold_fonts = [p for p in font_files if "bold" in p.name.lower()]
    font_path = bold_fonts[0] if bold_fonts else font_files[0]

    img = Image.open(bg_path).convert("RGBA")
    draw = ImageDraw.Draw(img)

    # –û—á–∏—Å—Ç–∫–∞ HTML –∏ —É–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    plain = re.sub(r"<[^>]+>", "", text or "")
    summary = summarize_for_image(plain).upper()

    max_text_width = int(img.width * 0.45)  # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –±–ª–æ–∫ ~45%
    max_text_height = int(img.height * 0.8)

    font_size = 140
    min_font = 100
    chosen_lines = []
    chosen_font = ImageFont.truetype(str(font_path), font_size)
    tokens = parse_accent_tokens(summary)

    def measure_lines(lines_tokens: list[list[tuple[str, bool]]], font: ImageFont.FreeTypeFont) -> tuple[float, float, list[float], list[float]]:
        spacing_px_inner = int(font.size * 0.6)
        line_heights_inner = []
        line_widths_inner = []
        for line in lines_tokens:
            text_line = " ".join(t[0] for t in line)
            bbox = draw.textbbox((0, 0), text_line, font=font)
            line_widths_inner.append(bbox[2] - bbox[0])
            line_heights_inner.append(bbox[3] - bbox[1])
        total_h_inner = sum(line_heights_inner) + spacing_px_inner * (len(lines_tokens) - 1 if lines_tokens else 0)
        max_w_inner = max(line_widths_inner) if line_widths_inner else 0
        return max_w_inner, total_h_inner, line_widths_inner, line_heights_inner

    while font_size >= min_font:
        font = ImageFont.truetype(str(font_path), font_size)
        lines_tokens = wrap_tokens_to_width(draw, tokens, font, max_text_width)
        max_w, total_h, line_widths, line_heights = measure_lines(lines_tokens, font)

        if max_w <= max_text_width and total_h <= max_text_height and len(lines_tokens) <= 12:
            chosen_lines = lines_tokens
            chosen_font = font
            chosen_line_widths = line_widths
            chosen_line_heights = line_heights
            break
        font_size -= 2

    if not chosen_lines:
        lines_tokens = wrap_tokens_to_width(draw, tokens, chosen_font, max_text_width)
        chosen_lines = lines_tokens[:12]
        max_w, total_h, chosen_line_widths, chosen_line_heights = measure_lines(chosen_lines, chosen_font)
    else:
        max_w, total_h = max(chosen_line_widths), sum(chosen_line_heights) + int(chosen_font.size * 0.6) * (len(chosen_lines) - 1 if chosen_lines else 0)

    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ –≤–ª–µ–∑–∞–µ—Ç ‚Äî —É–º–µ–Ω—å—à–∞–µ–º —à—Ä–∏—Ñ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
    reduce_steps = 0
    while (max_w > max_text_width or total_h > max_text_height) and chosen_font.size > min_font:
        new_size = max(min_font, int(chosen_font.size * 0.9))
        chosen_font = ImageFont.truetype(str(font_path), new_size)
        chosen_lines = wrap_tokens_to_width(draw, tokens, chosen_font, max_text_width)[:12]
        max_w, total_h, chosen_line_widths, chosen_line_heights = measure_lines(chosen_lines, chosen_font)
        reduce_steps += 1
        if reduce_steps > 10:
            break

    spacing_px = int(chosen_font.size * 0.6)
    x_start = (img.width - max_w) / 2
    y_start = (img.height - total_h) / 2

    # –õ—ë–≥–∫–æ–µ –∑–∞—Ç–µ–º–Ω–µ–Ω–∏–µ –ø–æ–¥ —Ç–µ–∫—Å—Ç –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ (50%)
    overlay = Image.new("RGBA", img.size, (0, 0, 0, int(255 * 0.50)))
    img = Image.alpha_composite(img, overlay)
    draw = ImageDraw.Draw(img)

    accent_color = "#D4AF37"  # –∑–æ–ª–æ—Ç–∏—Å—Ç–æ-–±–µ–∂–µ–≤—ã–π

    y = y_start
    for line_idx, line in enumerate(chosen_lines):
        text_line = " ".join(t[0] for t in line)
        line_bbox = draw.textbbox((0, 0), text_line, font=chosen_font)
        line_width = line_bbox[2] - line_bbox[0]
        x = (img.width - line_width) / 2

        cursor_x = x
        for i, (tok, is_accent) in enumerate(line):
            fill_color = accent_color if is_accent else "white"
            tok_bbox = draw.textbbox((0, 0), tok, font=chosen_font)
            tok_width = tok_bbox[2] - tok_bbox[0]
            space_bbox = draw.textbbox((0, 0), " ", font=chosen_font)
            space_w = space_bbox[2] - space_bbox[0]
            draw.text(
                (cursor_x, y),
                tok,
                font=chosen_font,
                fill=fill_color,
                stroke_width=5,
                stroke_fill="black",
            )
            cursor_x += tok_width
            if i != len(line) - 1:
                cursor_x += space_w

        y += line_heights[line_idx]
        if line_idx != len(chosen_lines) - 1:
            y += spacing_px

    out_path = tmp_dir / f"single_art_{uuid.uuid4().hex}.png"
    img.save(out_path, format="PNG")
    log.info("[PILLOW] Single art post created successfully")
    return str(out_path)


def _rounded_mask(size: tuple[int, int], radius: int) -> np.ndarray:
    """–°–æ–∑–¥–∞–µ—Ç –º–∞—Å–∫—É —Å –∑–∞–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–º–∏ —É–≥–ª–∞–º–∏ (0..1)."""
    w, h = size
    mask_img = Image.new("L", (w, h), 0)
    draw = ImageDraw.Draw(mask_img)
    draw.rounded_rectangle([(0, 0), (w, h)], radius=radius, fill=255)
    arr = np.array(mask_img).astype("float32") / 255.0
    return arr


def _render_caption_image(text: str, width: int = 1080, height: int = 200) -> Path | None:
    """–†–µ–Ω–¥–µ—Ä–∏—Ç —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ PNG –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å."""
    if not text:
        return None
    try:
        tmp_dir = Path("tmp_media") / "captions"
        tmp_dir.mkdir(parents=True, exist_ok=True)
        img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        font = ImageFont.load_default()
        # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
        first_line = text.splitlines()[0].strip()
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(first_line) > 80:
            first_line = first_line[:80] + "..."
        bbox = draw.textbbox((0, 0), first_line, font=font)
        tw = bbox[2] - bbox[0]
        th = bbox[3] - bbox[1]
        pos = ((width - tw) // 2, (height - th) // 2)
        draw.text(pos, first_line, font=font, fill=(255, 215, 0, 255))
        out_path = tmp_dir / f"caption_{uuid.uuid4().hex}.png"
        img.save(out_path, "PNG")
        return out_path
    except Exception as e:
        log.warning(f"Caption render failed: {e}")
        return None


def process_video(local_path: Path, caption: str | None = None, speed_multiplier: float = 1.01, bg_color_override: tuple | None = None, brightness_adjust: float = 0.0, random_crop: bool = False, voiceover_path: str | None = None) -> Path | None:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –≤–∏–¥–µ–æ –≤ —Å—Ç–∏–ª–µ Reels:
    - –ö–∞–Ω–≤–∞—Å 1080x1920 —Ç—ë–º–Ω—ã–π
    - –í–∏–¥–µ–æ ~80% —à–∏—Ä–∏–Ω—ã, –ø–æ —Ü–µ–Ω—Ç—Ä—É, —Å–∫—Ä—É–≥–ª—ë–Ω–Ω—ã–µ —É–≥–ª—ã
    - –õ–æ–≥–æ—Ç–∏–ø –ø–æ–≤–µ—Ä—Ö
    - –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ caption
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è "–ü–ª–∞–Ω–∞ –ë":
    - speed_multiplier: –º–Ω–æ–∂–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ (1.01, 1.02, 1.03)
    - bg_color_override: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ü–≤–µ—Ç —Ñ–æ–Ω–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
    - brightness_adjust: –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏ (0.0 –¥–æ 0.03)
    - random_crop: —Å–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ 5-15px —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    # === IRONCLAD CONFIGURATION: DO NOT ALTER ===
    # BITRATE: 5000k (Strict limit for Supabase)
    # PRESET: slow (High quality encoding)
    # CRF: 19 (Optimal quality/size balance)
    # STITCHES: Checked for duration (No crashes)
    # AUDIO: Pro processing Pitch 0.2 / Tempo 0.5
    # ============================================
    try:
        header_path = (Path(__file__).parent / "header.gif").resolve()
        clip = VideoFileClip(str(local_path))
        duration = clip.duration
        
        # –ü–õ–ê–ù –ë: –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ (Random Crop) –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
        if random_crop:
            original_w, original_h = clip.w, clip.h
            crop_pixels = random.randint(5, 15)
            
            # –û–±—Ä–µ–∑–∞–µ–º —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω
            x1 = crop_pixels
            y1 = crop_pixels
            x2 = original_w - crop_pixels
            y2 = original_h - crop_pixels
            
            clip = clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)
            # –†–∞—Å—Ç—è–≥–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            clip = clip.resize((original_w, original_h))
            log.info(f"[PLAN B] Random crop applied: {crop_pixels}px from each side, resized back to {original_w}x{original_h}")

        canvas_size = (1080, 1920)
        dark_palette = [
            (0, 0, 0),
            (10, 10, 20),
            (20, 20, 30),
            (12, 8, 24),
            (6, 12, 18),
        ]
        bg_color = bg_color_override if bg_color_override is not None else random.choice(dark_palette)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if bg_color_override is not None or speed_multiplier > 1.01 or brightness_adjust != 0.0:
            log.info(f"[PLAN B] Video processing with unique parameters: speed={speed_multiplier:.3f}, bg={bg_color}, brightness={brightness_adjust:+.3f}")
        
        # –ü–õ–ê–ù –ë: –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ (Random Crop) –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
        if brightness_adjust != 0.0:
            crop_pixels = random.randint(5, 15)
            original_w, original_h = clip.w, clip.h
            
            # –û–±—Ä–µ–∑–∞–µ–º —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω
            x1 = crop_pixels
            y1 = crop_pixels
            x2 = original_w - crop_pixels
            y2 = original_h - crop_pixels
            
            clip = clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)
            log.info(f"[PLAN B] Random crop applied: {crop_pixels}px from each side ({original_w}x{original_h} -> {clip.w}x{clip.h})")
        
        # –ó–æ–ª–æ—Ç–æ–π —à–∞–±–ª–æ–Ω: –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø–æ–ª—è —Å–æ –≤—Å–µ—Ö —Å—Ç–æ—Ä–æ–Ω (10% margin)
        margin = 0.10
        target_w = int(canvas_size[0] * (1 - margin))
        target_h = int(canvas_size[1] * (1 - margin))
        scale = min(target_w / clip.w, target_h / clip.h)
        new_w = int(clip.w * scale)
        new_h = int(clip.h * scale)
        log.info(f"[DEBUG] Golden Template: Resizing video to {new_w}x{new_h} on canvas {canvas_size} with equal margins")

        # –ü–æ—Å–ª–µ crop –≤–∏–¥–µ–æ —Ä–µ—Å–∞–π–∑–∏—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–æ –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è 1080x1920 –∫–∞–Ω–≤–∞—Å–∞
        clip = clip.resize(width=new_w, height=new_h)
        clip = clip.fx(vfx_all.speedx, speed_multiplier)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —è—Ä–∫–æ—Å—Ç–∏ (–ü–ª–∞–Ω –ë)
        if brightness_adjust != 0.0:
            clip = clip.fx(vfx_all.colorx, 1.0 + brightness_adjust)
            log.info(f"[PLAN B] Brightness adjusted: {brightness_adjust:+.3f}")
        
        # SMART SLICER & ZOOM: –ù–∞—Ä–µ–∑–∫–∞ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã —Å Crossfade –∏ –ª–µ–≥–∫–∏–º –∑—É–º–æ–º (–∑–∞–º–µ–Ω–∞ —à—É–º–∞)
        if brightness_adjust != 0.0 or speed_multiplier > 1.01 or random_crop:
            try:
                segment_duration = random.uniform(3.5, 4.0)  # –î–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
                fade_duration = 0.25  # –î–ª–∏–Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
                zoom_factor = 1.03  # –õ–µ–≥–∫–∏–π –∑—É–º –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–π –ø–æ–¥–ø–∏—Å–∏
                
                segments = []
                current_time = 0
                
                while current_time < duration:
                    # –ü–†–û–í–ï–†–ö–ê: end_time –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±–æ–ª—å—à–µ duration
                    end_time = min(current_time + segment_duration, duration)
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Å–µ–≥–º–µ–Ω—Ç –∏–º–µ–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
                    if end_time - current_time < 0.5:
                        break
                    
                    start_t = _clamp_t(current_time, clip.duration)
                    end_t = _clamp_t(end_time, clip.duration)
                    if end_t <= start_t:
                        end_t = _clamp_t(start_t + 0.5, clip.duration)
                    segment = clip.subclip(start_t, end_t)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–µ–≥–∫–∏–π –∑—É–º –∫ –∫–∞–∂–¥–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É
                    segment = segment.resize(zoom_factor)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º fade-in –∏ fade-out –¥–ª—è –ø–ª–∞–≤–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
                    segment_duration_actual = segment.duration
                    if len(segments) > 0 and segment_duration_actual > fade_duration * 2:
                        # Fade-in –¥–ª—è –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                        segment = segment.fadein(fade_duration)
                    
                    if segment_duration_actual > fade_duration * 2:
                        # Fade-out –¥–ª—è –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                        segment = segment.fadeout(fade_duration)
                    
                    segments.append(segment)
                    current_time = end_time
                
                if len(segments) > 1:
                    from moviepy import concatenate
                    clip = concatenate_videoclips(segments, method="compose")
                    log.info(f"[SMART SLICER] Video sliced into {len(segments)} segments with Fade transitions & Zoom 1.03x")
                elif len(segments) == 1:
                    clip = segments[0]
                    log.info(f"[SMART SLICER] Single segment with Zoom 1.03x applied")
            except Exception as e:
                log.warning(f"[SMART SLICER] Failed to apply: {e}, using original clip")

        # MICRO-STITCHES: –ù–µ–≤–∏–¥–∏–º—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 3 —Å–µ–≥–º–µ–Ω—Ç–∞ + —É–¥–∞–ª–µ–Ω–∏–µ 2 –∫–∞–¥—Ä–æ–≤)
        if duration > 3.0:  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∏–¥–µ–æ –¥–ª–∏–Ω–Ω–µ–µ 3 —Å–µ–∫—É–Ω–¥
            try:
                fps = clip.fps or 30
                frame_duration = 1.0 / fps
                
                # Duration Guard: –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ —Å–Ω–∏–∂–∞–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –≤—ã—Ä–µ–∑–æ–≤
                if duration < 10.0:
                    cut_frames = 1  # –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ: —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ 1 –∫–∞–¥—Ä
                    trim_duration = 0.3  # –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ: –æ–±—Ä–µ–∑–∞–µ–º —Ç–æ–ª—å–∫–æ 0.3 —Å–µ–∫
                else:
                    cut_frames = 2  # –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: —É–¥–∞–ª—è–µ–º 2 –∫–∞–¥—Ä–∞
                    trim_duration = 1.5  # –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: –æ–±—Ä–µ–∑–∞–µ–º 1.5 —Å–µ–∫
                
                cut_time = cut_frames * frame_duration
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º 3 —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç–æ—á–∫–∏ —Ä–∞–∑—Ä–µ–∑–∞
                segment_1_end = random.uniform(duration * 0.2, duration * 0.4)
                segment_2_end = random.uniform(duration * 0.6, duration * 0.8)
                
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –Ω–µ –≤—ã—Ö–æ–¥–∏–º –∑–∞ –ø—Ä–µ–¥–µ–ª—ã duration
                seg1_start = 0
                seg1_end = min(segment_1_end - cut_time, duration)
                seg2_start = min(segment_1_end + cut_time, duration)
                seg2_end = min(segment_2_end - cut_time, duration)
                seg3_start = min(segment_2_end + cut_time, duration - 0.1)
                seg3_end = duration
                
                # –°–æ–∑–¥–∞–µ–º 3 —Å–µ–≥–º–µ–Ω—Ç–∞ —Å –º–∏–∫—Ä–æ-–≤—ã—Ä–µ–∑–∞–º–∏ (–µ—Å–ª–∏ seg3 –≤–∞–ª–∏–¥–Ω—ã–π)
                segments = []
                if seg1_end > seg1_start:
                    s1 = _clamp_t(seg1_start, clip.duration)
                    e1 = _clamp_t(seg1_end, clip.duration)
                    if e1 > s1:
                        segments.append(clip.subclip(s1, e1))
                if seg2_end > seg2_start:
                    s2 = _clamp_t(seg2_start, clip.duration)
                    e2 = _clamp_t(seg2_end, clip.duration)
                    if e2 > s2:
                        segments.append(clip.subclip(s2, e2))
                if seg3_start < seg3_end and seg3_start < duration - 0.05:
                    s3 = _clamp_t(seg3_start, clip.duration)
                    e3 = _clamp_t(seg3_end, clip.duration)
                    if e3 > s3:
                        segments.append(clip.subclip(s3, e3))
                
                # –°–∫–ª–µ–∏–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
                if len(segments) > 1:
                    clip = concatenate_videoclips(segments, method="compose")
                else:
                    log.warning("[MICRO-STITCH] Not enough valid segments, skipping stitch")
                
                # Random Trim
                    if clip.duration > trim_duration + 1.0:
                        if random.choice([True, False]):
                            # –û—Ç—Ä–µ–∑–∞–µ–º —Å –Ω–∞—á–∞–ª–∞
                            s = _clamp_t(trim_duration, clip.duration)
                            e = _clamp_t(clip.duration, clip.duration)
                            if e <= s:
                                e = _clamp_t(s + 0.5, clip.duration)
                            clip = clip.subclip(s, e)
                            log.info(f"[MICRO-STITCH] Trimmed {trim_duration}s from start")
                        else:
                            # –û—Ç—Ä–µ–∑–∞–µ–º —Å –∫–æ–Ω—Ü–∞
                            s = _clamp_t(0, clip.duration)
                            e = _clamp_t(clip.duration - trim_duration, clip.duration)
                            if e <= s:
                                e = _clamp_t(s + 0.5, clip.duration)
                            clip = clip.subclip(s, e)
                            log.info(f"[MICRO-STITCH] Trimmed {trim_duration}s from end")
                
                duration = clip.duration
                log.info(f"[MICRO-STITCH] Applied 3 segments with frame cuts. New duration: {duration:.2f}s")
            except Exception as stitch_err:
                log.warning(f"[MICRO-STITCH] Failed to apply: {stitch_err}, using original clip")

        # –ú–∞—Å–∫–∞ —Å–∫—Ä—É–≥–ª–µ–Ω–Ω—ã—Ö —É–≥–ª–æ–≤
        radius = 45
        mask_arr = _rounded_mask((new_w, new_h), radius)
        mask_clip = ImageClip(mask_arr).set_duration(duration)
        mask_clip.ismask = True  # MoviePy 2.1: —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏
        clip = clip.set_mask(mask_clip)

        layers = []
        canvas_clip = ColorClip(canvas_size, color=bg_color).set_duration(duration)
        layers.append(canvas_clip)
        layers.append(clip.set_position("center"))

        # –õ–æ–≥–æ—Ç–∏–ø –æ—Ç–∫–ª—é—á—ë–Ω –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é

        out_path = Path("tmp_media") / f"proc_{local_path.stem}.mp4"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        final_video = CompositeVideoClip(layers)

        # PROFESSIONAL AUDIO: –û–∑–≤—É—á–∫–∞ ElevenLabs –ò–õ–ò –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
        if voiceover_path and Path(voiceover_path).exists():
            try:
                # üéôÔ∏è –û–ó–í–£–ß–ö–ê: –ò—Å–ø–æ–ª—å–∑—É–µ–º ElevenLabs –≤–º–µ—Å—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
                
                voiceover_audio = AudioFileClip(str(voiceover_path))
                
                # –ü–æ–¥–≥–æ–Ω—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–∑–≤—É—á–∫–∏ –ø–æ–¥ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ
                if voiceover_audio.duration < duration:
                    # –ï—Å–ª–∏ –æ–∑–≤—É—á–∫–∞ –∫–æ—Ä–æ—á–µ - –ø–æ–≤—Ç–æ—Ä—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ –ø–æ—Å–ª–µ –Ω–µ—ë
                    if clip.audio is not None:
                        remaining_duration = duration - voiceover_audio.duration
                        audio_end = min(clip.audio.duration, remaining_duration)
                        audio_end = _clamp_t(audio_end, clip.audio.duration)
                        original_audio = clip.audio.subclip(0, audio_end)
                       # from moviepy import concatenate_audioclips
                        audio_track = concatenate_audioclips([voiceover_audio, original_audio])
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ - –ø—Ä–æ—Å—Ç–æ —Ç–∏—à–∏–Ω–∞ –ø–æ—Å–ª–µ –æ–∑–≤—É—á–∫–∏
                        audio_track = voiceover_audio
                elif voiceover_audio.duration > duration:
                    # –í–∏–¥–µ–æ –∫–æ—Ä–æ—á–µ –≥–æ–ª–æ—Å–∞ ‚Äî –∑–∞–º–µ–¥–ª—è–µ–º –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–ª–∏
                     new_speed = duration / voiceover_audio.duration
                     final_video = final_video.fx(vfx_all.speedx, new_speed)
                     audio_track = voiceover_audio
                     log.info(f"[SYNC] –í–∏–¥–µ–æ –∑–∞–º–µ–¥–ª–µ–Ω–æ –¥–æ {new_speed:.2f} –¥–ª—è —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –≥–æ–ª–æ—Å–æ–º")
                else:
                    audio_track = voiceover_audio
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞–µ–º fps –¥–ª—è –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º –Ω–∞ –≤–∏–¥–µ–æ
                if audio_track is not None:
                    audio_track = audio_track.set_fps(44100)
                final_video = final_video.set_audio(audio_track)
                log.info(f"[ELEVENLABS] ‚úÖ Voiceover applied to video: {Path(voiceover_path).name}")
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –æ–∑–≤—É—á–∫–∏
                Path(voiceover_path).unlink()
                log.info("[ELEVENLABS] Voiceover file cleaned up after applying")
            except Exception as voiceover_err:
                log.warning(f"[ELEVENLABS] Failed to apply voiceover: {voiceover_err}, using original audio")
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ
                if clip.audio is not None:
                    final_video = final_video.set_audio(clip.audio)
        elif clip.audio is not None:
            try:
                audio_track = clip.audio
                
                # Smart Pitch Shift: -0.2 –¥–æ +0.2 –ø–æ–ª—É—Ç–æ–Ω–∞ (–≤—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º)
                semitones = random.uniform(-0.2, 0.2)
                pitch_factor = 2 ** (semitones / 12)
                original_fps = audio_track.fps or 44100
                new_fps = int(original_fps * pitch_factor)
                
                # –ò–∑–º–µ–Ω—è–µ–º fps –∞—É–¥–∏–æ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∞ pitch shift
                audio_track = audio_track.with_fps(new_fps)
                log.info(f"[PROFESSIONAL_AUDIO] Pitch shifted: {semitones:+.3f} semitones (fps: {original_fps} -> {new_fps})")
                
                # Tempo Shift: ¬±0.5% –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∞—É–¥–∏–æ
                tempo_change = random.uniform(0.995, 1.005)  # 99.5% - 100.5%
                if abs(tempo_change - 1.0) > 0.001:
                    # –ú–µ–Ω—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ speedx
                    audio_track = audio_track.fx(afx_all.audio_speedx, tempo_change)
                    log.info(f"[PROFESSIONAL_AUDIO] Tempo adjusted: {tempo_change:.4f}x ({(tempo_change-1)*100:+.2f}%)")
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                final_video = final_video.set_audio(audio_track)
                log.info("[PROFESSIONAL_AUDIO] High-quality audio processing applied (NO NOISE)")
            except Exception as audio_err:
                log.warning(f"[PROFESSIONAL_AUDIO] Failed to process audio: {audio_err}, using original audio")
        
        # –†–∞–∑–º—ã—Ç–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤: —Å–æ–∑–¥–∞–µ–º —Ä–∞–∑–º—ã—Ç—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –≤–Ω–∏–∑—É –≤–∏–¥–µ–æ (–≥–¥–µ –æ–±—ã—á–Ω–æ —Å—É–±—Ç–∏—Ç—Ä—ã)
        def add_blur_to_captions(clip):
            # –û–±—Ä–µ–∑–∞–µ–º –∫—É—Å–æ–∫ —Å–Ω–∏–∑—É, —Ä–∞–∑–º—ã–≤–∞–µ–º –µ–≥–æ –∏ –Ω–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
            overlay = clip.crop(y1=int(clip.h*0.8), y2=clip.h).fx(vfx_all.blur, 20)
            return CompositeVideoClip([clip, overlay.set_position(("center", "bottom"))])
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–∞–∑–º—ã—Ç–∏–µ –∫ –≤–∏–¥–µ–æ
        #final_video = add_blur_to_captions(final_video)
        final_video = final_video.set_duration(final_video.duration - 0.5)
        log.info("[BLUR] Blur applied to bottom 20% of video (captions area)")
        
        # === SAFE_DURATION_FIX: –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ===
        eps = 0.25  # Safety margin –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è WinError 32 –ø—Ä–∏ –¥–æ—Å—Ç—É–ø–µ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
        safe_duration = final_video.duration - eps
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞—É–¥–∏–æ –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ
        if final_video.audio is not None:
            audio_duration = final_video.audio.duration
            safe_duration = min(safe_duration, audio_duration - eps)
            log.info(f"[SAFE_DURATION] Video: {final_video.duration:.2f}s, Audio: {audio_duration:.2f}s ‚Üí Safe: {safe_duration:.2f}s (eps={eps})")
            s = _clamp_t(0, final_video.duration)
            e = _clamp_t(safe_duration, final_video.duration)
            if e <= s:
                e = _clamp_t(s + 0.5, final_video.duration)
            final_video = final_video.subclip(s, e)
            final_video.audio = final_video.audio.subclip(s, e)
        else:
            log.info(f"[SAFE_DURATION] No audio track. Trimming video: {final_video.duration:.2f}s ‚Üí {safe_duration:.2f}s")
            s = _clamp_t(0, final_video.duration)
            e = _clamp_t(safe_duration, final_video.duration)
            if e <= s:
                e = _clamp_t(s + 0.5, final_video.duration)
            final_video = final_video.subclip(s, e)
        
        # –ó–∞–ø–∏—Å—å –≤–∏–¥–µ–æ —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–∞–∫—Ä—ã—Ç–∏–µ–º —Ä–µ—Å—É—Ä—Å–æ–≤
        try:
            final_video.write_videofile(
                str(out_path),
                codec="libx264",
                audio_codec="aac",
                fps=30,
                preset="slow",
                bitrate="6000k",
                ffmpeg_params=[
                    "-crf", "18",
                    "-pix_fmt", "yuv420p"
                ],
                logger=None,
            )
            log.info("INFO | [PROCESS] Video unique processing: Success")
        finally:
            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∫–ª–∏–ø–æ–≤ (–∏–∑–±–µ–≥–∞–µ–º WinError 32)
            try:
                if hasattr(final_video, 'close'):
                    final_video.close()
                if hasattr(final_video, 'audio') and final_video.audio is not None and hasattr(final_video.audio, 'close'):
                    final_video.audio.close()
            except Exception as close_err:
                log.warning(f"[SAFE_DURATION] Error closing video/audio clips: {close_err}")
        
        log.info("[SAFE_DURATION] All clips closed successfully")
        
        # üîÑ AUTO-COMPRESS: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∂–∞—Ç–∏–µ (SIZE GUARD)
        try:
            file_size_mb = out_path.stat().st_size / (1024 * 1024)
            max_size_mb = 50  # –õ–∏–º–∏—Ç –¥–ª—è Telegram –∏ Instagram
            
            if file_size_mb > max_size_mb:
                log.warning(f"[AUTO-COMPRESS] File too large: {file_size_mb:.2f} MB > {max_size_mb} MB")
                log.info("[AUTO-COMPRESS] Re-encoding with CRF 22 to reduce size...")
                
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–∂–∞—Ç–æ–π –≤–µ—Ä—Å–∏–∏
                compressed_path = out_path.parent / f"compressed_{out_path.name}"
                
                # –ü–ï–†–í–ê–Ø –ü–û–ü–´–¢–ö–ê: CRF 22, bitrate 4000k —á–µ—Ä–µ–∑ ffmpeg (file-based)
                cmd_crf22 = [
                    "ffmpeg", "-y",
                    "-i", str(out_path),
                    "-c:v", "libx264",
                    "-preset", "medium",
                    "-b:v", "4000k",
                    "-crf", "22",
                    "-pix_fmt", "yuv420p",
                    "-c:a", "aac",
                    "-b:a", "128k",
                    str(compressed_path)
                ]
                
                try:
                    subprocess.run(cmd_crf22, check=True, capture_output=True, timeout=600)
                    compressed_size_mb = compressed_path.stat().st_size / (1024 * 1024)
                    log.info(f"[AUTO-COMPRESS] New size with CRF 22: {compressed_size_mb:.2f} MB (was {file_size_mb:.2f} MB)")
                    
                    if compressed_size_mb <= max_size_mb:
                        # –£—Å–ø–µ—Ö! –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                        out_path.unlink()
                        compressed_path.rename(out_path)
                        log.info(f"‚úÖ [AUTO-COMPRESS] Success! File compressed to {compressed_size_mb:.2f} MB")
                    else:
                        # –í–¢–û–†–ê–Ø –ü–û–ü–´–¢–ö–ê: CRF 24, bitrate 3000k —á–µ—Ä–µ–∑ ffmpeg
                        log.warning(f"[AUTO-COMPRESS] Still too large ({compressed_size_mb:.2f} MB), trying CRF 24...")
                        compressed_path.unlink()  # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—É—é –ø–æ–ø—ã—Ç–∫—É
                        
                        cmd_crf24 = [
                            "ffmpeg", "-y",
                            "-i", str(out_path),
                            "-c:v", "libx264",
                            "-preset", "medium",
                            "-b:v", "3000k",
                            "-crf", "24",
                            "-pix_fmt", "yuv420p",
                            "-c:a", "aac",
                            "-b:a", "128k",
                            str(compressed_path)
                        ]
                        
                        subprocess.run(cmd_crf24, check=True, capture_output=True, timeout=600)
                        final_size_mb = compressed_path.stat().st_size / (1024 * 1024)
                        log.info(f"[AUTO-COMPRESS] Final size with CRF 24: {final_size_mb:.2f} MB")
                        
                        out_path.unlink()
                        compressed_path.rename(out_path)
                        log.info(f"‚úÖ [AUTO-COMPRESS] Compressed with CRF 24 to {final_size_mb:.2f} MB")
                
                except subprocess.TimeoutExpired:
                    log.error("[AUTO-COMPRESS] Compression timeout (600s), keeping original file")
                except subprocess.CalledProcessError as ffmpeg_err:
                    log.error(f"[AUTO-COMPRESS] ffmpeg compression failed: {ffmpeg_err}, keeping original file")
                    if compressed_path.exists():
                        compressed_path.unlink()
            else:
                log.info(f"‚úÖ [SIZE CHECK] File size OK: {file_size_mb:.2f} MB <= {max_size_mb} MB (HD quality preserved)")
        except Exception as compress_err:
            log.error(f"[AUTO-COMPRESS] Failed: {compress_err}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º
        
        return out_path
    except Exception as e:
        log.error(f"Video processing failed, not sending original: {e}")
        try:
            clip.close()
        except Exception:
            pass
        return None


async def prepare_video_for_ready(application, item: dict) -> Path | None:
    """
    –°–ò–°–¢–ï–ú–ê –ö–û–ù–í–ï–ô–ï–†: –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –∑–∞—Ä–∞–Ω–µ–µ —Å —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–µ–π.
    - –°–∫–∞—á–∏–≤–∞–µ—Ç —Å—ã—Ä–æ–µ –≤–∏–¥–µ–æ –∏–∑ Telegram –ò–õ–ò –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Instagram-–∏—Å—Ç–æ—á–Ω–∏–∫
    - –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∏–∫—Ä–æ-–∑—É–º 2%, —Å–ª—É—á–∞–π–Ω—É—é –æ–±—Ä–µ–∑–∫—É, pitch ¬±0.5
    - –°–∂–∏–º–∞–µ—Ç –¥–æ 15-25 –ú–ë (bitrate 2500k)
    - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ ready_to_publish
    - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –≥–æ—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
    """
    try:
        tmp_dir = Path("tmp_media")
        tmp_dir.mkdir(exist_ok=True)
        
        video_file_id = item["file_id"]
        is_instagram_source = False
        
        # ‚úÖ –ü–†–û–í–ï–†–ö–ê: Instagram-–∏—Å—Ç–æ—á–Ω–∏–∫ –∏–ª–∏ Telegram
        if video_file_id == "instagram_source" and item.get("instagram_video_path"):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –∏–∑ Instagram
            instagram_path = Path(item["instagram_video_path"])
            if not instagram_path.exists():
                log.error(f"[CONVEYOR] Instagram video not found: {instagram_path}")
                return None
            local_path = instagram_path
            is_instagram_source = True
            log.info(f"[CONVEYOR] Using Instagram video: {local_path.name}")
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å: —Å–∫–∞—á–∏–≤–∞–µ–º –∏–∑ Telegram
            file_obj = await application.bot.get_file(video_file_id)
            remote_path = getattr(file_obj, "file_path", "") or ""
            suffix = Path(remote_path).suffix or ".mp4"
            local_path = tmp_dir / f"{video_file_id}{suffix}"
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Å—ã—Ä–æ–µ –≤–∏–¥–µ–æ
            await file_obj.download_to_drive(custom_path=str(local_path))
            log.info(f"[CONVEYOR] Downloaded raw video: {local_path.name}")
        
        # –£–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è: –º–∏–∫—Ä–æ-–∑—É–º 2% + —Å–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ + pitch
        caption = item.get("caption", "")
        speed_mult = random.uniform(1.01, 1.03)  # –°–ª—É—á–∞–π–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å 1.01-1.03
        brightness = random.uniform(0.01, 0.03)  # –°–ª—É—á–∞–π–Ω–∞—è —è—Ä–∫–æ—Å—Ç—å
        voiceover_path = item.get("voiceover_path")  # üéôÔ∏è –ü—É—Ç—å –∫ –æ–∑–≤—É—á–∫–µ
        
        processed_path = process_video(
            local_path,
            caption,
            speed_multiplier=speed_mult,
            brightness_adjust=brightness,
            random_crop=True,  # –í—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º crop –¥–ª—è –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
            voiceover_path=voiceover_path  # üéôÔ∏è –ü–µ—Ä–µ–¥–∞–µ–º –æ–∑–≤—É—á–∫—É
        )
        
        if not processed_path or not Path(processed_path).exists():
            log.error(f"[CONVEYOR] Video processing failed for {video_file_id}")
            # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –ù–ï Instagram (–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª Telegram)
            if not is_instagram_source and local_path.exists():
                await safe_unlink(local_path)
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ready_to_publish —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º
        ready_filename = f"ready_{uuid.uuid4().hex[:8]}_{int(time_module.time())}.mp4"
        ready_path = READY_TO_PUBLISH_DIR / ready_filename
        
        # üîç DIAGNOSTICS: –õ–æ–≥–∏—Ä—É–µ–º –ø—É—Ç–∏ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
        log.info(f"[CONVEYOR] Saving ready video: {ready_filename}")
        log.info(f"[CONVEYOR] Ready directory: {READY_TO_PUBLISH_DIR.resolve()}")
        log.info(f"[CONVEYOR] Ready path (absolute): {ready_path.resolve()}")
        
        shutil.move(str(processed_path), str(ready_path))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (—Ü–µ–ª–µ–≤–æ–π 15-25 –ú–ë)
        file_size_mb = ready_path.stat().st_size / (1024 * 1024)
        log.info(f"[CONVEYOR] Ready video saved: {ready_filename} ({file_size_mb:.2f} MB)")
        log.info(f"[CONVEYOR] Saved to (absolute): {ready_path.resolve()}")
        log.info(f"[CONVEYOR] File exists after save: {ready_path.exists()}")

        # –ì–ê–†–ê–ù–¢–ò–Ø: –°—Ä–∞–∑—É —Å–æ—Ö—Ä–∞–Ω—è–µ–º sidecar meta (.json) ‚Äî –Ω–µ –ø–æ–ª–∞–≥–∞–µ–º—Å—è –Ω–∞ –¥–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏
        try:
            meta_path = ready_path.with_suffix('.mp4.json')
            caption_tg_local = prepare_caption_for_publish_tg(caption) if caption else ""
            caption_meta_local = prepare_caption_for_publish_meta(caption) if caption else ""
            meta_obj = {
                "ready_file": ready_path.name,
                "created_at": datetime.utcnow().isoformat(),
                "caption": caption or "",
                "caption_tg": caption_tg_local or "",
                "caption_meta": caption_meta_local or "",
                "source_id": item.get("id") or item.get("video_file_id") or item.get("ig_media_id") or ""
            }
            meta_path.write_text(json.dumps(meta_obj, ensure_ascii=False, indent=2), encoding='utf-8')
            log.info(f"[CONVEYOR] Ready meta saved: {meta_path.name} (exists={meta_path.exists()})")
        except Exception as meta_err:
            log.error(f"[CONVEYOR] Failed to write ready meta sidecar: {meta_err}")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
        if local_path.exists():
            await safe_unlink(local_path)
            if is_instagram_source:
                log.info("[CONVEYOR] Instagram source video cleaned up after processing")
        
        return ready_path
        
    except Exception as e:
        error_msg = str(e)
        
        # üö® CRITICAL: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Invalid file_id (–ù–û –ù–ï –¥–ª—è Instagram!)
        if ("Invalid file_id" in error_msg or "file_id" in error_msg.lower()) and item.get('file_id') != "instagram_source":
            log.critical(f"üö® CRITICAL | [CONVEYOR] Skipping broken post due to Invalid file_id: {item.get('file_id', 'unknown')[:20]}")
            return None
        
        log.error(f"[CONVEYOR] prepare_video_for_ready failed: {e}")
        return None


def process_photo(local_path: Path) -> Path | None:
    """–ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç –ª–æ–≥–æ—Ç–∏–ø –Ω–∞ —Ñ–æ—Ç–æ (–Ω–∏–∂–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª, 15% —à–∏—Ä–∏–Ω—ã, –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π)."""
    try:
        img = Image.open(local_path).convert("RGBA")
        dark_palette = [
            (0, 0, 0),
            (10, 10, 20),
            (20, 20, 30),
            (12, 8, 24),
            (6, 12, 18),
        ]
        # –ó–¥–µ—Å—å –ª–æ–≥–æ—Ç–∏–ø —É–±—Ä–∞–Ω; –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª —Å –≤–æ–∑–º–æ–∂–Ω—ã–º –±—É–¥—É—â–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        out_path = local_path
        return out_path
    except Exception as e:
        log.error(f"Photo processing failed (logo): {e}")
        return None


def load_stats():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ñ–∞–π–ª–∞"""
    global DAILY_STATS
    if STATS_FILE.exists():
        try:
            with STATS_FILE.open("r", encoding="utf-8") as f:
                data = json.load(f)
                today = datetime.now().strftime("%Y-%m-%d")
                if data.get("date") == today:
                    DAILY_STATS.update(data)
                else:
                    # –ù–æ–≤—ã–π –¥–µ–Ω—å - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    reset_stats()
        except Exception as e:
            log.warning(f"Failed to load stats: {e}")
            reset_stats()
    else:
        reset_stats()


def save_stats():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Ñ–∞–π–ª"""
    try:
        with STATS_FILE.open("w", encoding="utf-8") as f:
            json.dump(DAILY_STATS, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f"Failed to save stats: {e}")


def reset_stats():
    """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞ –Ω–æ–≤—ã–π –¥–µ–Ω—å"""
    global DAILY_STATS
    today = datetime.now().strftime("%Y-%m-%d")
    DAILY_STATS = {
        "date": today,
        "morning": 0,
        "afternoon": 0,
        "video": 0,
        "photo": 0,
        "text": 0,
        "total": 0,
        "tokens": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
        },
        "cost_usd": 0.0
    }
    save_stats()


def log_tokens(prompt_tokens: int, completion_tokens: int, total_tokens: int):
    """–õ–æ–≥–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω—ã, –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞."""
    global DAILY_STATS, DAILY_COST_USD, TRANSLATION_LAST_COST
    today = datetime.now().strftime("%Y-%m-%d")
    
    if DAILY_STATS.get("date") != today:
        reset_stats()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á—ë—Ç—á–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
    DAILY_STATS["tokens"]["prompt_tokens"] += prompt_tokens
    DAILY_STATS["tokens"]["completion_tokens"] += completion_tokens
    DAILY_STATS["tokens"]["total_tokens"] += total_tokens
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è gpt-4o-mini
    # input: $0.15/1M, output: $0.60/1M
    input_cost = (prompt_tokens / 1_000_000) * 0.15
    output_cost = (completion_tokens / 1_000_000) * 0.60
    total_cost = input_cost + output_cost
    
    DAILY_STATS["cost_usd"] += total_cost
    DAILY_COST_USD += total_cost
    TRANSLATION_LAST_COST += total_cost
    
    log.info(f"TOKENS USED: prompt={prompt_tokens}, completion={completion_tokens}, total={total_tokens}, cost=${total_cost:.6f}")
    save_stats()
    return total_cost


def increment_stat(post_type: str):
    """–£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—á—ë—Ç—á–∏–∫ –¥–ª—è —Ç–∏–ø–∞ –ø–æ—Å—Ç–∞"""
    global DAILY_STATS
    today = datetime.now().strftime("%Y-%m-%d")
    
    # –ï—Å–ª–∏ –Ω–æ–≤—ã–π –¥–µ–Ω—å - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
    if DAILY_STATS.get("date") != today:
        reset_stats()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
    now = datetime.now()
    if now.hour < 14:
        DAILY_STATS["morning"] += 1
    else:
        DAILY_STATS["afternoon"] += 1
    
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ —Ç–∏–ø–∞
    if post_type in ["video", "photo", "text"]:
        DAILY_STATS[post_type] += 1
    
    DAILY_STATS["total"] += 1
    save_stats()


async def send_daily_report(application):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á—ë—Ç"""
    today = datetime.now().strftime("%Y-%m-%d")
    
    if DAILY_STATS.get("date") != today:
        return
    
    stats = DAILY_STATS
    tokens = stats.get("tokens", {})
    cost = stats.get("cost_usd", 0.0)
    
    report = (
        f"üìä –û—Ç—á—ë—Ç Haqiqat ({today})\n\n"
        f"–î–æ –æ–±–µ–¥–∞: {stats['morning']} –ø–æ—Å—Ç–æ–≤\n"
        f"–ü–æ—Å–ª–µ –æ–±–µ–¥–∞: {stats['afternoon']} –ø–æ—Å—Ç–æ–≤\n"
        f"–í–∏–¥–µ–æ: {stats['video']}\n"
        f"–§–æ—Ç–æ: {stats['photo']}\n"
        f"–¢–µ–∫—Å—Ç: {stats['text']}\n"
        f"–í—Å–µ–≥–æ –∑–∞ –¥–µ–Ω—å: {stats['total']}\n\n"
        f"–¢–æ–∫–µ–Ω—ã:\n"
        f"  Prompt: {tokens.get('prompt_tokens', 0):,}\n"
        f"  Completion: {tokens.get('completion_tokens', 0):,}\n"
        f"  –í—Å–µ–≥–æ: {tokens.get('total_tokens', 0):,}\n\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å: ${cost:.4f}"
    )
    
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á—ë—Ç –∞–¥–º–∏–Ω—É, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –∏–Ω–∞—á–µ –≤ –ª–æ–≥
        if ADMIN_CHAT_ID:
            await application.bot.send_message(
                chat_id=ADMIN_CHAT_ID,
                text=report
            )
            log.info("Daily report sent to admin")
        else:
            log.info(f"Daily report:\n{report}")
    except Exception as e:
        log.error(f"Failed to send daily report: {e}")
        log.info(f"Daily report (fallback):\n{report}")


async def send_progress_report(application):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞"""
    if not (REPORT_AFTER_POST and ADMIN_CHAT_ID):
        return

    stats = DAILY_STATS
    tokens = stats.get("tokens", {})

    report = (
        "‚úÖ –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\n"
        f"–í—Å–µ–≥–æ —Å–µ–≥–æ–¥–Ω—è: {stats.get('total', 0)}\n"
        f"–í–∏–¥–µ–æ: {stats.get('video', 0)}, —Ñ–æ—Ç–æ: {stats.get('photo', 0)}, —Ç–µ–∫—Å—Ç: {stats.get('text', 0)}\n"
        f"–¢–æ–∫–µ–Ω—ã: prompt {tokens.get('prompt_tokens', 0)}, completion {tokens.get('completion_tokens', 0)}\n"
        f"–°—Ç–æ–∏–º–æ—Å—Ç—å (–æ—Ü–µ–Ω–∫–∞): ${stats.get('cost_usd', 0.0):.4f}"
    )

    try:
        await application.bot.send_message(chat_id=ADMIN_CHAT_ID, text=report)
        log.info("Progress report sent to admin")
    except Exception as e:
        log.warning(f"Failed to send progress report: {e}")


async def send_daily_stats(application):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ 23:30 –ø–æ —Å–µ—Ä–≤–µ—Ä–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏."""
    today = datetime.now().strftime("%Y-%m-%d")
    if DAILY_STATS.get("date") != today:
        reset_stats()
    total_posts = DAILY_STATS.get("total", 0)
    cost = DAILY_STATS.get("cost_usd", 0.0)
    report = f"–í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤ —Å–µ–≥–æ–¥–Ω—è: {total_posts}. –ó–∞—Ç—Ä–∞—Ç—ã –Ω–∞ OpenAI: ${cost:.2f}."
    try:
        if ADMIN_CHAT_ID:
            await application.bot.send_message(chat_id=ADMIN_CHAT_ID, text=report)
            log.info("Daily stats sent to admin")
        else:
            log.info(f"Daily stats: {report}")
    except Exception as e:
        log.error(f"Failed to send daily stats: {e}")
        log.info(f"Daily stats (fallback): {report}")


async def daily_report_scheduler(application):
    """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á—ë—Ç–∞"""
    while True:
        now = datetime.now()
        target_time = datetime.combine(now.date(), time(hour=23, minute=30))

        if now >= target_time:
            await send_daily_stats(application)
            target_time = datetime.combine(now.date() + timedelta(days=1), time(hour=23, minute=30))

        wait_seconds = (target_time - datetime.now()).total_seconds()
        await asyncio.sleep(max(wait_seconds, 60))


async def history_log_scheduler():
    """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏ history.log –≤ 23:50."""
    while True:
        now = datetime.now()
        target_time = datetime.combine(now.date(), time(hour=23, minute=50))

        if now >= target_time:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç –ø–µ—Ä–µ–¥ —Ä–æ—Ç–∞—Ü–∏–µ–π
            total_posts = DAILY_STATS.get("total", 0)
            cost = DAILY_STATS.get("cost_usd", 0.0)
            report_text = (
                f"üìä Kunlik hisobot\n"
                f"Postlar: {total_posts}\n"
                f"OpenAI xarajatlari: ${cost:.4f}\n"
            )
            send_report_message(report_text)
            rotate_history_log()
            target_time = datetime.combine(now.date() + timedelta(days=1), time(hour=23, minute=50))

        wait_seconds = (target_time - datetime.now()).total_seconds()
        await asyncio.sleep(max(wait_seconds, 60))


def load_ready_files_to_queue():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ –∏–∑ ready_to_publish –≤ POST_QUEUE.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ POST_QUEUE –ø—É—Å—Ç–∞—è, –Ω–æ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã.
    """
    # üîç DIAGNOSTICS: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç–∏
    cwd = Path.cwd()
    ready_dir_resolved = READY_TO_PUBLISH_DIR.resolve()
    log.info(f"[QUEUE LOADER] Current working directory: {cwd}")
    log.info(f"[QUEUE LOADER] Ready directory (absolute): {ready_dir_resolved}")
    log.info(f"[QUEUE LOADER] Ready directory exists: {ready_dir_resolved.exists()}")
    
    ready_files = sorted(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
    
    if not ready_files:
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –µ—Å–ª–∏ –ø–∞–ø–∫–∞ –ø—É—Å—Ç–∞—è
        all_files_in_dir = list(READY_TO_PUBLISH_DIR.glob("*"))[:20]
        log.warning(f"[QUEUE LOADER] No ready files found in {ready_dir_resolved}")
        log.warning(f"[QUEUE LOADER] Directory contents (first 20): {[f.name for f in all_files_in_dir]}")
        return 0
    
    log.info(f"[DEBUG] Queue empty, found {len(ready_files)} ready files on disk. Filling queue...")
    
    loaded_count = 0
    for ready_file in ready_files:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–∂–µ
        # READY_META_EXT_FIX: Try both .json and .mp4.json formats
        meta_file_a = ready_file.with_suffix(".json")
        meta_file_b = ready_file.with_suffix(".mp4.json")
        meta_file = meta_file_a if meta_file_a.exists() else (meta_file_b if meta_file_b.exists() else None)
        
        file_exists = ready_file.exists()
        meta_exists = meta_file is not None
        
        log.info(f"[QUEUE LOADER] Processing {ready_file.name}: file_exists={file_exists}, meta_exists={meta_exists}")
        log.info(f"[QUEUE LOADER] File path (absolute): {ready_file.resolve()}")
        log.info(f"[QUEUE LOADER] meta picked: {meta_file.name if meta_file else 'NONE'}")
        
        if not meta_file:
            log.warning(f"[QUEUE LOADER] Metadata missing for {ready_file.name} (tried .json and .mp4.json), skipping")
            continue
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            meta_data = json.loads(meta_file.read_text(encoding="utf-8"))

            # –°–æ–∑–¥–∞–µ–º item –¥–ª—è –æ—á–µ—Ä–µ–¥–∏
            item = {
                "type": "video",
                "file_id": meta_data.get("file_id", "unknown"),
                "caption": meta_data.get("caption", ""),
                "ready_file_path": str(ready_file),
                "ready_metadata": meta_data,
                "from_ready_folder": True  # –§–ª–∞–≥, —á—Ç–æ —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            }

            POST_QUEUE.append(item)
            loaded_count += 1
            log.info(f"[QUEUE LOADER] Added {ready_file.name} to queue")

        except Exception as e:
            log.error(f"[QUEUE LOADER] Failed to load metadata for {ready_file.name}: {e}")
            continue
    
    if loaded_count > 0:
        save_queue()
        log.info(f"[QUEUE LOADER] Loaded {loaded_count} ready files into queue. Queue size: {len(POST_QUEUE)}")
    
    return loaded_count


async def maintain_ready_posts_worker(application):
    """
    –°–ò–°–¢–ï–ú–ê –ö–û–ù–í–ï–ô–ï–†: –§–æ–Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è 5 –≥–æ—Ç–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤.
    - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ ready_to_publish
    - –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 5, –±–µ—Ä–µ—Ç –≤–∏–¥–µ–æ –∏–∑ POST_QUEUE –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç
    - –†–µ–Ω–¥–µ—Ä–∏—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É –∑–∞ —Ä–∞–∑
    """
    global IS_PREPARING
    
    log.info("[CONVEYOR] Maintain ready posts worker started")
    
    while True:
        try:
            # –°—á–∏—Ç–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –≤–∏–¥–µ–æ (—Ç–æ–ª—å–∫–æ .mp4 —Ñ–∞–π–ª—ã)
            ready_files = list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
            ready_count = len(ready_files)
            
            # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏
            if ready_count < TARGET_READY_POSTS and POST_QUEUE and not IS_PREPARING:
                IS_PREPARING = True
                log.info(f"[CONVEYOR] Ready posts: {ready_count}/{TARGET_READY_POSTS}. Preparing new video...")
                
                # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ –≤–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏ (—Ç–æ–ª—å–∫–æ –°–´–†–´–ï, –Ω–µ –≥–æ—Ç–æ–≤—ã–µ)
                video_item = None
                for idx, item in enumerate(POST_QUEUE):
                    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Å—ã—Ä—ã–µ –≤–∏–¥–µ–æ (–Ω–µ –∏–∑ ready_to_publish)
                    if item.get("type") == "video" and not item.get("from_ready_folder", False):
                        video_item = item
                        # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                        POST_QUEUE.remove(item)
                        save_queue()
                        log.info(f"[CONVEYOR] Took RAW video from queue position {idx}, queue size: {len(POST_QUEUE)}")
                        break
                
                if video_item:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
                    ready_path = await prepare_video_for_ready(application, video_item)
                    
                    if ready_path:
                        log.info(f"[CONVEYOR] Successfully prepared: {ready_path.name}")
                        # –£–¥–∞–ª—è–µ–º –∏–∑ –±—É—Ñ–µ—Ä–∞
                        try:
                            await delete_from_buffer(application, video_item)
                        except Exception as e:
                            log.warning(f"[CONVEYOR] Failed to delete from buffer: {e}")
                    else:
                        # –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å - prepare_video_for_ready –≤–µ—Ä–Ω—É–ª–∞ None –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏
                        log.critical(f"üö® CRITICAL | [CONVEYOR] Failed to prepare video, SKIPPING (not returning to queue)")
                        # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –∏–∑ –±—É—Ñ–µ—Ä–∞
                        try:
                            await delete_from_buffer(application, video_item)
                        except Exception as e:
                            log.warning(f"[CONVEYOR] Failed to delete from buffer: {e}")
                
                IS_PREPARING = False
                
            elif ready_count >= TARGET_READY_POSTS:
                log.info(f"[CONVEYOR] Ready posts: {ready_count}/{TARGET_READY_POSTS}. Target reached.")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            await asyncio.sleep(30)
            
        except Exception as e:
            log.error(f"[CONVEYOR] maintain_ready_posts_worker error: {e}")
            IS_PREPARING = False
            await asyncio.sleep(60)


def post_hash(item: dict) -> str:
    base = item.get("type", "")
    if item["type"] == "text":
        base += item.get("text", "")
    else:
        base += item.get("file_id", "") + (item.get("caption") or "")

    return hashlib.sha256(base.encode("utf-8")).hexdigest()


def clean_text_before_translation(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ —Ö–≤–æ—Å—Ç—ã (–Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤, –ø–æ–¥–ø–∏—Å–∏) –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º"""
    if not text:
        return text
    
    import re
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ö–≤–æ—Å—Ç–æ–≤
    patterns_to_remove = [
        r"–¶–µ—Ä–µ–±—Ä–∞[^\n]*",
        r"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å[^\n]*",
        r"–ü–æ–¥–ø–∏—Å–∫–∞[^\n]*",
        r"–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è[^\n]*",
        r"–ö–∞–Ω–∞–ª[^\n]*",
        r"@[a-zA-Z0-9_]+",  # –£–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤
        r"https?://[^\s]+",  # –°—Å—ã–ª–∫–∏
        r"t\.me/[^\s]+",  # Telegram —Å—Å—ã–ª–∫–∏
        r"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è[^\n]*",
        r"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å –Ω–∞[^\n]*",
        r"–ü–æ–¥–ø–∏—à–∏—Å—å[^\n]*",
        r"–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞[^\n]*",
    ]
    
    cleaned = text
    for pattern in patterns_to_remove:
        cleaned = re.sub(pattern, "", cleaned, flags=re.IGNORECASE)
    
    # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –º—ã—Å–ª–∏ (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
    lines = cleaned.split('\n')
    seen_lines = set()
    unique_lines = []
    for line in lines:
        line_stripped = line.strip().lower()
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ
        if len(line_stripped) < 10:
            unique_lines.append(line)
            continue
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç—å (–µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —É–∂–µ –±—ã–ª–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
        if line_stripped not in seen_lines:
            seen_lines.add(line_stripped)
            unique_lines.append(line)
    
    return '\n'.join(unique_lines).strip()


async def translate_text(text: str) -> str:
    """–£–º–Ω—ã–π —Ä–µ–∂–∏–º –ø–µ—Ä–µ–≤–æ–¥–∞ —Å self-check"""
    if not openai_client or not text:
        return text

    # –û—á–∏—â–∞–µ–º –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ö–≤–æ—Å—Ç–æ–≤ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º
    cleaned_text = clean_text_before_translation(text)

    attempts = 3
    last_error = None

    for attempt in range(1, attempts + 1):
        try:
            # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: –ø–µ—Ä–µ–≤–æ–¥
            TRANSLATION_LAST_COST = 0.0
            resp1 = openai_client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                max_tokens=800,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Sen master aforizmlar va hikmatli so'zlar ijodkorisan. Maqsad: rus tilidagi matnni o'zbek (lotin) tilida ma'noli, qisqa, tabiiy va kuchli ohangda berish. "
                            "So'zma-so'z tarjimadan qoch, ma'no ustuvor. Masalan, '–¢–∏—Ö–∞—è —Å–∏–ª–∞' ‚Äî 'Vazmin quvvat' yoki 'Sokin qudrat', lekin 'Jim kuch' emas.\n"
                            "Qoidalar:\n"
                            "- qisqa, ravon, ta'sirli; ortiqcha so'zlar yo'q\n"
                            "- tuzilmani saqla (abzas, quote >), emoji qolgani joyida\n"
                            "- kanallar, xeshteglar va xizmat belgilarini tarjima qilma\n"
                            "- so'rov/komment so'ramagin\n"
                            "- 1-2 kuchli so'zni *yulduzcha* bilan belgilashing mumkin\n"
                            "- Matn oxirida 3-5 tegishli xeshteg (#hikmatlar #motivation #uzb #muvaffaqiyat kabi), o'zbek va ingliz tili aralash. Xeshteglar faqat caption uchundir, rasmga emas.\n"
                            "Natija: faqat yakuniy tayyor matn, oxirida xeshteglar bilan."
                        ),
                    },
                    {"role": "user", "content": cleaned_text},
                ],
            )
            
            translated = (resp1.choices[0].message.content or cleaned_text).strip()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            usage = resp1.usage
            if usage:
                log_tokens(usage.prompt_tokens, usage.completion_tokens, usage.total_tokens)
            
            # –ï—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –ø–æ–≤—Ç–æ—Ä—è–µ–º
            if not translated:
                raise RuntimeError("Empty translation")

            # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: self-check
            resp2 = openai_client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                max_tokens=800,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ —É–∑–±–µ–∫—Å–∫–∏–π —è–∑—ã–∫.\n\n"
                            "–û—Ü–µ–Ω–∏ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:\n"
                            '{"readability": 1-10, "logic": 1-10, "style": 1-10, "no_repeat": 1-10, "issues": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"], "improved_text": "—É–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"}\n\n'
                            "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:\n"
                            "- readability: —á–∏—Ç–∞–µ–º–æ—Å—Ç—å (1-10)\n"
                            "- logic: –ª–æ–≥–∏–∫–∞ –∏ —Å–≤—è–∑–Ω–æ—Å—Ç—å (1-10)\n"
                            "- style: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å Telegram-—Å—Ç–∏–ª—è (1-10)\n"
                            "- no_repeat: –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–≤—Ç–æ—Ä–æ–≤ —Å –¥—Ä—É–≥–∏–º–∏ –ø–æ—Å—Ç–∞–º–∏ (1-10)\n\n"
                            "–ï—Å–ª–∏ –õ–Æ–ë–ê–Ø –æ—Ü–µ–Ω–∫–∞ < 7 –∏–ª–∏ —Å—Ä–µ–¥–Ω—è—è < 7, —Ç–æ improved_text –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é:\n"
                            "- —É–ø—Ä–æ—Å—Ç–∏—Ç—å\n"
                            "- —É–∫–æ—Ä–æ—Ç–∏—Ç—å\n"
                            "- —É–±—Ä–∞—Ç—å –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞\n"
                            "- —Å–¥–µ–ª–∞—Ç—å –±–æ–ª–µ–µ –∂–∏–≤—ã–º\n\n"
                            "–¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –í–°–ï –æ—Ü–µ–Ω–∫–∏ >= 7, improved_text –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–≤–µ–Ω –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É."
                        ),
                    },
                    {
                        "role": "user",
                        "content": f"–û—Ü–µ–Ω–∏ —ç—Ç–æ—Ç –ø–µ—Ä–µ–≤–æ–¥:\n\n{translated}"
                    },
                ],
                response_format={"type": "json_object"},
            )
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            usage2 = resp2.usage
            if usage2:
                log_tokens(usage2.prompt_tokens, usage2.completion_tokens, usage2.total_tokens)
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            try:
                check_result = json.loads(resp2.choices[0].message.content or "{}")
                
                readability = check_result.get("readability", 10)
                logic = check_result.get("logic", 10)
                style = check_result.get("style", 10)
                no_repeat = check_result.get("no_repeat", 10)  # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–≤—Ç–æ—Ä–∞
                
                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å >= 7
                min_score = min(readability, logic, style, no_repeat)
                avg_score = (readability + logic + style + no_repeat) / 4
                
                improved_text = check_result.get("improved_text", translated)
                
                log.info(f"Translation self-check: readability={readability}, logic={logic}, style={style}, no_repeat={no_repeat}, min={min_score:.2f}, avg={avg_score:.2f}")
                
                # –ï—Å–ª–∏ –ª—é–±–∞—è –æ—Ü–µ–Ω–∫–∞ < 7 ‚Üí –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å
                if min_score < 7 or avg_score < 7:
                    log.warning(f"REWRITE: low score (min={min_score:.2f}, avg={avg_score:.2f}), using improved_text")
                    return improved_text
                else:
                    log.info(f"OK: translation approved (min={min_score:.2f}, avg={avg_score:.2f})")
                    return improved_text
                    
            except (json.JSONDecodeError, KeyError) as e:
                log.warning(f"Failed to parse self-check JSON: {e}, using original translation")
                return translated
        except Exception as e:
            last_error = e
            log.warning(f"Translate attempt {attempt}/{attempts} failed: {e}")
            if attempt == attempts:
                log.error(f"Translate error after {attempts} attempts: {e}")
                send_admin_error(f"OpenAI translation failed: {e}")
                return text
            await asyncio.sleep(1)
    
    # fallback
    if last_error:
        log.error(f"Translate fatal: {last_error}")
    return text


# ==================== WHISPER AUDIO-TO-TEXT ====================

def extract_audio_from_video(video_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É –∏–∑ –≤–∏–¥–µ–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π mp3 —Ñ–∞–π–ª.
    
    Args:
        video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
        
    Returns:
        –ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        from moviepy.editor import VideoFileClip
        
        tmp_audio_path = Path("tmp_media") / "whisper_temp.mp3"
        tmp_audio_path.parent.mkdir(exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ
        video = VideoFileClip(str(video_path))
        if video.audio is None:
            log.warning(f"[WHISPER] No audio track in video: {video_path}")
            video.close()
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        video.audio.write_audiofile(
            str(tmp_audio_path),
            codec='mp3',
            bitrate='128k',
            logger=None  # –û—Ç–∫–ª—é—á–∞–µ–º verbose –ª–æ–≥–∏
        )
        video.close()
        
        log.info(f"[WHISPER] Audio extracted: {tmp_audio_path.name} ({tmp_audio_path.stat().st_size / 1024:.1f} KB)")
        return tmp_audio_path
        
    except Exception as e:
        log.error(f"[WHISPER] Audio extraction failed: {e}")
        return None


def get_video_transcript(video_path):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ OpenAI Whisper API.
    
    Args:
        video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
        
    Returns:
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not openai_client:
        log.warning("[WHISPER] OpenAI client not initialized")
        return None
    
    audio_path = None
    try:
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
        audio_path = extract_audio_from_video(video_path)
        if not audio_path or not audio_path.exists():
            log.warning("[WHISPER] Audio extraction failed, skipping transcription")
            return None
        
        # 2. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Whisper API
        log.info("[WHISPER] Sending audio to Whisper API...")
        with open(audio_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"  # –£–∫–∞–∑—ã–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–π –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            )
        
        transcript_text = transcript.text.strip()
        log.info(f"[WHISPER] Transcription received: {len(transcript_text)} chars")
        log.info(f"[WHISPER] Preview: {transcript_text[:100]}...")
        
        return transcript_text
        
    except Exception as e:
        log.error(f"[WHISPER] Transcription failed: {e}")
        return None
        
    finally:
        # 3. Cleanup: –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª
        if audio_path and audio_path.exists():
            try:
                audio_path.unlink()
                log.info("[WHISPER] Temporary audio file deleted")
            except Exception as e:
                log.warning(f"[WHISPER] Failed to delete temp audio: {e}")


# ==================== END WHISPER ====================


# ==================== ELEVENLABS VOICE ====================

def generate_voiceover(text):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–∑–≤—É—á–∫—É —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ ElevenLabs API.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (—É–∑–±–µ–∫—Å–∫–∏–π)
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not ELEVENLABS_API_KEY:
        log.warning("[ELEVENLABS] API key not configured, skipping voiceover")
        return None
    
    try:
        from elevenlabs import VoiceSettings
        from elevenlabs.client import ElevenLabs
        
        client = ElevenLabs(api_key=ELEVENLABS_API_KEY)

        # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–∑–≤—É—á–∫–∏
        tmp_voiceover_path = Path("tmp_media") / "voiceover.mp3"
        tmp_voiceover_path.parent.mkdir(exist_ok=True)
        
        log.info(f"[ELEVENLABS] Generating voiceover for {len(text)} chars...")
        log.info(f"[ELEVENLABS] Text preview: {text[:100]}...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–∑–≤—É—á–∫—É
        response = client.text_to_speech.convert(
            voice_id=ELEVENLABS_VOICE_ID,
            output_format="mp3_44100_128",
            text=text,
            model_id="eleven_multilingual_v2",
            voice_settings=VoiceSettings(
                stability=0.5,
                similarity_boost=0.75,
                style=0.0,
                use_speaker_boost=True
            )
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ
        with open(tmp_voiceover_path, "wb") as f:
            for chunk in response:
                if chunk:
                    f.write(chunk)
        
        file_size_kb = tmp_voiceover_path.stat().st_size / 1024
        log.info(f"[ELEVENLABS] ‚úÖ Voiceover generated: {tmp_voiceover_path.name} ({file_size_kb:.1f} KB)")
        
        return tmp_voiceover_path
        
    except ImportError:
        log.error("[ELEVENLABS] elevenlabs package not installed. Run: pip install elevenlabs")
        return None
    except Exception as e:
        log.error(f"[ELEVENLABS] Voiceover generation failed: {e}")
        return None


# ==================== END ELEVENLABS ====================


# ==================== SMART INSTAGRAM DOWNLOADER ====================

def download_from_instagram(url):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –∏–∑ Instagram —á–µ—Ä–µ–∑ yt-dlp.
    
    Args:
        url: URL Instagram –ø–æ—Å—Ç–∞/reels
        
    Returns:
        –ü—É—Ç—å –∫ —Å–∫–∞—á–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        import yt_dlp
        
        tmp_dir = Path("tmp_media")
        tmp_dir.mkdir(exist_ok=True)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        import hashlib
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        output_template = str(tmp_dir / f"instagram_{url_hash}.%(ext)s")
        
        ydl_opts = {
            'format': 'best[ext=mp4]/best',
            'outtmpl': output_template,
            'quiet': True,
            'no_warnings': True,
            'extract_flat': False,
        }
        
        log.info(f"[INSTAGRAM] Downloading video from: {url[:50]}...")
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            filename = ydl.prepare_filename(info)
            
        if not Path(filename).exists():
            log.error(f"[INSTAGRAM] Downloaded file not found: {filename}")
            return None
        
        file_size_mb = Path(filename).stat().st_size / (1024 * 1024)
        log.info(f"[INSTAGRAM] ‚úÖ Video downloaded: {Path(filename).name} ({file_size_mb:.1f} MB)")
        
        return Path(filename)
        
    except ImportError:
        log.error("[INSTAGRAM] yt-dlp package not installed. Run: pip install yt-dlp")
        return None
    except Exception as e:
        log.error(f"[INSTAGRAM] Download failed: {e}")
        return None


# ==================== END INSTAGRAM DOWNLOADER ====================


# ==================== MIXED QUEUE 4+4 LOGIC ====================

def get_next_post_from_queue():
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –ø–æ –ª–æ–≥–∏–∫–µ 4+4:
    - 4 –ø–æ—Å—Ç–∞ —Å voiceover: True
    - 4 –ø–æ—Å—Ç–∞ —Å voiceover: False
    - –ï—Å–ª–∏ –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞ –Ω–µ—Ç, –±–µ—Ä—ë—Ç —Ç–æ, —á—Ç–æ –µ—Å—Ç—å
    
    Returns:
        –ü–æ—Å—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –∏–ª–∏ None
    """
    global VOICEOVER_POSTS_COUNT, NO_VOICEOVER_POSTS_COUNT, CURRENT_BLOCK_TYPE
    
    if not POST_QUEUE:
        return None
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π —Ç–∏–ø –ø–æ—Å—Ç–∞ –Ω—É–∂–µ–Ω —Å–µ–π—á–∞—Å
    if CURRENT_BLOCK_TYPE == "voiceover":
        target_voiceover = True
        needed = 4 - VOICEOVER_POSTS_COUNT
    else:
        target_voiceover = False
        needed = 4 - NO_VOICEOVER_POSTS_COUNT
    
    log.info(f"[MIXED QUEUE] Current block: {CURRENT_BLOCK_TYPE}, progress: {VOICEOVER_POSTS_COUNT if CURRENT_BLOCK_TYPE == 'voiceover' else NO_VOICEOVER_POSTS_COUNT}/4")
    
    # –ò—â–µ–º –ø–æ—Å—Ç –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞
    for idx, item in enumerate(POST_QUEUE):
        if item.get("voiceover", False) == target_voiceover:
            # –ù–∞—à–ª–∏ –Ω—É–∂–Ω—ã–π —Ç–∏–ø
            post = POST_QUEUE[idx]
            del POST_QUEUE[idx]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á—ë—Ç—á–∏–∫–∏
            if target_voiceover:
                VOICEOVER_POSTS_COUNT += 1
                log.info(f"[MIXED QUEUE] Selected voiceover post ({VOICEOVER_POSTS_COUNT}/4)")
                if VOICEOVER_POSTS_COUNT >= 4:
                    CURRENT_BLOCK_TYPE = "no_voiceover"
                    VOICEOVER_POSTS_COUNT = 0
                    log.info("[MIXED QUEUE] ‚úÖ Voiceover block complete, switching to no_voiceover")
            else:
                NO_VOICEOVER_POSTS_COUNT += 1
                log.info(f"[MIXED QUEUE] Selected no_voiceover post ({NO_VOICEOVER_POSTS_COUNT}/4)")
                if NO_VOICEOVER_POSTS_COUNT >= 4:
                    CURRENT_BLOCK_TYPE = "voiceover"
                    NO_VOICEOVER_POSTS_COUNT = 0
                    log.info("[MIXED QUEUE] ‚úÖ No_voiceover block complete, switching to voiceover")
            
            return post
    
    # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞ –Ω–µ—Ç, –±–µ—Ä—ë–º —á—Ç–æ –µ—Å—Ç—å
    log.warning(f"[MIXED QUEUE] No {CURRENT_BLOCK_TYPE} posts available, taking any post")
    return POST_QUEUE.popleft()


# ==================== END MIXED QUEUE ====================


SYSTEM_PROMPT_UZ = (
    "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏—Å—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —É–∑–±–µ–∫—Å–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ (SCENARIST MODE). "
    "–í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∏–∑ –≤–∏–¥–µ–æ) –∫–∞–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫. –°–æ–∑–¥–∞–π –Ω–∞ –µ–≥–æ –æ—Å–Ω–æ–≤–µ –≤–æ–≤–ª–µ–∫–∞—é—â–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∞ —É–∑–±–µ–∫—Å–∫–æ–º —è–∑—ã–∫–µ (–ª–∞—Ç–∏–Ω–∏—Ü–∞). "
    "\n"
    "üé£ –ö–†–Æ–ß–û–ö (HOOK) ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û! –ù–∞—á–Ω–∏ —Ç–µ–∫—Å—Ç —Å –æ–¥–Ω–æ–≥–æ –∏–∑ —ç—Ç–∏—Ö –∫—Ä—é—á–∫–æ–≤, –≤—ã–±–µ—Ä–∏ —Å–∞–º—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∏–¥–µ–æ:\n"
    "1. Siz buni bilarmidingiz... (–ê –≤—ã –∑–Ω–∞–ª–∏...)\n"
    "2. Bunga ishonish qiyin, lekin bu haqiqat... (–¢—Ä—É–¥–Ω–æ –ø–æ–≤–µ—Ä–∏—Ç—å, –Ω–æ —ç—Ç–æ –ø—Ä–∞–≤–¥–∞...)\n"
    "3. Buni ko'pchilikdan yashirishgan! (–≠—Ç–æ —Å–∫—Ä—ã–≤–∞–ª–∏ –æ—Ç –º–Ω–æ–≥–∏—Ö!)\n"
    "4. Oxirigacha ko'ring, natijasi hayratlanarli! (–î–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ –∫–æ–Ω—Ü–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Ä–∞–∑–∏—Ç–µ–ª–µ–Ω!)\n"
    "5. Sizningcha, bu qanday sodir bo'ldi? (–ö–∞–∫ –≤—ã –¥—É–º–∞–µ—Ç–µ, –∫–∞–∫ —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ?)\n"
    "6. Hech kim kutmagan voqea sodir bo'ldi... (–°–ª—É—á–∏–ª–æ—Å—å —Ç–æ, —á–µ–≥–æ –Ω–∏–∫—Ç–æ –Ω–µ –æ–∂–∏–¥–∞–ª...)\n"
    "7. Buni ko'rib hayratda qolasiz! (–í—ã –±—É–¥–µ—Ç–µ –≤ —à–æ–∫–µ, —É–≤–∏–¥–µ–≤ —ç—Ç–æ!)\n"
    "8. Dunyodagi eng g'alati narsalardan biri... (–û–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö —Å—Ç—Ä–∞–Ω–Ω—ã—Ö –≤–µ—â–µ–π –≤ –º–∏—Ä–µ...)\n"
    "9. Siz buni o'z ko'zingiz bilan ko'rishingiz kerak! (–í—ã –¥–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å —ç—Ç–æ —Å–≤–æ–∏–º–∏ –≥–ª–∞–∑–∞–º–∏!)\n"
    "\n"
    "–ê–¥–∞–ø—Ç–∏—Ä—É–π –∫—Ä—é—á–æ–∫ –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —É–¥–µ—Ä–∂–∞–Ω–∏—è –≤ –ø–µ—Ä–≤—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã. "
    "–°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª –æ—Ä–∏–≥–∏–Ω–∞–ª–∞, –Ω–æ –∞–¥–∞–ø—Ç–∏—Ä—É–π —Å—Ç–∏–ª—å –ø–æ–¥ —É–∑–±–µ–∫—Å–∫—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é ‚Äî –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∂–∏–≤–æ, —Å —ç–º–æ—Ü–∏–µ–π. "
    "–í–ê–ñ–ù–û: –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—É—Ç–∞–π –∂–∏–≤–æ—Ç–Ω—ã—Ö —Å —Ä–∞—Å—Ç–µ–Ω–∏—è–º–∏. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ üêô –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∂–∏–≤–æ—Ç–Ω—ã—Ö ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –∂–∏–≤–æ—Ç–Ω—ã—Ö (Sakkizoyoq, hayvonlar), –∞ –Ω–µ –¥–ª—è —Ä–∞—Å—Ç–µ–Ω–∏–π (o'simliklar). "
    "Sen master aforizmlar va hikmatli so'zlar ijodkorisan. "
    "So'zma-so'z tarjimadan qoch, ma'no ustuvor. Masalan, '–¢–∏—Ö–∞—è —Å–∏–ª–∞' ‚Äî bu 'Vazmin quvvat' yoki 'Sokin qudrat', lekin 'Jim kuch' emas. "
    "Matnni qisqa, ravon, ta'sirli uslubda yoz, ortiqcha so'zlarsiz. "
    "Kerak bo'lsa satr tashlash mumkin, savol-javob ohangi ham mos. "
    "–•–≠–®–¢–ï–ì–ò: –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–º—ã—Å–ª–∞ –≤–∏–¥–µ–æ –≤—ã–±–µ—Ä–∏ —Ç–æ–ª—å–∫–æ –û–î–ò–ù —Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ö—ç—à—Ç–µ–≥ –Ω–∞ —É–∑–±–µ–∫—Å–∫–æ–º —è–∑—ã–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: #texnologiya, #tarix, #tabiat, #fan, #sport, #san'at). –î–æ–±–∞–≤—å –µ–≥–æ –≤ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞. "
    "Agar satr `>` bilan boshlangan bo'lsa, shu belgini saqla. "
    "Emojilar: 0‚Äì2 ta, faqat juda mos bo'lsa. "
    "Hech qanday izoh bermagin ‚Äî faqat yakuniy matnni qaytar. "
    "1-2 eng kuchli so'zni *yulduzcha* bilan belgilab (masalan, *SOKIN QUDRAT*) keyinchalik ajratish mumkin bo'lsin."
)


def _translate_sync(text: str) -> str:
    assert openai_client is not None
    resp = openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT_UZ},
            {"role": "user", "content": text},
        ],
    )
    out = (resp.choices[0].message.content or "").strip()
    return out or text


async def translate_and_adapt(text: str, logger) -> str:
    text = (text or "").strip()
    if not text:
        return text

    if not openai_client:
        return text

    try:
        # OpenAI SDK –≤—ã–∑–æ–≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π ‚Äî —É–≤–æ–¥–∏–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop PTB.
        return await asyncio.to_thread(_translate_sync, text)
    except Exception as e:
        logger.warning("Translate failed, sending original text. Error=%s", e)
        return text


def sanitize_post(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –º—É—Å–æ—Ä–∞, –ù–ï —Ç—Ä–æ–≥–∞—è emoji –∏ Unicode"""
    if not text:
        return text

    # –£–±–∏—Ä–∞–µ–º –º—É—Å–æ—Ä–Ω—ã–µ —Ç–µ–≥–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
    import re
    # –£–±–∏—Ä–∞–µ–º HTML-—Ç–µ–≥–∏ (–∫—Ä–æ–º–µ –Ω—É–∂–Ω—ã—Ö)
    text = re.sub(r'<[^>]+>', '', text)
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ >>> (–±–æ–ª–µ–µ 3 –ø–æ–¥—Ä—è–¥)
    text = re.sub(r'>{3,}', '>>>', text)
    # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã (–Ω–æ –Ω–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
    text = re.sub(r' +', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
    lines = [line.rstrip() for line in text.split("\n")]

    cleaned = []
    empty = 0
    for line in lines:
        if line.strip() == "":
            empty += 1
            if empty <= 2:
                cleaned.append("")
        else:
            empty = 0
            cleaned.append(line)

    result = "\n".join(cleaned).strip()
    return result or text


def append_branding(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫—É –±—Ä–µ–Ω–¥–∞ –≤ –∫–æ–Ω–µ—Ü caption –ø–æ—Å–ª–µ —Ö—ç—à—Ç–µ–≥–æ–≤."""
    if not text:
        return BRANDED_LINK
    if BRANDED_LINK in text:
        return text
    return f"{text}\n{BRANDED_LINK}"


def append_hashtags(text: str) -> str:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ö—ç—à—Ç–µ–≥–∏ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ –ø–æ—Å—Ç–∞."""
    if not text:
        return HASHTAGS_BLOCK
    if HASHTAGS_BLOCK in text:
        return text
    return f"{text.rstrip()}\n{HASHTAGS_BLOCK}"


def clean_caption(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ö—ç—à—Ç–µ–≥–∏, —Å—Å—ã–ª–∫–∏ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –∫–∞–Ω–∞–ª–æ–≤."""
    if not text:
        return ""
    import re
    cleaned = re.sub(r'https?://\S+|www\.\S+|t\.me/\S+|@\w+', '', text, flags=re.IGNORECASE)
    cleaned = re.sub(r'#\S+', '', cleaned)
    cleaned = re.sub(r'—Ü–µ—Ä–µ–±—Ä–∞', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Haqiqat\s*üß†', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Batafsil[:\s]*', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r"Kanalga obuna bo'ling", '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'–ü–æ–¥–ø–∏—Å(?:–∞—Ç—å—Å—è|–∞—Ç—å—Å—è –Ω–∞|–∫–∞|–∫–∏|—ã|—ã–≤–∞–π—Ç–µ—Å—å|–∞—Ç—å—Å—è!?)', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'üëâ', '', cleaned)
    cleaned = re.sub(r'\|\|', '', cleaned)
    cleaned = re.sub(r'\|', '', cleaned)
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
    # –£–¥–∞–ª—è–µ–º –ª—é–±—ã–µ HTML-—Ç–µ–≥–∏ —Ü–µ–ª–∏–∫–æ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫ <a>
    cleaned = re.sub(r'<[^>]+>', '', cleaned)
    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    lines = [ln.strip() for ln in cleaned.splitlines() if ln.strip()]
    return "\n".join(lines).strip()


def finalize_caption_tg(text: str) -> str:
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π HTML-–±–ª–æ–∫ —Å—Å—ã–ª–∫–∏ –ø–µ—Ä–µ–¥ —Ö—ç—à—Ç–µ–≥–∞–º–∏."""
    cleaned = clean_caption(text)
    # –ü–æ–≤—Ç–æ—Ä–Ω–æ —É–±–∏—Ä–∞–µ–º t.me –∏ –ø—Ä–æ—á–∏–µ —Å—Å—ã–ª–∫–∏, –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
    cleaned = re.sub(r'https?://\S+|www\.\S+|t\.me/\S+|@\w+', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Batafsil[:\s]*', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'üëâ', '', cleaned)
    cleaned = re.sub(r'\|\|', '', cleaned)
    cleaned = re.sub(r'\|', '', cleaned)
    cleaned = re.sub(r'–ü–æ–¥–ø–∏—Å(?:–∞—Ç—å—Å—è|–∞—Ç—å—Å—è –Ω–∞|–∫–∞|–∫–∏|—ã|—ã–≤–∞–π—Ç–µ—Å—å|–∞—Ç—å—Å—è!?)', '', cleaned, flags=re.IGNORECASE)

    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –±–ª–æ–∫ —Å—Å—ã–ª–∫–∏ –ø–µ—Ä–µ–¥ —Ö—ç—à—Ç–µ–≥–∞–º–∏
    link_block = LINK_BLOCK_HTML
    cleaned = cleaned.rstrip()
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∫–æ–Ω—Ü–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–Ω–∞—á–∫–∏)
    cleaned = re.sub(r"[^\w\s\[\]\(\)\\\/.,!?-]+$", "", cleaned)
    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ —Å—Å—ã–ª–∫–æ–π –∏ —Ö—ç—à—Ç–µ–≥–∞–º–∏
    cleaned = f"{cleaned}\n\n{link_block}\n\n{HASHTAGS_BLOCK}"
    return cleaned.strip()


def finalize_caption_meta(text: str) -> str:
    """–°—Ç–µ—Ä–∏–ª—å–Ω—ã–π caption –±–µ–∑ —Å—Å—ã–ª–æ–∫/telegram –±–ª–æ–∫–∞ –¥–ª—è Meta: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç + —Ö—ç—à—Ç–µ–≥–∏."""
    cleaned = clean_caption(text)
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
    cleaned = re.sub(r'https?://\S+|www\.\S+|t\.me/\S+|@\w+', '', cleaned, flags=re.IGNORECASE)
    # –£–¥–∞–ª—è–µ–º telegram-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    cleaned = re.sub(r'Haqiqat\s*üß†', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Kanalga obuna bo[\'`]?ling', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'Batafsil[:\s]*', '', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r'üëâ', '', cleaned)
    cleaned = re.sub(r'\|\|', '', cleaned)
    cleaned = re.sub(r'\|', '', cleaned)
    cleaned = re.sub(r'–ü–æ–¥–ø–∏—Å(?:–∞—Ç—å—Å—è|–∞—Ç—å—Å—è –Ω–∞|–∫–∞|–∫–∏|—ã|—ã–≤–∞–π—Ç–µ—Å—å|–∞—Ç—å—Å—è!?)', '', cleaned, flags=re.IGNORECASE)
    cleaned = cleaned.rstrip()
    cleaned = re.sub(r"[^\w\s\[\]\(\)\\\/.,!?-]+$", "", cleaned)
    # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç + —Ö—ç—à—Ç–µ–≥–∏, –±–µ–∑ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –±–ª–æ–∫–∞
    cleaned = f"{cleaned}\n\n{HASHTAGS_BLOCK}"
    return cleaned.strip()


def prepare_caption_for_publish_tg(raw: str) -> str:
    """Caption –¥–ª—è TG: –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç + —Å—Å—ã–ª–∫–∞ + —Ö—ç—à—Ç–µ–≥–∏ (HTML)."""
    text = ensure_utf8_text(raw or "")
    text = remove_comment_phrases(text)
    text = clean_caption(text)
    text = ensure_footer(text)
    text = append_branding(text)
    text = append_hashtags(text)
    text = finalize_caption_tg(text)
    return text


def prepare_caption_for_publish_meta(raw: str) -> str:
    """Caption –¥–ª—è IG/FB: –±–µ–∑ —Å—Å—ã–ª–æ–∫/telegram –±–ª–æ–∫–∞, —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç + —Ö—ç—à—Ç–µ–≥–∏."""
    text = ensure_utf8_text(raw or "")
    text = remove_comment_phrases(text)
    text = clean_caption(text)
    text = ensure_footer(text)
    text = append_branding(text)
    text = append_hashtags(text)
    text = finalize_caption_meta(text)
    return text




def remove_quote_markers(text: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å > –≤ —Ñ–æ—Ä–º–∞—Ç —Å —ç–º–æ–¥–∑–∏ üó®"""
    if not text:
        return text
    
    lines = text.split("\n")
    result = []
    
    for line in lines:
        if line.strip().startswith(">"):
            # –£–±–∏—Ä–∞–µ–º > –∏ –¥–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏
            quote_text = line.strip()[1:].strip()
            if quote_text:
                result.append(f"üó® {quote_text}")
        else:
            result.append(line)
    
    return "\n".join(result)


def remove_duplicate_footers(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Ñ—É—Ç–µ—Ä—ã –∏ —Ä—É–±—Ä–∏–∫–∏"""
    if not text:
        return text
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    patterns_to_remove = [
        "Qiziqarli faktlar",
        "Qiziqarli fakt",
        "Faktlar",
        "Fakt",
    ]
    
    lines = text.split("\n")
    cleaned = []
    
    for line in lines:
        line_lower = line.strip().lower()
        should_remove = False
        
        for pattern in patterns_to_remove:
            if pattern.lower() in line_lower:
                should_remove = True
                break
        
        if not should_remove:
            cleaned.append(line)
    
    return "\n".join(cleaned)


def format_post_structure(text: str) -> str:
    """–í—ã—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–µ—Ä–∞—Ä—Ö–∏—é —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return text
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Ñ—É—Ç–µ—Ä—ã
    text = remove_duplicate_footers(text)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–∏—Ç–∞—Ç—ã
    text = remove_quote_markers(text)
    
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    
    if not lines:
        return text
    
    # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ö—É–∫
    hook = lines[0] if lines else ""
    
    # –û—Å—Ç–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç
    rest = lines[1:] if len(lines) > 1 else []
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    result = [hook]
    
    if rest:
        result.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        result.extend(rest)
    
    return "\n".join(result)


def entities_to_markers(text, entities):
    if not entities:
        return text

    offset_shift = 0
    text = text

    for e in entities:
        if e.type == MessageEntityType.BLOCKQUOTE:
            start = e.offset + offset_shift
            end = start + e.length
            block = text[start:end]
            marked = "\n".join("> " + l for l in block.split("\n"))
            text = text[:start] + marked + text[end:]
            offset_shift += len(marked) - e.length

    return text


def markers_to_entities(text):
    lines = text.split("\n")
    cleaned = []
    for l in lines:
        if l.startswith("> "):
            cleaned.append(l[2:])
        else:
            cleaned.append(l)
    return "\n".join(cleaned)


def ensure_footer(text: str) -> str:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ñ—É—Ç–µ—Ä–∞ –≤ —Ç–µ–∫—Å—Ç–µ (—Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è text, –∏ –¥–ª—è caption)"""
    if not text:
        return FOOTER_HTML.strip()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ—É—Ç–µ—Ä–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    if "Haqiqat" not in text or "Kanalga obuna" not in text:
        return text + FOOTER_HTML
    return text


def trim_caption_with_footer(text: str, max_len: int = CAPTION_MAX_LENGTH) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç caption –¥–æ max_len, –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—è —á—Ç–æ —Ñ—É—Ç–µ—Ä –Ω–µ –æ–±—Ä–µ–∑–∞–µ—Ç—Å—è"""
    if len(text) <= max_len:
        return ensure_footer(text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ—É—Ç–µ—Ä
    has_footer = "Haqiqat" in text and "Kanalga obuna" in text
    
    if has_footer:
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ —Ñ—É—Ç–µ—Ä–∞
        footer_start = text.find("‚Äî ‚Äî ‚Äî")
        if footer_start == -1:
            footer_start = text.find("üß† Haqiqat")
        
        if footer_start > 0:
            main_text = text[:footer_start].strip()
            footer = text[footer_start:].strip()
            footer_len = len(footer)
            
            # –û–±—Ä–µ–∑–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç, –æ—Å—Ç–∞–≤–ª—è—è –º–µ—Å—Ç–æ –¥–ª—è —Ñ—É—Ç–µ—Ä–∞
            if len(main_text) + footer_len > max_len:
                available_len = max_len - footer_len - 10  # –ó–∞–ø–∞—Å
                if available_len > 0:
                    main_text = main_text[:available_len].rstrip() + "..."
                else:
                    # –ï—Å–ª–∏ —Ñ—É—Ç–µ—Ä —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ—É—Ç–µ—Ä
                    return footer[:max_len]
            
            return main_text + "\n\n" + footer
    
    # –ï—Å–ª–∏ —Ñ—É—Ç–µ—Ä–∞ –Ω–µ—Ç, –æ–±—Ä–µ–∑–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º
    trimmed = text[:max_len - len(FOOTER_HTML) - 10].rstrip() + "..."
    return ensure_footer(trimmed)


async def delete_from_buffer(application, item: dict) -> None:
    """–£–¥–∞–ª—è–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –±—É—Ñ–µ—Ä–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
    if not DELETE_FROM_BUFFER:
        return
    
    buffer_message_id = item.get("buffer_message_id")
    buffer_chat_id = item.get("buffer_chat_id", BUFFER_CHANNEL_ID)
    
    if not buffer_message_id:
        log.warning("delete_from_buffer: buffer_message_id not found in item")
        return
    
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º buffer_message_id –≤ seen_posts.json
        if SEEN_FILE.exists():
            try:
                data = json.loads(SEEN_FILE.read_text(encoding="utf-8"))
                if isinstance(data, dict):
                    if "buffer_message_ids" not in data:
                        data["buffer_message_ids"] = []
                    if buffer_message_id not in data["buffer_message_ids"]:
                        data["buffer_message_ids"].append(buffer_message_id)
                else:
                    # –°—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                    data = {
                        "hashes": data if isinstance(data, list) else [],
                        "buffer_message_ids": [buffer_message_id]
                    }
                SEEN_FILE.write_text(json.dumps(data), encoding="utf-8")
            except Exception as e:
                log.warning(f"Failed to save buffer_message_id to seen_posts.json: {e}")
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –±—É—Ñ–µ—Ä–∞
        await application.bot.delete_message(
            chat_id=buffer_chat_id,
            message_id=buffer_message_id
        )
        log.info(f"delete_from_buffer_ok: message_id={buffer_message_id}, chat_id={buffer_chat_id}")
        
    except Exception as e:
        # –ù–µ –ø–∞–¥–∞–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ —É–¥–∞–ª–µ–Ω–∏—è, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
        error_msg = str(e)
        error_code = getattr(e, 'error_code', None)
        log.warning(f"delete_from_buffer_fail: message_id={buffer_message_id}, chat_id={buffer_chat_id}, error={error_msg}, code={error_code}")


# FIX B: Worker –¥–ª—è –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
async def video_processing_worker():
    """
    –§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ.
    –ë–µ—Ä–µ—Ç —Ä–∞–±–æ—Ç—ã –∏–∑ VIDEO_PROCESSING_QUEUE –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö.
    –ù–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ Telegram/scheduler.
    """
    log.info("[WORKER] Video processing worker started")
    while True:
        try:
            job = await VIDEO_PROCESSING_QUEUE.get()
            try:
                log.info(f"[QUEUE] video dequeued: type={job.get('type', 'unknown')}")
                # job —Å–æ–¥–µ—Ä–∂–∏—Ç information –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
                # –¢—è–∂–µ–ª–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (rendering, ffmpeg) –∏–¥–µ—Ç –∑–¥–µ—Å—å
                await asyncio.sleep(0.1)  # Placeholder –¥–ª—è —Ä–∞–±–æ—Ç—ã
                log.info(f"[QUEUE] video processed: type={job.get('type', 'unknown')}")
            except Exception as e:
                log.error(f"[WORKER] job failed: {e}")
            finally:
                VIDEO_PROCESSING_QUEUE.task_done()
        except Exception as e:
            log.error(f"[WORKER] unexpected error: {e}")
            await asyncio.sleep(1)


async def post_worker(application):
    global IS_POSTING, FORCE_CAROUSEL_TEST, FIRST_RUN_IMMEDIATE, LAST_PHOTO_TIME, LAST_VIDEO_TIME, LAST_POST_TIME, IS_PAUSED, FORCE_POST_NOW, POSTNOW_EVENT

    if IS_POSTING:
        return

    IS_POSTING = True

    while True:
        try:
            # === IG SCHEDULE: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π (9 –ø–æ—Å—Ç–æ–≤/–¥–µ–Ω—å) ===
            now = datetime.now()
            reset_ig_schedule_if_needed()
            
            ready = False
            postnow_mode = FORCE_POST_NOW  # Local flag to track POSTNOW mode throughout this cycle
            
            # === POSTNOW BYPASS: –û–±—Ö–æ–¥ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è ===
            if postnow_mode:
                log.info("[SCHEDULER] POSTNOW override: immediate publish (bypass schedule windows)")
                ready = True
            else:
                # === NORMAL SCHEDULE MODE: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏ –æ–∫–æ–Ω ===
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –∏ –ª–∏–º–∏—Ç–æ–≤
                hour = now.hour
                
                # –ü–∞—É–∑–∞ 14:00-16:00
                if 14 <= hour < 16:
                    log.info("[SCHEDULER] Outside schedule window: sleeping until 16:00")
                    await sleep_or_postnow(3600)  # Sleep 1 hour
                    continue
                
                # –ü–æ—Å–ª–µ 21:00 - —Å–ø–∏–º –¥–æ —É—Ç—Ä–∞
                if hour > 21:
                    log.info("[SCHEDULER] After 21:00: sleeping until tomorrow 08:00")
                    sleep_hours = (24 - hour) + 8
                    await sleep_or_postnow(sleep_hours * 3600)
                    continue
                
                # –£—Ç—Ä–æ (–¥–æ 14:00): –º–∞–∫—Å–∏–º—É–º 3 –ø–æ—Å—Ç–∞
                if hour < 14:
                    if IG_SCHEDULE["morning_videos"] >= 3:
                        log.info("[SCHEDULER] Morning limit reached (3/3): sleeping until 16:00")
                        await sleep_or_postnow(3600)  # Sleep 1 hour, will check again
                        continue
                    ready = True
                # –í–µ—á–µ—Ä (16:00-21:00): –º–∞–∫—Å–∏–º—É–º 6 –ø–æ—Å—Ç–æ–≤
                elif 16 <= hour <= 21:
                    if IG_SCHEDULE["afternoon_videos"] >= 6:
                        log.info("[SCHEDULER] Evening limit reached (6/6): sleeping until tomorrow 08:00")
                        await sleep_or_postnow(8 * 3600)  # Sleep 8 hours
                        continue
                    ready = True
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (1 —á–∞—Å –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏) ‚Äî —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ–±—ã—á–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
                if ready and LAST_POST_TIME is not None:
                    time_since_last = (now - LAST_POST_TIME).total_seconds()
                    if time_since_last < PUBLISH_INTERVAL_SECONDS:
                        sleep_time = PUBLISH_INTERVAL_SECONDS - time_since_last
                        log.info(f"[SCHEDULER] Cooldown: sleeping {sleep_time:.0f}s until next publish window")
                        await sleep_or_postnow(sleep_time)
                        continue

            # SMART CONTROL: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—É–∑—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π (–ù–ï –æ–±—Ö–æ–¥–∏—Ç—Å—è –ø—Ä–∏ POSTNOW)
            if IS_PAUSED and not postnow_mode:
                log.info("[PAUSE] Conveyor paused. Sleeping for 10 seconds...")
                await sleep_or_postnow(10)
                continue
            
            # STATUS LOG: –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
            ready_count = len(list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4")))
            last_post_str = LAST_POST_TIME.strftime('%Y-%m-%d %H:%M:%S') if LAST_POST_TIME else "Never"
            log.info(f"STATUS | Queue: {len(POST_QUEUE)} | Ready: {ready_count}/10 | Last post: {last_post_str}")

            if POST_QUEUE:
                # –ü–µ—Ä–≤–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ: –ø—É–±–ª–∏–∫—É–µ–º —Å—Ä–∞–∑—É –û–î–ò–ù –†–ê–ó
                if FIRST_RUN_IMMEDIATE:
                    # üéØ PERSISTENT FIRST STRIKE: –ü—Ä–æ–±—É–µ–º —Ñ–∞–π–ª—ã –æ–¥–∏–Ω –∑–∞ –¥—Ä—É–≥–∏–º –¥–æ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—Ö–∞
                    first_strike_success = False
                    first_strike_attempts = 0
                    max_first_strike_attempts = 50  # –ú–∞–∫—Å–∏–º—É–º 50 –ø–æ–ø—ã—Ç–æ–∫
                    
                    log.warning("[FIRST STRIKE] Starting persistent post attempt. Will try files until one succeeds...")
                    
                    while not first_strike_success and POST_QUEUE and first_strike_attempts < max_first_strike_attempts:
                        first_strike_attempts += 1
                        item = POST_QUEUE.popleft()
                        save_queue()
                        item["first_strike"] = True
                        log.warning(f"[FIRST STRIKE] Attempt #{first_strike_attempts}: Trying post from queue. Remaining: {len(POST_QUEUE)}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –ø–æ—Å—Ç–∞ - First Strike —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –≤–∏–¥–µ–æ
                        if item["type"] != "video":
                            log.warning(f"[FIRST STRIKE] Skipping non-video post (type={item['type']})")
                            continue
                        
                        # –ü—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ
                        post_attempt_failed = False
                        
                        # === –ù–ê–ß–ê–õ–û –ë–õ–û–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò FIRST STRIKE –í–ò–î–ï–û ===
                        # FIX: If item comes from ready folder, initialize captions empty
                        if item.get("from_ready_folder", False):
                            caption = ""
                            caption_tg = ""
                            caption_meta = ""
                        else:
                            caption = item.get("caption", "")
                            caption_tg = prepare_caption_for_publish_tg(caption)
                            caption_meta = prepare_caption_for_publish_meta(caption)

                            if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                                caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                        
                        tmp_dir = Path("tmp_media")
                        tmp_dir.mkdir(exist_ok=True)
                        video_file_id = item["file_id"]
                        public_url = None
                        local_path = None
                        processed_path = None
                        upload_path = None
                        
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–ª–∏ —Å—ã—Ä–æ–π?
                            if item.get("from_ready_folder", False):
                                # ‚úÖ –≠—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª - –±–µ—Ä—ë–º –Ω–∞–ø—Ä—è–º—É—é —Å –¥–∏—Å–∫–∞
                                ready_video_path = Path(item["ready_file_path"])
                                
                                # üîç DIAGNOSTICS: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                                file_exists = ready_video_path.exists()
                                file_absolute = ready_video_path.resolve()
                                log.info(f"[FIRST STRIKE] Ready file check: name={ready_video_path.name}, exists={file_exists}")
                                log.info(f"[FIRST STRIKE] Ready file absolute path: {file_absolute}")
                                
                                if not file_exists:
                                    # –í—ã–≤–æ–¥–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                                    ready_dir = READY_TO_PUBLISH_DIR.resolve()
                                    dir_contents = list(READY_TO_PUBLISH_DIR.glob("*"))[:20]
                                    log.error(f"[FIRST STRIKE] Ready file not found: {file_absolute}")
                                    log.error(f"[FIRST STRIKE] Ready directory: {ready_dir}")
                                    log.error(f"[FIRST STRIKE] Directory contents (first 20): {[f.name for f in dir_contents]}")
                                    log.error(f"[FIRST STRIKE] Drop missing ready file and continue: {ready_video_path}")
                                    continue
                                
                                upload_path = ready_video_path
                                
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º .json –∏ .mp4.json)
                                ready_meta_a = ready_video_path.with_suffix('.json')
                                ready_meta_b = ready_video_path.with_suffix('.mp4.json')
                                ready_meta_path = ready_meta_a if ready_meta_a.exists() else (ready_meta_b if ready_meta_b.exists() else None)
                                caption = ""
                                caption_tg = ""
                                caption_meta = ""

                                if ready_meta_path and ready_meta_path.exists():
                                    try:
                                        meta = json.loads(ready_meta_path.read_text(encoding='utf-8'))
                                        caption = meta.get('caption', '') or ""
                                        caption_tg = meta.get('caption_tg', '') or ""
                                        caption_meta = meta.get('caption_meta', '') or ""
                                        if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                                            caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                                        log.info(f"[FIRST STRIKE] Loaded ready meta: {ready_meta_path.name}")
                                    except Exception as e:
                                        log.error(f"[FIRST STRIKE] Failed to read meta json: {ready_meta_path.name} -> {e}")
                                else:
                                    log.error(f"[FIRST STRIKE] Meta json missing for ready file: {ready_video_path.name} -> using empty caption")
                                
                                log.info(f"[FIRST STRIKE] Using ready file: {ready_video_path.name}")
                                
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Supabase (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ)
                                if not item.get("supabase_url"):
                                    content_type = "video/mp4"
                                    public_url = upload_to_supabase(str(upload_path), content_type)
                                    if public_url:
                                        log.info(f"[FIRST STRIKE] Supabase URL OK: {public_url}")
                                        item["supabase_url"] = public_url
                                    else:
                                        raise RuntimeError("[FIRST STRIKE] Supabase upload failed")
                                else:
                                    public_url = item["supabase_url"]
                                    log.info(f"[FIRST STRIKE] Using existing Supabase URL: {public_url}")
                            else:
                                # ‚ö†Ô∏è –≠—Ç–æ —Å—ã—Ä–æ–π —Ñ–∞–π–ª - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
                                
                                # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ Instagram –¥–ª—è First Strike
                                if video_file_id == "instagram_source" and item.get("instagram_video_path"):
                                    instagram_path = Path(item["instagram_video_path"])
                                    if not instagram_path.exists():
                                        log.error(f"[FIRST STRIKE] –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –ø—É—Ç–∏: {instagram_path}")
                                        continue
                                    local_path = instagram_path
                                    log.info(f"[FIRST STRIKE] –ò—Å–ø–æ–ª—å–∑—É—é –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª Instagram: {local_path.name}")
                                else:
                                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å: —Å–∫–∞—á–∏–≤–∞–µ–º –∏–∑ Telegram
                                    file_obj = await application.bot.get_file(video_file_id)
                                    remote_path = getattr(file_obj, "file_path", "") or ""
                                    suffix = Path(remote_path).suffix or ".mp4"
                                    local_path = tmp_dir / f"{video_file_id}{suffix}"
                                    
                                    # –°–∫–∞—á–∏–≤–∞–µ–º —Å—ã—Ä–æ–µ –≤–∏–¥–µ–æ –∏–∑ TG
                                    await file_obj.download_to_drive(custom_path=str(local_path))
                                    log.info(f"[FIRST STRIKE] –í–∏–¥–µ–æ —Å–∫–∞—á–∞–Ω–æ –∏–∑ Telegram: {local_path.name}")
                                
                                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
                                processed_path = process_video(local_path, caption)
                                if not processed_path or not Path(processed_path).exists():
                                    raise RuntimeError("[FIRST STRIKE] Video processing failed")
                                upload_path = processed_path

                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Supabase
                                content_type = mimetypes.guess_type(str(upload_path))[0] or "video/mp4"
                                public_url = upload_to_supabase(str(upload_path), content_type)
                                if public_url:
                                    log.info(f"[FIRST STRIKE] Supabase URL OK: {public_url}")
                                    item["supabase_url"] = public_url
                                else:
                                    raise RuntimeError("[FIRST STRIKE] Supabase upload failed")
                                
                        except Exception as e:
                            error_msg = str(e)
                            log.error(f"[FIRST STRIKE] Processing error: {e}")
                            
                            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                            for p in [local_path, processed_path]:
                                if p and Path(p).exists():
                                    await safe_unlink(p)
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ Invalid file_id –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
                            if "Invalid file_id" in error_msg or "file_id" in error_msg.lower() or "Supabase" in error_msg:
                                log.critical(f"üö® CRITICAL | [FIRST STRIKE] Broken file detected: {error_msg[:100]}")
                                log.critical("üö® CRITICAL | [FIRST STRIKE] Skipping to next file immediately...")
                                post_attempt_failed = True
                                continue  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ñ–∞–π–ª—É
                            
                            # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ —Ç–æ–∂–µ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π
                            post_attempt_failed = True
                            continue
                        
                        # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - —Ñ–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ, –ø—Ä–æ–±—É–µ–º –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å
                        if not post_attempt_failed and item.get("supabase_url"):
                            try:
                                # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
                                with open(upload_path, "rb") as f:
                                    await application.bot.send_video(
                                        chat_id=MAIN_CHANNEL_ID,
                                        video=f,
                                        caption=caption_tg if caption_tg else None,
                                        parse_mode="HTML",
                                        supports_streaming=True,
                                        width=1080,
                                        height=1920,
                                    )
                                    log.info("[FIRST STRIKE] Telegram format: VIDEO_STREAMING_ON")
                                
                                # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Facebook
                                try:
                                    item_fb = dict(item)
                                    item_fb["caption"] = caption_meta
                                    await publish_to_facebook(item_fb)
                                    append_history("FB", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                                except Exception as e:
                                    log.error(f"[FIRST STRIKE] Facebook publish error: {e}")
                                
                                # === DIAGNOSTIC: IG Schedule Check (First Strike) ===
                                now_fs_check = datetime.now()
                                log.info(f"[DIAGNOSTICS PRE-DECISION] [FIRST STRIKE]")
                                log.info(f"  FORCE_POST_NOW={FORCE_POST_NOW}")
                                log.info(f"  Current time={now_fs_check.strftime('%Y-%m-%d %H:%M:%S')} (hour={now_fs_check.hour})")
                                log.info(f"  IG_SCHEDULE: morning={IG_SCHEDULE['morning_videos']}/3, evening={IG_SCHEDULE['afternoon_videos']}/6")
                                
                                # Instagram –ø—É–±–ª–∏–∫–∞—Ü–∏—è (–±–µ–∑ Plan B –¥–ª—è First Strike - –ø—Ä–æ—Å—Ç–æ –æ–¥–Ω–∞ –ø–æ–ø—ã—Ç–∫–∞)
                                if can_ig_publish("video", force=FORCE_POST_NOW):
                                    try:
                                        item_ig = dict(item)
                                        item_ig["caption"] = caption_meta
                                        ig_result = await publish_to_instagram(item_ig)
                                        if ig_result:
                                            log.info("[FIRST STRIKE] Instagram published successfully")
                                            append_history("IG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                                    except Exception as e:
                                        log.error(f"[FIRST STRIKE] Instagram publish error: {e}")
                                
                                # Cleanup –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                                if item.get("from_ready_folder", False):
                                    # –î–ª—è –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                                    if upload_path and Path(upload_path).exists():
                                        await safe_unlink(upload_path)
                                        log.info(f"[FIRST STRIKE] Deleted ready file: {Path(upload_path).name}")
                                    # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (READY_META_EXT_FIX: try both formats)
                                    if upload_path:
                                        meta_path_a = Path(upload_path).with_suffix('.json')
                                        meta_path_b = Path(upload_path).with_suffix('.mp4.json')
                                        meta_path = meta_path_a if meta_path_a.exists() else (meta_path_b if meta_path_b.exists() else None)
                                        if meta_path and meta_path.exists():
                                            await safe_unlink(meta_path)
                                            log.info(f"[FIRST STRIKE] Deleted metadata: {meta_path.name}")
                                else:
                                    # –î–ª—è —Å—ã—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                                    for p in [local_path, processed_path]:
                                        if p and Path(p).exists():
                                            await safe_unlink(p)
                                
                                # –£–¥–∞–ª—è–µ–º –∏–∑ –±—É—Ñ–µ—Ä–∞
                                await delete_from_buffer(application, item)
                                await send_progress_report(application)
                                
                                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                                increment_stat("video")
                                append_history("TG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                                if caption:
                                    PUBLISHED_TEXTS.append(caption)
                                    if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                                        PUBLISHED_TEXTS.pop(0)
                                    save_published_texts()
                                
                                # üéØ –£–°–ü–ï–•! –ü–æ–º–µ—á–∞–µ–º —Ñ–ª–∞–≥ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è
                                first_strike_success = True
                                now_publish = datetime.now()
                                LAST_POST_TIME = now_publish
                                save_last_post_time()
                                
                                # NOTE: IG_SCHEDULE counters incremented at the end of post_worker (no double increment)
                                log.info(f"‚úÖ [FIRST STRIKE] SUCCESS after {first_strike_attempts} attempt(s)! Published one post. Cooldown active.")
                                
                            except Exception as e:
                                log.error(f"[FIRST STRIKE] Publication error: {e}")
                                # Cleanup (—Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã, –≥–æ—Ç–æ–≤—ã–µ –ù–ï —É–¥–∞–ª—è–µ–º)
                                if not item.get("from_ready_folder", False):
                                    for p in [local_path, processed_path]:
                                        if p and Path(p).exists():
                                            await safe_unlink(p)
                                continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Ñ–∞–π–ª
                        # === –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò FIRST STRIKE –í–ò–î–ï–û ===
                    
                    # –ü–æ—Å–ª–µ —Ü–∏–∫–ª–∞ First Strike
                    if first_strike_success:
                        log.info("[FIRST STRIKE] Completed! Next post in 60 minutes.")
                    else:
                        log.error(f"[FIRST STRIKE] FAILED after {first_strike_attempts} attempts. No successful post.")
                    
                    # –°–ë–†–ê–°–´–í–ê–ï–ú –§–õ–ê–ì (—Ç–µ–ø–µ—Ä—å First Strike –∑–∞–≤–µ—Ä—à–µ–Ω)
                    FIRST_RUN_IMMEDIATE = False
                    continue  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞—á–∞–ª—É —Ü–∏–∫–ª–∞ worker
                else:
                    now = datetime.now()
                    ready = (LAST_POST_TIME is None) or ((now - LAST_POST_TIME) >= timedelta(seconds=PUBLISH_INTERVAL_SECONDS))
                    if not ready:
                        if POST_QUEUE and POST_QUEUE[0].get("type") == "photo" and LAST_POST_TIME:
                            next_time = LAST_POST_TIME + timedelta(seconds=PUBLISH_INTERVAL_SECONDS)
                            log.info(f"INFO | [NEXT] Type: Photo. Scheduled at: {next_time.strftime('%Y-%m-%d %H:%M:%S')}")
                        # === POSTNOW Wake-up: —Å–ø–∏–º, –Ω–æ –ø—Ä–æ—Å—ã–ø–∞–µ–º—Å—è –ø–æ —Å–æ–±—ã—Ç–∏—é ===
                        POSTNOW_EVENT.clear()
                        try:
                            await asyncio.wait_for(POSTNOW_EVENT.wait(), timeout=60)
                            log.info("[POSTNOW] Woken up by POSTNOW_EVENT!")
                        except asyncio.TimeoutError:
                            pass  # –û–±—ã—á–Ω—ã–π timeout, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
                        continue
                    
                    # üéõÔ∏è MIXED QUEUE 4+4: –í—ã–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç –ø–æ –ª–æ–≥–∏–∫–µ —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è
                    # FIX A: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–±–æ—Ä ready-—Ñ–∞–π–ª–æ–≤
                    max_attempts = 10
                    attempts = 0
                    item = None
                    while attempts < max_attempts:
                        item = get_next_post_from_queue()
                        if not item:
                            log.warning("[MIXED QUEUE] No posts available in queue")
                            break
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑ ready_to_publish
                        if item.get("from_ready_folder", False):
                            ready_path = Path(item.get("ready_file_path", ""))
                            if ready_path and not ready_path.exists():
                                log.error(f"[SCHEDULER] missing file, drop from queue: {ready_path.name}")
                                log.info(f"[SCHEDULER] pick_ready: name={ready_path.name}, exists=False")
                                item = None
                                attempts += 1
                                continue  # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Ñ–∞–π–ª
                            else:
                                log.info(f"[SCHEDULER] pick_ready: name={ready_path.name}, exists=True")
                                break  # –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                        else:
                            # –≠—Ç–æ –Ω–µ ready-—Ñ–∞–π–ª, –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
                            break
                    
                    if not item:
                        if attempts >= max_attempts:
                            log.warning("[SCHEDULER] attempts_exhausted (10), skipping post cycle")
                        # === POSTNOW Wake-up: —Å–ø–∏–º, –Ω–æ –ø—Ä–æ—Å—ã–ø–∞–µ–º—Å—è –ø–æ —Å–æ–±—ã—Ç–∏—é ===
                        POSTNOW_EVENT.clear()
                        try:
                            await asyncio.wait_for(POSTNOW_EVENT.wait(), timeout=60)
                            log.info("[POSTNOW] Woken up by POSTNOW_EVENT!")
                        except asyncio.TimeoutError:
                            pass  # –û–±—ã—á–Ω—ã–π timeout, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
                        continue
                    
                    save_queue()
                    log.info("Worker pop type=%s voiceover=%s size_after_pop=%s (scheduled)", 
                            item["type"], item.get("voiceover", False), len(POST_QUEUE))

                try:
                    if item["type"] == "carousel_pending":
                        log.info("Carousel posts temporarily disabled; skipping.")
                        await delete_from_buffer(application, item)
                        await send_progress_report(application)
                        continue
                    if item["type"] == "text":
                        text = prepare_caption_for_publish(item.get("text", ""))
                        msg = await application.bot.send_message(
                            chat_id=MAIN_CHANNEL_ID,
                            text=text,
                            parse_mode="HTML"
                        )
                        increment_stat("text")
                        PUBLISHED_TEXTS.append(text)
                        if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                            PUBLISHED_TEXTS.pop(0)
                        save_published_texts()
                        log.info("published_ok (text)")
                        await delete_from_buffer(application, item)
                        await send_progress_report(application)
                        LAST_POST_TIME = datetime.now()
                        save_last_post_time()
                    elif item["type"] == "photo":
                        upload_path = None
                        caption_tg = prepare_caption_for_publish_tg(item.get("caption", ""))
                        caption_meta = prepare_caption_for_publish_meta(item.get("caption", ""))
                        if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                            caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                            log.info(f"Caption trimmed to {len(caption_tg)} chars (was {len(item.get('caption', ''))})")

                        tmp_dir = Path("tmp_media")
                        tmp_dir.mkdir(exist_ok=True)
                        photo_file_id = item["file_id"]
                        public_url = None
                        local_path = None
                        processed_photo = None
                        log.info(f"[DEBUG] Starting Supabase upload for post (photo) file_id={photo_file_id}")
                        try:
                            file_obj = await application.bot.get_file(photo_file_id)
                            remote_path = getattr(file_obj, "file_path", "") or ""
                            suffix = Path(remote_path).suffix or ".jpg"
                            local_path = tmp_dir / f"{photo_file_id}{suffix}"
                            await file_obj.download_to_drive(custom_path=str(local_path))
                            
                            processed_photo = process_photo(local_path)
                            upload_path = processed_photo if processed_photo and Path(processed_photo).exists() else local_path
                            if upload_path == local_path and not processed_photo:
                                log.warning("Photo watermark skipped (processing failed); sending original photo.")

                            content_type = mimetypes.guess_type(str(upload_path))[0] or "image/jpeg"
                            public_url = upload_to_supabase(str(upload_path), content_type)
                            if public_url:
                                log.info(f"SUPABASE_URL_OK: {public_url}")
                                item["supabase_url"] = public_url
                            else:
                                log.error("SUPABASE_UPLOAD_FAILED")
                        except Exception as e:
                            log.error(f"SUPABASE_UPLOAD_FAILED: {e}")
                            send_admin_error(f"Supabase upload failed (photo): {e}")
                            await sleep_or_postnow(5)
                            continue
                        if not upload_path or not Path(upload_path).exists():
                            log.error("Photo upload_path missing; skipping send.")
                        else:
                            try:
                                with open(upload_path, "rb") as f:
                                    await application.bot.send_photo(
                                        chat_id=MAIN_CHANNEL_ID,
                                        photo=f,
                                        caption=caption_tg if caption_tg else None,
                                        parse_mode="HTML"
                                    )
                            except Exception as e:
                                log.error(f"Telegram send photo failed: {e}")
                            try:
                                item_fb = dict(item)
                                item_fb["caption"] = caption_meta
                                await publish_to_facebook(item_fb)
                                append_history("FB", "Photo", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                            except Exception as e:
                                log.error(f"Facebook publish error (photo): {e}")
                                send_admin_error(f"Facebook publish error (photo): {e}")

                            increment_stat("photo")
                            append_history("TG", "Photo", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                            if caption_tg:
                                PUBLISHED_TEXTS.append(caption_tg)
                                if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                                    PUBLISHED_TEXTS.pop(0)
                                save_published_texts()
                            log.info("published_ok (photo)")
                        
                        # cleanup –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
                        for p in [local_path, processed_photo, upload_path]:
                            if p and Path(p).exists():
                                await safe_unlink(p)

                        await delete_from_buffer(application, item)
                        await send_progress_report(application)
                        LAST_PHOTO_TIME = datetime.now()
                        LAST_POST_TIME = datetime.now()
                        save_last_post_time()
                        
                        # NOTE: IG_SCHEDULE counters incremented at the end of post_worker (no double increment)
                        # IG: —Ç–æ–ª—å–∫–æ –≤–∏–¥–µ–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–æ—Ç–æ
                        maybe_delete_supabase_media(item, reason="telegram")
                    elif item["type"] == "video":
                        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö –ø—É—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                        local_path = None
                        processed_path = None
                        upload_path = None
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑ ready_to_publish –∏–ª–∏ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
                        if item.get("from_ready_folder", False):
                            # –ë–µ—Ä–µ–º –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å
                            log.info("[CONVEYOR] Using pre-loaded ready video from queue")
                            
                            ready_video_path = Path(item["ready_file_path"])
                            
                            # üîç DIAGNOSTICS: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                            file_exists = ready_video_path.exists()
                            file_absolute = ready_video_path.resolve()
                            log.info(f"[CONVEYOR] Ready file check: name={ready_video_path.name}, exists={file_exists}")
                            log.info(f"[CONVEYOR] Ready file absolute path: {file_absolute}")
                            
                            if not file_exists:
                                # –í—ã–≤–æ–¥–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                                ready_dir = READY_TO_PUBLISH_DIR.resolve()
                                dir_contents = list(READY_TO_PUBLISH_DIR.glob("*"))[:20]
                                log.error(f"[CONVEYOR] Ready file not found: {file_absolute}")
                                log.error(f"[CONVEYOR] Ready directory: {ready_dir}")
                                log.error(f"[CONVEYOR] Directory contents (first 20): {[f.name for f in dir_contents]}")
                                continue
                            
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º .json –∏ .mp4.json)
                            ready_meta_a = ready_video_path.with_suffix('.json')
                            ready_meta_b = ready_video_path.with_suffix('.mp4.json')
                            ready_meta_path = ready_meta_a if ready_meta_a.exists() else (ready_meta_b if ready_meta_b.exists() else None)
                            
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                            caption = item.get("caption", "")
                            if ready_meta_path and ready_meta_path.exists():
                                try:
                                    with open(ready_meta_path, 'r', encoding='utf-8') as f:
                                        meta = json.load(f)
                                        caption = meta.get('caption', caption)
                                        log.info(f"[CONVEYOR] Loaded metadata from {ready_meta_path.name}")
                                except Exception as e:
                                    log.warning(f"[CONVEYOR] Failed to load metadata: {e}")
                            
                            caption_tg = prepare_caption_for_publish_tg(caption)
                            caption_meta = prepare_caption_for_publish_meta(caption)
                            
                            if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                                caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                            
                            upload_path = ready_video_path
                            # ‚úÖ FIX: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º local_path –¥–ª—è Plan B Instagram
                            local_path = ready_video_path
                        else:
                            # ‚ö†Ô∏è –≠—Ç–æ —Å—ã—Ä–æ–π —Ñ–∞–π–ª - —Å–∫–∞—á–∏–≤–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                            log.info("[CONVEYOR] Processing raw video file")
                            
                            tmp_dir = Path("tmp_media")
                            tmp_dir.mkdir(exist_ok=True)
                            video_file_id = item["file_id"]
                            
                            caption = item.get("caption", "")
                            caption_tg = prepare_caption_for_publish_tg(caption)
                            caption_meta = prepare_caption_for_publish_meta(caption)
                            
                            if caption_tg and len(caption_tg) > CAPTION_MAX_LENGTH:
                                caption_tg = trim_caption_with_footer(caption_tg, CAPTION_MAX_LENGTH)
                            
                            try:
                                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –∏–∑ Telegram
                                file_obj = await application.bot.get_file(video_file_id)
                                remote_path = getattr(file_obj, "file_path", "") or ""
                                suffix = Path(remote_path).suffix or ".mp4"
                                local_path = tmp_dir / f"{video_file_id}{suffix}"
                                await file_obj.download_to_drive(custom_path=str(local_path))
                                
                                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
                                processed_path = process_video(local_path, caption)
                                if not processed_path or not Path(processed_path).exists():
                                    log.error("[CONVEYOR] Video processing failed")
                                    # Cleanup
                                    if local_path and Path(local_path).exists():
                                        await safe_unlink(local_path)
                                    continue
                                
                                upload_path = processed_path
                                log.info(f"[CONVEYOR] Raw video processed: {Path(upload_path).name}")
                            except Exception as e:
                                log.error(f"[CONVEYOR] Failed to process raw video: {e}")
                                # Cleanup
                                for p in [local_path, processed_path]:
                                    if p and Path(p).exists():
                                        await safe_unlink(p)
                                continue
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–æ—Ç–æ–≤–æ–µ –≤–∏–¥–µ–æ –≤ Supabase (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ)
                        if not item.get("supabase_url"):
                            # –ü–†–û–í–ï–†–ö–ê: –§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
                            if not upload_path or not Path(upload_path).exists():
                                log.critical(f"üö® CRITICAL | File not found for upload: {upload_path}")
                                log.critical("üö® CRITICAL | Skipping broken post due to missing file")
                                # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å (READY_META_EXT_FIX: try both formats)
                                if upload_path:
                                    meta_path_a = Path(str(upload_path)).with_suffix('.json')
                                    meta_path_b = Path(str(upload_path)).with_suffix('.mp4.json')
                                    meta_path = meta_path_a if meta_path_a.exists() else (meta_path_b if meta_path_b.exists() else None)
                                    if meta_path.exists():
                                        await safe_unlink(meta_path)
                                save_queue()
                                await sleep_or_postnow(300)
                                continue
                            
                            public_url = None
                            try:
                                content_type = "video/mp4"
                                public_url = upload_to_supabase(str(upload_path), content_type)
                                if public_url:
                                    log.info(f"[SUPABASE] Upload OK: {public_url}")
                                    item["supabase_url"] = public_url
                                else:
                                    log.error("[SUPABASE] Upload failed")
                                    if item.get("from_ready_folder"):
                                        # –£–¥–∞–ª—è–µ–º –±–∏—Ç—ã–π —Ñ–∞–π–ª (READY_META_EXT_FIX: try both formats)
                                        if upload_path.exists():
                                            await safe_unlink(upload_path)
                                        meta_path_a = upload_path.with_suffix('.json')
                                        meta_path_b = upload_path.with_suffix('.mp4.json')
                                        meta_path = meta_path_a if meta_path_a.exists() else (meta_path_b if meta_path_b.exists() else None)
                                        if meta_path and meta_path.exists():
                                            await safe_unlink(meta_path)
                                    log.critical("üö® CRITICAL | Skipping broken post due to Supabase upload failure")
                                    save_queue()
                                    await sleep_or_postnow(300)
                                    continue
                            except Exception as e:
                                log.error(f"[SUPABASE] Upload error: {e}")
                                log.critical("üö® CRITICAL | Skipping broken post due to Supabase exception")
                                save_queue()
                                await sleep_or_postnow(300)
                                continue
                        
                        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
                        try:
                            with open(upload_path, "rb") as f:
                                await application.bot.send_video(
                                    chat_id=MAIN_CHANNEL_ID,
                                    video=f,
                                    caption=caption_tg if caption_tg else None,
                                    parse_mode="HTML",
                                    supports_streaming=True,
                                    width=1080,
                                    height=1920,
                                )
                            log.info("Telegram format: VIDEO_STREAMING_ON")
                        except Exception as e:
                            log.error(f"Telegram send video failed: {e}")
                            try:
                                item_fb = dict(item)
                                item_fb["caption"] = caption_meta
                                await publish_to_facebook(item_fb)
                                append_history("FB", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                            except Exception as e:
                                log.error(f"Facebook publish error (video): {e}")
                                send_admin_error(f"Facebook publish error (video): {e}")
                        # INSTAGRAM –ü–£–ë–õ–ò–ö–ê–¶–ò–Ø –° –ü–õ–ê–ù–û–ú –ë (–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è)
                        ig_success = False
                        ig_publish_attempts = 0
                        max_ig_attempts = 3
                        
                        # === DIAGNOSTIC: IG Schedule Check ===
                        now_before_check = datetime.now()
                        ready_count = len(list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4")))
                        last_post_str = LAST_POST_TIME.strftime('%Y-%m-%d %H:%M:%S') if LAST_POST_TIME else "Never"
                        log.info(f"[DIAGNOSTICS PRE-DECISION]")
                        log.info(f"  FORCE_POST_NOW={FORCE_POST_NOW}")
                        log.info(f"  Current time={now_before_check.strftime('%Y-%m-%d %H:%M:%S')} (hour={now_before_check.hour})")
                        log.info(f"  IG_SCHEDULE: morning={IG_SCHEDULE['morning_videos']}/3, evening={IG_SCHEDULE['afternoon_videos']}/6")
                        log.info(f"  LAST_POST_TIME={last_post_str}")
                        log.info(f"  Queue size={len(POST_QUEUE)}, Ready count={ready_count}")
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ Supabase –ü–ï–†–ï–î –ø–æ–ø—ã—Ç–∫–æ–π IG –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                        if can_ig_publish("video", force=FORCE_POST_NOW):
                            if not item.get("supabase_url"):
                                log.error("[IG_BLOCKED] Supabase upload failed - skipping Instagram publish to avoid empty URL")
                            else:
                                dark_palette = [(0, 0, 0), (10, 10, 20), (20, 20, 30), (12, 8, 24), (6, 12, 18)]
                                
                                while ig_publish_attempts < max_ig_attempts and not ig_success:
                                    ig_publish_attempts += 1
                                    
                                    try:
                                        # –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ
                                        if ig_publish_attempts == 1:
                                            log.info(f"[IG_ATTEMPT_{ig_publish_attempts}] Publishing with original processed video")
                                            item_ig = dict(item)
                                            item_ig["caption"] = caption_meta
                                            ig_result = await publish_to_instagram(item_ig)
                                            
                                            if ig_result is True:
                                                ig_success = True
                                                append_history("IG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                                                log.info("[IG_SUCCESS] Video published successfully on first attempt")
                                                break
                                            else:
                                                log.warning(f"[IG_ATTEMPT_{ig_publish_attempts}] Failed, preparing Plan B")
                                        
                                        # –ü–õ–ê–ù –ë: –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                                        else:
                                            log.warning(f"[PLAN B] Instagram retry attempt {ig_publish_attempts}/{max_ig_attempts} with new unique parameters...")
                                            
                                            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ü–ª–∞–Ω–∞ –ë
                                            speed_mult = 1.01 + (ig_publish_attempts - 1) * 0.01  # 1.01, 1.02, 1.03
                                            bg_color_new = dark_palette[(ig_publish_attempts - 1) % len(dark_palette)]
                                            brightness_adj = 0.01 * ig_publish_attempts  # 0.01, 0.02, 0.03
                                            
                                            log.info(f"[PLAN B] Reprocessing video: speed={speed_mult:.3f}, bg={bg_color_new}, brightness={brightness_adj:+.3f}")
                                            
                                            # –ü–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                                            processed_path_retry = process_video(
                                                local_path, 
                                                caption, 
                                                speed_multiplier=speed_mult, 
                                                bg_color_override=bg_color_new, 
                                                brightness_adjust=brightness_adj,
                                                random_crop=True  # –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ Meta
                                            )
                                            
                                            if not processed_path_retry or not Path(processed_path_retry).exists():
                                                log.error(f"[PLAN B] Video reprocessing failed on attempt {ig_publish_attempts}")
                                                continue
                                            
                                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –≤ Supabase
                                            content_type_retry = mimetypes.guess_type(str(processed_path_retry))[0] or "video/mp4"
                                            public_url_retry = upload_to_supabase(str(processed_path_retry), content_type_retry)
                                            
                                            if not public_url_retry:
                                                log.error(f"[PLAN B] Supabase upload failed on attempt {ig_publish_attempts}")
                                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                                if Path(processed_path_retry).exists():
                                                    await safe_unlink(processed_path_retry)
                                                continue
                                            
                                            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –∏–∑ Supabase –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                                            old_url = item.get("supabase_url")
                                            if old_url:
                                                delete_supabase_file(old_url)
                                            
                                            # –û–±–Ω–æ–≤–ª—è–µ–º URL –≤ item
                                            item["supabase_url"] = public_url_retry
                                            item_ig = dict(item)
                                            item_ig["caption"] = caption_meta
                                            
                                            log.info(f"[PLAN B] Attempting publish with new URL: {public_url_retry[:60]}...")
                                            ig_result = await publish_to_instagram(item_ig)
                                            
                                            if ig_result is True:
                                                ig_success = True
                                                append_history("IG", "Video", public_url_retry, item.get("translation_cost", 0.0))
                                                log.info(f"[PLAN B SUCCESS] Video published on attempt {ig_publish_attempts}")
                                                
                                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                                if Path(processed_path_retry).exists():
                                                    await safe_unlink(processed_path_retry)
                                                break
                                            else:
                                                log.warning(f"[PLAN B] Attempt {ig_publish_attempts} failed")
                                                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                                                if Path(processed_path_retry).exists():
                                                    await safe_unlink(processed_path_retry)
                                                
                                                if ig_publish_attempts >= max_ig_attempts:
                                                    log.error(f"[PLAN B EXHAUSTED] All {max_ig_attempts} attempts failed, giving up on this post")
                                                    send_admin_error(f"Instagram: Failed after {max_ig_attempts} attempts (Plan B exhausted)")
                                    
                                    except Exception as e:
                                        log.error(f"[IG_ATTEMPT_{ig_publish_attempts}] Exception: {e}")
                                        send_admin_error(f"Instagram publish error (attempt {ig_publish_attempts}): {e}")
                                        
                                        if ig_publish_attempts >= max_ig_attempts:
                                            log.error("[PLAN B EXHAUSTED] Maximum attempts reached, moving to next post")
                        
                        # –û–¢–õ–û–ñ–ï–ù–ù–û–ï –£–î–ê–õ–ï–ù–ò–ï: –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—Ö–∞ Instagram –∏–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è –ø–æ–ø—ã—Ç–æ–∫
                        if ig_success:
                            log.info("[IG_SUCCESS] Waiting 300 seconds before cleanup (guaranteed publish protocol)")
                            await sleep_or_postnow(300)
                        
                        # cleanup –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
                        # CONVEYOR: –£–¥–∞–ª—è–µ–º –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑ ready_to_publish
                        if upload_path and upload_path.parent == READY_TO_PUBLISH_DIR:
                            try:
                                if upload_path.exists():
                                    await safe_unlink(upload_path)
                                    log.info(f"[CONVEYOR] Deleted ready file: {upload_path.name}")
                                # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (READY_META_EXT_FIX: try both formats)
                                meta_path_a = upload_path.with_suffix('.json')
                                meta_path_b = upload_path.with_suffix('.mp4.json')
                                meta_path = meta_path_a if meta_path_a.exists() else (meta_path_b if meta_path_b.exists() else None)
                                if meta_path and meta_path.exists():
                                    await safe_unlink(meta_path)
                                    log.info(f"[CONVEYOR] Deleted metadata: {meta_path.name}")
                            except Exception as e:
                                log.warning(f"[CONVEYOR] Failed to delete ready file: {e}")
                        else:
                            # FIRST STRIKE: –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (local_path, processed_path)
                            try:
                                if 'local_path' in locals() and local_path and Path(local_path).exists():
                                    await safe_unlink(local_path)
                                    log.info(f"[FIRST STRIKE] Deleted temp file: {Path(local_path).name}")
                                if 'processed_path' in locals() and processed_path and Path(processed_path).exists():
                                    await safe_unlink(processed_path)
                                    log.info(f"[FIRST STRIKE] Deleted processed file: {Path(processed_path).name}")
                                if upload_path and Path(upload_path).exists():
                                    await safe_unlink(upload_path)
                                    log.info(f"[FIRST STRIKE] Deleted upload file: {Path(upload_path).name}")
                            except Exception as e:
                                log.warning(f"[FIRST STRIKE] Failed to delete temp files: {e}")
                        
                        # –£–¥–∞–ª–µ–Ω–∏–µ –∏–∑ Supabase –¢–û–õ–¨–ö–û –µ—Å–ª–∏ IG —É—Å–ø–µ—à–Ω–∞ –∏–ª–∏ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
                        if ig_success or ig_publish_attempts >= max_ig_attempts:
                            maybe_delete_supabase_media(item, reason="all_platforms_complete")
                            log.info(f"[CLEANUP] Supabase cleanup executed (ig_success={ig_success}, attempts={ig_publish_attempts})")
                        else:
                            log.warning("[CLEANUP] Supabase cleanup skipped - IG publish pending")
                        
                        increment_stat("video")
                        append_history("TG", "Video", item.get("supabase_url", "-"), item.get("translation_cost", 0.0))
                        if caption:
                            PUBLISHED_TEXTS.append(caption)
                            if len(PUBLISHED_TEXTS) > MAX_PUBLISHED_TEXTS:
                                PUBLISHED_TEXTS.pop(0)
                            save_published_texts()
                        log.info("published_ok (video)")
                        
                        await delete_from_buffer(application, item)
                        await send_progress_report(application)
                        LAST_VIDEO_TIME = datetime.now()
                        LAST_POST_TIME = datetime.now()
                        save_last_post_time()
                        
                        # Increment schedule counters (9 posts/day: 3 morning + 6 evening)
                        now_publish = datetime.now()
                        if now_publish.hour < 14:
                            IG_SCHEDULE["morning_videos"] += 1
                            log.info(f"[SCHEDULER] Morning counter: {IG_SCHEDULE['morning_videos']}/3")
                        elif 16 <= now_publish.hour <= 21:
                            IG_SCHEDULE["afternoon_videos"] += 1
                            log.info(f"[SCHEDULER] Evening counter: {IG_SCHEDULE['afternoon_videos']}/6")
                        
                        # === FINAL POSTNOW RESET (after full publish cycle) ===
                        if FORCE_POST_NOW:
                            FORCE_POST_NOW = False
                            log.info("[POSTNOW] Final reset after full multi-platform publish")
                except Exception as e:
                    log.error(f"Failed to send post: {e}")
                    error_msg = str(e)
                    
                    # –ù–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ –±–∏—Ç—ã—Ö –ø–æ—Å—Ç–∞—Ö
                    if isinstance(e, BadRequest) or "Bad Request" in error_msg or "Invalid file_id" in error_msg:
                        log.critical("üö® CRITICAL | Skipping broken post due to BadRequest/Invalid file_id")
                        try:
                            maybe_delete_supabase_media(item, reason="bad_request")
                            await delete_from_buffer(application, item)
                            await send_progress_report(application)
                        except Exception as e2:
                            log.error(f"Failed to cleanup after BadRequest: {e2}")
                        # –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                        save_queue()
                        await sleep_or_postnow(300)
                    else:
                        # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                        POST_QUEUE.appendleft(item)
                        save_queue()
                        await sleep_or_postnow(60)
            else:
                # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞—è - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
                loaded = load_ready_files_to_queue()
                if loaded == 0:
                    log.info("[DEBUG] Queue empty and no ready files. Waiting...")
                await sleep_or_postnow(60)
        except Exception as e:
            log.exception(f"[POST_WORKER] Loop error (will continue): {e}")
            await asyncio.sleep(1)
            continue


async def restart_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–£–¥–∞–ª–µ–Ω–Ω—ã–π —Ä–µ—Å—Ç–∞—Ä—Ç –±–æ—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized restart attempt from user_id={user_id}")
        return
    
    log.info(f"[RESTART] Remote restart initiated by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "üöÄ –†–µ—Å—Ç–∞—Ä—Ç –∑–∞–ø—É—â–µ–Ω... –û–±–Ω–æ–≤–ª—è—é —Å–∏—Å—Ç–µ–º—É.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[RESTART] Failed to send confirmation message: {e}")
    
    # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ Python
    log.info("[RESTART] Executing restart...")
    os.execv(sys.executable, ['python'] + sys.argv)


async def stop_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–£–¥–∞–ª–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized stop attempt from user_id={user_id}")
        return
    
    log.info(f"[STOP] Remote shutdown initiated by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "üõë –°–∏—Å—Ç–µ–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∞–¥–º–∏–Ω–æ–º. –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞...",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[STOP] Failed to send confirmation message: {e}")
    
    # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ (–ø—Ä–µ–∫—Ä–∞—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö —Ñ–æ–Ω–æ–≤—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤)
    log.info("[STOP] Executing shutdown... All workers and conveyor system will be terminated.")
    os._exit(0)


async def postnow_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–§–æ—Ä—Å-–ø—É–±–ª–∏–∫–∞—Ü–∏—è —Å—Ä–∞–∑—É (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ)"""
    global FORCE_POST_NOW, POSTNOW_EVENT
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized postnow attempt from user_id={user_id}")
        return
    
    FORCE_POST_NOW = True
    POSTNOW_EVENT.set()  # –ü—Ä–æ–±—É–∂–¥–∞–µ–º –≤–æ—Ä–∫–µ—Ä –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
    
    log.info(f"[POSTNOW] Force post override activated by admin (user_id={user_id}) at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        await update.message.reply_text(
            "‚úÖ POSTNOW: –≤–æ—Ä–∫–µ—Ä —Ä–∞–∑–±—É–∂–µ–Ω, –ø—Ä–æ–±—É—é –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–µ–π—á–∞—Å.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[POSTNOW] Failed to send confirmation message: {e}")


async def pause_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°—Ç–∞–≤–∏—Ç –∫–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ –ø–∞—É–∑—É (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    global IS_PAUSED
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized pause attempt from user_id={user_id}")
        return
    
    IS_PAUSED = True
    log.info(f"[PAUSE] Conveyor paused by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "‚è∏ –ö–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ –ø–∞—É–∑–µ. –ü–æ—Å—Ç—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[PAUSE] Failed to send confirmation message: {e}")


async def resume_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ—Ç —Ä–∞–±–æ—Ç—É –∫–æ–Ω–≤–µ–π–µ—Ä–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    global IS_PAUSED
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized resume attempt from user_id={user_id}")
        return
    
    IS_PAUSED = False
    log.info(f"[RESUME] Conveyor resumed by admin (user_id={user_id})")
    
    try:
        await update.message.reply_text(
            "‚ñ∂Ô∏è –ö–æ–Ω–≤–µ–π–µ—Ä –∑–∞–ø—É—â–µ–Ω! –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É.",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[RESUME] Failed to send confirmation message: {e}")


async def interval_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ò–∑–º–µ–Ω—è–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–π (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    global PUBLISH_INTERVAL_SECONDS
    
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized interval attempt from user_id={user_id}")
        return

    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥—ã
    try:
        if not context.args or len(context.args) == 0:
            await update.message.reply_text(
                "‚ùå –£–∫–∞–∂–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö.\n–ü—Ä–∏–º–µ—Ä: /interval 60",
                parse_mode='HTML'
            )
            return
        
        new_interval_minutes = int(context.args[0])
        
        if new_interval_minutes < 1 or new_interval_minutes > 1440:
            await update.message.reply_text(
                "‚ùå –ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 1440 –º–∏–Ω—É—Ç (24 —á–∞—Å–∞).",
                parse_mode='HTML'
            )
            return
        
        PUBLISH_INTERVAL_SECONDS = new_interval_minutes * 60
        log.info(f"[INTERVAL] Changed to {new_interval_minutes} minutes by admin (user_id={user_id})")
        
        await update.message.reply_text(
            f"‚è∞ –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω: {new_interval_minutes} –º–∏–Ω. –°–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ–¥ —ç—Ç–æ –≤—Ä–µ–º—è.",
            parse_mode='HTML'
        )
    except ValueError:
        await update.message.reply_text(
            "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –£–∫–∞–∂–∏—Ç–µ —á–∏—Å–ª–æ.\n–ü—Ä–∏–º–µ—Ä: /interval 60",
            parse_mode='HTML'
        )
    except Exception as e:
        log.error(f"[INTERVAL] Error: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞.",
            parse_mode='HTML'
        )


async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id if update.effective_user else None
    
    if user_id != ADMIN_TELEGRAM_ID:
        log.warning(f"[SECURITY] Unauthorized status attempt from user_id={user_id}")
        return

    try:
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        status_text = "‚úÖ –†–ê–ë–û–¢–ê–ï–¢" if not IS_PAUSED else "‚è∏ –ü–ê–£–ó–ê"
        
        # –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤ –º–∏–Ω—É—Ç–∞—Ö
        interval_minutes = PUBLISH_INTERVAL_SECONDS // 60
        
        # –í—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ—Å—Ç–∞
        if LAST_POST_TIME is None:
            time_remaining = "‚ö° –ì–æ—Ç–æ–≤ –∫ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"
        else:
            next_post_time = LAST_POST_TIME + timedelta(seconds=PUBLISH_INTERVAL_SECONDS)
            now = datetime.now()
            time_diff = next_post_time - now
            
            if time_diff.total_seconds() <= 0:
                time_remaining = "‚ö° –ì–æ—Ç–æ–≤ –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"
            else:
                minutes = int(time_diff.total_seconds() // 60)
                seconds = int(time_diff.total_seconds() % 60)
                time_remaining = f"{minutes:02d}:{seconds:02d}"
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ—Ç–æ–≤—ã—Ö –≤–∏–¥–µ–æ –Ω–∞ —Å–∫–ª–∞–¥–µ
        ready_files = list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
        ready_count = len(ready_files)
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏
        queue_count = len(POST_QUEUE)
        video_queue_count = sum(1 for item in POST_QUEUE if item.get("type") == "video")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        status_message = (
            f"üìä <b>–ú–û–ù–ò–¢–û–†–ò–ù–ì –°–ò–°–¢–ï–ú–´:</b>\n\n"
            f"‚óè –°—Ç–∞—Ç—É—Å: {status_text}\n"
            f"‚óè –ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval_minutes} –º–∏–Ω.\n"
            f"‚óè –°–õ–ï–î–£–Æ–©–ò–ô –ü–û–°–¢ –ß–ï–†–ï–ó: {time_remaining}\n"
            f"‚óè –ì–æ—Ç–æ–≤—ã—Ö HD-–≤–∏–¥–µ–æ (—Å–∫–ª–∞–¥): {ready_count}/5\n"
            f"‚óè –í–∏–¥–µ–æ –≤ –æ—á–µ—Ä–µ–¥–∏ (–±–∞–∑–∞): {video_queue_count}\n"
            f"‚óè –í—Å–µ–≥–æ –≤ –æ—á–µ—Ä–µ–¥–∏: {queue_count}\n"
        )
        
        await update.message.reply_text(
            status_message,
            parse_mode='HTML'
        )
        
        log.info(f"[STATUS] System status requested by admin (user_id={user_id})")
        
    except Exception as e:
        log.error(f"[STATUS] Error: {e}")
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã.",
            parse_mode='HTML'
        )


async def handle_channel_post(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    msg = update.channel_post
    if not msg:
        return

    chat_id = msg.chat_id
    message_id = msg.message_id

    log.info(f"channel_post received: chat_id={chat_id}, message_id={message_id}")

    # —Ä–µ–∞–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ –±—É—Ñ–µ—Ä–Ω—ã–π –∫–∞–Ω–∞–ª
    if chat_id != BUFFER_CHANNEL_ID:
        log.info(f"Ignored channel_post from chat_id={chat_id} (not BUFFER)")
        return

    # –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
    post = update.channel_post
    # CAPTION_SOURCE_PRIORITY: prefer caption over text
    src_text_raw = (post.caption or post.text or "")
    src_text = ensure_utf8_text(src_text_raw).strip()
    log.info("RAW_CAPTION_SOURCE: %s", src_text[:200] if src_text else "(empty)")
    text_for_translate = src_text
    entities = post.entities or post.caption_entities
    
    # üîç SMART ROUTING: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Instagram URL
    instagram_url = None
    instagram_video_path = None
    is_url_source = False
    
    # –ò—â–µ–º Instagram URL –≤ —Ç–µ–∫—Å—Ç–µ
    if text_for_translate:
        import re
        instagram_pattern = r'https?://(?:www\.)?instagram\.com/(?:p|reel|reels)/[\w-]+'
        match = re.search(instagram_pattern, text_for_translate)
        if match:
            instagram_url = match.group(0)
            is_url_source = True
            log.info(f"[SMART ROUTING] Instagram URL detected: {instagram_url[:50]}...")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ Instagram
            try:
                instagram_video_path = download_from_instagram(instagram_url)
                if not instagram_video_path:
                    error_msg = f"‚ùå [INSTAGRAM] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ URL: {instagram_url}"
                    log.error(error_msg)
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –∞–¥–º–∏–Ω—É
                    try:
                        await context.bot.send_message(
                            chat_id=ADMIN_TELEGRAM_ID,
                            text=f"üö® <b>Instagram Download Failed</b>\n\n{error_msg}",
                            parse_mode='HTML'
                        )
                    except:
                        pass
                    return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                log.info(f"[SMART ROUTING] ‚úÖ Video downloaded from Instagram: {instagram_video_path.name}")
            except Exception as e:
                error_msg = f"‚ùå [INSTAGRAM] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {e}"
                log.error(error_msg)
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –∞–¥–º–∏–Ω—É
                try:
                    await context.bot.send_message(
                        chat_id=ADMIN_TELEGRAM_ID,
                        text=f"üö® <b>Instagram Download Error</b>\n\n{error_msg}",
                        parse_mode='HTML'
                    )
                except:
                    pass
                return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É

    # üé§ WHISPER: –ï—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ (Telegram –∏–ª–∏ Instagram), –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
    whisper_transcript = None
    video_source_path = None
    
    if instagram_video_path:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–∞—á–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –∏–∑ Instagram
        video_source_path = instagram_video_path
        log.info("[WHISPER] Processing Instagram video...")
    elif post.video:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏–¥–µ–æ –∏–∑ Telegram
        log.info("[WHISPER] Processing Telegram video...")
    
    # Only attempt Whisper transcription if no src_text provided
    if (video_source_path or post.video) and not text_for_translate.strip():
        try:
            if not video_source_path:
                # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ Telegram
                log.info("[WHISPER] Video detected, attempting transcription...")
                tmp_dir = Path("tmp_media")
                tmp_dir.mkdir(exist_ok=True)
                video_file = await context.bot.get_file(post.video.file_id)
                tmp_video_path = tmp_dir / f"whisper_video_{post.video.file_id[:10]}.mp4"
                await video_file.download_to_drive(custom_path=str(tmp_video_path))
                video_source_path = tmp_video_path
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
            whisper_transcript = get_video_transcript(video_source_path)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –∏–∑ Telegram, Instagram —É–¥–∞–ª–∏–º –ø–æ–∑–∂–µ)
            if post.video and video_source_path.exists():
                video_source_path.unlink()
                log.info("[WHISPER] Temporary Telegram video file deleted")
            
            if whisper_transcript:
                log.info(f"[WHISPER] ‚úÖ Transcription successful: {len(whisper_transcript)} chars")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
                text_for_translate = whisper_transcript
            else:
                log.warning("[WHISPER] Transcription failed, using caption text")
        except Exception as e:
            log.error(f"[WHISPER] Video transcription error: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ

    log.info("RAW before translate: %s", text_for_translate[:200] if text_for_translate else "(empty)")

    # –ì–ê–†–ê–ù–¢–ò–†–£–ï–ú –ø–µ—Ä–µ–≤–æ–¥ –í–°–ï–• –ø–æ—Å—Ç–æ–≤
    if text_for_translate.strip():
        # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º entities –≤ –º–∞—Ä–∫–µ—Ä—ã –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º
        prepared = entities_to_markers(text_for_translate, entities)
        translated = await translate_text(prepared)
    else:
        translated = ""
    
    final_text = sanitize_post(translated)
    
    # –£–±–∏—Ä–∞–µ–º —Ñ—Ä–∞–∑—ã –ø—Ä–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    final_text = remove_comment_phrases(final_text)

    log.info("FINAL after translate: %s", final_text[:200] if final_text else "(empty)")

    # üéôÔ∏è ELEVENLABS: SMART ROUTING - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–∑–≤—É—á–∫—É —Ç–æ–ª—å–∫–æ –¥–ª—è Instagram URL
    voiceover_path = None
    has_voiceover = False
    
    if is_url_source and final_text.strip():
        # IF URL (Instagram): Generate ElevenLabs voiceover
        try:
            log.info("[SMART ROUTING] Instagram source ‚Üí Generating ElevenLabs voiceover...")
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ö—ç—à—Ç–µ–≥–æ–≤ –¥–ª—è –æ–∑–≤—É—á–∫–∏
            text_for_voice = final_text.split('\n')[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç)
            voiceover_path = generate_voiceover(text_for_voice)
            
            if voiceover_path:
                has_voiceover = True
                log.info(f"[ELEVENLABS] ‚úÖ Voiceover ready: {voiceover_path.name} (voiceover: True)")
            else:
                log.warning("[ELEVENLABS] Voiceover generation failed, continuing without voice")
        except Exception as e:
            log.error(f"[ELEVENLABS] Voiceover generation error: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –æ–∑–≤—É—á–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    elif post.video:
        # IF FILE (Telegram): SKIP ElevenLabs
        log.info("[SMART ROUTING] Telegram source ‚Üí Skipping ElevenLabs (voiceover: False)")
        has_voiceover = False

    # —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    final_text = format_post_structure(final_text)
    
    # –ì–ª—É–±–æ–∫–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å—Å—ã–ª–∫–∏/—Ö—ç—à—Ç–µ–≥–∏/—É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –Ω–∞—à–∏—Ö –±–ª–æ–∫–æ–≤
    final_text = clean_caption(final_text)
    
    # –ì–ê–†–ê–ù–¢–ò–†–£–ï–ú –Ω–∞–ª–∏—á–∏–µ —Ñ—É—Ç–µ—Ä–∞ –ü–û–°–õ–ï –æ—á–∏—Å—Ç–∫–∏
    final_text = ensure_footer(final_text)
    final_text = append_branding(final_text)
    final_text = append_hashtags(final_text)

    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª
    if post.photo:
        # –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        item = {
            "type": "photo",
            "file_id": post.photo[-1].file_id,
            "caption": final_text,
            "buffer_message_id": message_id,
            "buffer_chat_id": chat_id,
            "translation_cost": TRANSLATION_LAST_COST,
        }
    elif post.video or instagram_video_path:
        # –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ (Telegram –∏–ª–∏ Instagram), –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        item = {
            "type": "video",
            "file_id": post.video.file_id if post.video else "instagram_source",
            "caption": final_text,
            "instagram_video_path": str(instagram_video_path) if instagram_video_path else None,  # –î–û–ë–ê–í–¨ –≠–¢–û
            "buffer_message_id": message_id,
            "buffer_chat_id": chat_id,
            "translation_cost": TRANSLATION_LAST_COST,
            "voiceover": has_voiceover,  # üéôÔ∏è –§–ª–∞–≥ –¥–ª—è Smart Routing
            "voiceover_path": str(voiceover_path) if voiceover_path else None,  # üéôÔ∏è –ü—É—Ç—å –∫ –æ–∑–≤—É—á–∫–µ
            "instagram_source": instagram_url if instagram_url else None,
        }
    else:
        # –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –≤–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –∫–∞—Ä—É—Å–µ–ª–∏
        log.info("[DEBUG] –†–µ–∂–∏–º –∫–∞—Ä—É—Å–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∞–∫—Ç–∏–≤–µ–Ω")
        item = {
            "type": "carousel_pending",
            "text": final_text,
            "buffer_message_id": message_id,
            "buffer_chat_id": chat_id,
            "translation_cost": TRANSLATION_LAST_COST,
        }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–µ–π –≤–∫–ª—é—á–µ–Ω–∞
    h = post_hash(item)
    if h in SEEN_HASHES:
        log.info("Duplicate skipped")
        return
    SEEN_HASHES.add(h)
    save_seen()
    log.info("Queue push type=%s size_before=%s", item["type"], len(POST_QUEUE))
    POST_QUEUE.append(item)
    save_queue()
    log.info("Post queued. Queue size=%s", len(POST_QUEUE))
    
    # üéôÔ∏è –û–ó–í–£–ß–ö–ê: –ù–ï —É–¥–∞–ª—è–µ–º - –æ–Ω–∞ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ –≤ CONVEYOR
    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ prepare_video_for_ready
    if voiceover_path:
        log.info(f"[ELEVENLABS] Voiceover saved for later use: {voiceover_path.name}")
    
    # ‚úÖ Instagram –≤–∏–¥–µ–æ –ù–ï —É–¥–∞–ª—è–µ–º - –æ–Ω–æ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ CONVEYOR
    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤ prepare_video_for_ready


def main() -> None:
    load_queue()
    load_seen()
    load_stats()
    load_published_texts()
    load_last_post_time()
    log.info(f"INFO | [CONFIG] Current publish interval: {PUBLISH_INTERVAL_SECONDS // 60} minutes")
    log.info("System ready. All social networks optimized.")
    log.info("Golden Template Active. Content Separated.")
    video_count = sum(1 for it in POST_QUEUE if it.get("type") == "video")
    est_hours = (video_count + 59) // 60  # 1 per hour -> videos count hours
    log.info(f"INFO | [QUEUE] Found {video_count} posts for Instagram. Estimated completion time: {est_hours} hours.")

    async def post_init(app: Application) -> None:
        # üö® TOTAL QUEUE PURGE: –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ
        global POST_QUEUE
        try:
            original_size = len(POST_QUEUE)
            POST_QUEUE.clear()  # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            save_queue()
            
            if original_size > 0:
                log.info(f"üßπ [TOTAL PURGE] Cleared entire queue ({original_size} old items removed)")
            else:
                log.info("[TOTAL PURGE] Queue was already empty.")
        except Exception as e:
            log.error(f"[TOTAL PURGE] Error during queue cleanup: {e}")
        
        # üîÑ STARTUP SYNC: –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∏–∑ ready_to_publish
        try:
            log.info("[STARTUP] Loading fresh ready files from disk...")
            loaded = load_ready_files_to_queue()
            if loaded > 0:
                log.info(f"‚úÖ [SUCCESS] Queue refreshed from disk. Starting instant post with 4 hashtags (incl. #qiziqarli) + AI tag.")
                log.info(f"‚úÖ [STARTUP] Loaded {loaded} ready files into queue. First Strike ready.")
            else:
                log.warning("[STARTUP] No ready files found on disk.")
        except Exception as e:
            log.error(f"[STARTUP] Error loading ready files: {e}")
        
        # –†–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ Supabase –æ—Ç —Å–∏—Ä–æ—Ç—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º
        try:
            await cleanup_supabase_orphans(dry_run=False)
        except Exception as e:
            log.error(f"[Supabase] cleanup_supabase_orphans failed at startup: {e}")
        
        log.info("[CONVEYOR] System initialization...")
        
        # AUTO-PURGE: –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª—ã–µ —Ñ–∞–π–ª—ã –∏–∑ ready_to_publish
        try:
            ready_files = list(READY_TO_PUBLISH_DIR.glob("ready_*.mp4"))
            purged_count = 0
            for ready_file in ready_files:
                file_size_mb = ready_file.stat().st_size / (1024 * 1024)
                if file_size_mb > 95:
                    log.warning(f"[AUTO-PURGE] Deleting oversized file: {ready_file.name} ({file_size_mb:.2f} MB)")
                    ready_file.unlink()
                    # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–∂–µ (READY_META_EXT_FIX: try both formats)
                    meta_file_a = ready_file.with_suffix('.json')
                    meta_file_b = ready_file.with_suffix('.mp4.json')
                    meta_file = meta_file_a if meta_file_a.exists() else (meta_file_b if meta_file_b.exists() else None)
                    if meta_file and meta_file.exists():
                        meta_file.unlink()
                    purged_count += 1
            if purged_count > 0:
                log.info(f"[AUTO-PURGE] Removed {purged_count} oversized files. Conveyor will regenerate them.")
            else:
                log.info("[AUTO-PURGE] No oversized files found. All clear.")
        except Exception as e:
            log.error(f"[AUTO-PURGE] Error during cleanup: {e}")
        
        # üßπ TMP_MEDIA CLEANUP: –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        try:
            tmp_media_dir = Path("tmp_media")
            if tmp_media_dir.exists():
                old_files = []
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ .mp4 –∏ .MP4 —Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ –ø–æ–¥–ø–∞–ø–æ–∫)
                for pattern in ["*.mp4", "*.MP4"]:
                    for file in tmp_media_dir.glob(pattern):
                        if file.is_file():
                            try:
                                file.unlink()
                                old_files.append(file.name)
                            except Exception as e:
                                log.warning(f"[TMP_CLEANUP] Failed to delete {file.name}: {e}")
                
                if old_files:
                    log.info(f"üßπ [TMP_CLEANUP] Removed {len(old_files)} old temporary files from tmp_media/")
                else:
                    log.info("[TMP_CLEANUP] No old temporary files found in tmp_media/")
        except Exception as e:
            log.error(f"[TMP_CLEANUP] Error during tmp_media cleanup: {e}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º workers
        asyncio.create_task(video_processing_worker())  # FIX B: Video processing worker
        asyncio.create_task(post_worker(app))
        asyncio.create_task(daily_report_scheduler(app))
        asyncio.create_task(history_log_scheduler())
        asyncio.create_task(maintain_ready_posts_worker(app))  # CONVEYOR worker
        
        log.info("[CONVEYOR] All workers started. First Strike and Conveyor system active.")

    app = (
        Application.builder()
        .token(TELEGRAM_BOT_TOKEN)
        .read_timeout(60)
        .connect_timeout(60)
        .pool_timeout(60)
        .write_timeout(60)
        .post_init(post_init)
        .build()
    )

    # –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)
    app.add_handler(CommandHandler("restart", restart_command))
    app.add_handler(CommandHandler("stop", stop_command))
    app.add_handler(CommandHandler("postnow", postnow_command))
    app.add_handler(CommandHandler("pause", pause_command))
    app.add_handler(CommandHandler("resume", resume_command))
    app.add_handler(CommandHandler("interval", interval_command))
    app.add_handler(CommandHandler("status", status_command))

    # –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ—Å—Ç–æ–≤ –∏–∑ –∫–∞–Ω–∞–ª–æ–≤
    app.add_handler(MessageHandler(filters.UpdateType.CHANNEL_POST, handle_channel_post))

    log.info("‚úÖ Bot is running. Waiting for channel posts...")
    log.info("üîß Remote management active. New Instagram schedule applied.")
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
